<!DOCTYPE HTML>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>References,heading=bibintoc - Addition and removal energies via the in-medium similarity renormalization group method</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <base href="">

        <link rel="stylesheet" href="book.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:500" rel="stylesheet" type="text/css">

        <link rel="shortcut icon" href="favicon.png">

        <!-- Font Awesome -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">

        <!-- MathJax -->
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Fetch JQuery from CDN but have a local fallback -->
        <script src="https://code.jquery.com/jquery-2.1.4.min.js"></script>
        <script>
            if (typeof jQuery == 'undefined') {
                document.write(unescape("%3Cscript src='jquery.js'%3E%3C/script%3E"));
            }
        </script>
    </head>
    <body class="light">
        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme = localStorage.getItem('theme');
            if (theme == null) { theme = 'light'; }
            $('body').removeClass().addClass(theme);
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var sidebar = localStorage.getItem('sidebar');
            if (sidebar === "hidden") { $("html").addClass("sidebar-hidden") }
            else if (sidebar === "visible") { $("html").addClass("sidebar-visible") }
        </script>

        <div id="sidebar" class="sidebar">
            <ul class="chapter"><li class="affix"><a href="abstract.html">Abstract</a></li><li class="affix"><a href="dedication.html">Dedication</a></li><li class="affix"><a href="acknowledgments.html">Acknowledgments</a></li><li class="affix"><a href="key-to-symbols.html">Key to Symbols</a></li><li><a href="introduction.html"><strong>1.</strong> Introduction</a></li><li><a href="many-body-theory.html"><strong>2.</strong> Many-body formalism</a></li><li><ul class="section"><li><a href="diagrams.html"><strong>2.1.</strong> Many-body diagrams</a></li></ul></li><li><a href="angular-momentum-coupling.html"><strong>3.</strong> Angular momentum coupling</a></li><li><a href="methods.html"><strong>4.</strong> Many-body methods</a></li><li><ul class="section"><li><a href="hartree-fock.html"><strong>4.1.</strong> Hartree–Fock method</a></li><li><a href="imsrg.html"><strong>4.2.</strong> In-medium similarity renormalization group method</a></li><li><a href="qdpt.html"><strong>4.3.</strong> Quasidegenerate perturbation theory</a></li></ul></li><li><a href="systems.html"><strong>5.</strong> Application to quantum systems</a></li><li><ul class="section"><li><a href="quantum-dots.html"><strong>5.1.</strong> Quantum dots</a></li><li><a href="nuclei.html"><strong>5.2.</strong> Nuclei</a></li></ul></li><li><a href="implementation.html"><strong>6.</strong> Implementation</a></li><li><a href="results.html"><strong>7.</strong> Results and analysis</a></li><li><a href="conclusions.html"><strong>8.</strong> Conclusions</a></li><li class="affix"><a href="bibliography.html">References,heading=bibintoc</a></li></ul>
        </div>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar" class="menu-bar">
                    <div class="left-buttons">
                        <i id="sidebar-toggle" class="fa fa-bars"></i>
                        <i id="theme-toggle" class="fa fa-paint-brush"></i>
                    </div>

                    <h1 class="menu-title">Addition and removal energies via the in-medium similarity renormalization group method</h1>

                    <div class="right-buttons">
                        <i id="print-button" class="fa fa-print" title="Print this book"></i>
                    </div>
                </div>

                <div id="content" class="content">
                    <h1 id="abstract"><span class="header-section-number">1</span> Abstract</h1>
<p>The in-medium similarity renormalization group (IM-SRG) is an <em>ab initio</em> many-body method suitable for systems with moderate numbers of particles due to its polynomial scaling in computational cost. The formalism is highly flexible and admits a variety of modifications that extend its utility beyond the original goal of computing ground state energies of closed-shell systems.</p>
<p>In this work, we present an extension of IM-SRG through quasidegenerate perturbation theory (QDPT) to compute addition and removal energies (single particle energies) near the Fermi level at low computational cost. This expands the range of systems that can be studied from closed-shell ones to nearby systems that differ by one particle. The method is applied to circular quantum dot systems and nuclei, and compared against other methods including equations-of-motion (EOM) IM-SRG and EOM coupled-cluster (CC) theory. The results are in good agreement for most cases.</p>
<p>As part of this work, we present an open-source implementation of our flexible and easy-to-use J-scheme framework as well as the HF, IM-SRG, and QDPT codes built upon this framework. We include an overview of the overall structure, the implementation details, and strategies for maintaining high code quality and efficiency.</p>
<p>Lastly, we also present a graphical application for manipulation of angular momentum coupling coefficients through a diagrammatic notation for angular momenta (Jucys diagrams). The tool enables rapid derivations of equations involving angular momentum coupling – such as in J-scheme – and significantly reduces the risk of human errors.</p>
<h1 id="dedication"><span class="header-section-number">2</span> Dedication</h1>
<p><em>In memory of Shichao Yuan (1964-2016) and Erik “Kexie” Gustafsson (1992-2017)</em></p>
<h1 id="acknowledgments"><span class="header-section-number">3</span> Acknowledgments</h1>
<p>I am forever indebted to my parents, who have made this journey at all possible. My interest in software was strongly inspired by my father’s projects, whereas my foundations in mathematics would not have been as solid without the tutoring from my mother. Throughout my studies, they have gone above and beyond to support my education, in spite of the limited resources our family had. I also extend my thanks to my grandparents who cared for me during my youngest years.</p>
<p>On the academic side, I would like to thank my thesis advisor Morten Hjorth-Jensen for his knowledge, wisdom, and, most importantly, support. He had helped reignite my interest in physics by offering a pathway from experimental to computational physics. He encouraged me to research in areas that are most relevant to my interests, allowing me to learn and explore far more than I would have otherwise. I also wish to thank my co-advisor Scott Bogner, who has been very patient and offered valuable assistance and technical discussions. I thank the rest of my committee – Alexandra Gade, Carlo Piermarrochi, and Scott Pratt – for their helpful inputs, as well as my former advisor Chong-Yu Ruan who guided me during both undergraduate research and my first two years of graduate research.</p>
<p>I thank my colleagues for our productive discussions, including Heiko Hergert, Titus Morris, Justin Lietz, as well as Nathan Parzuchowski and Sam Novario, who have contributed substantially to the results of this work. On a personal level, I wish to thank Nathan, my hard-working officemate who is well-versed in the intricacies of IM-SRG and Fortran and has a great sense of humor, Titus, whose mastery in many-body theory, quantum chemistry, and social situations is unmatched, Vinzent Steinberg, with whom many fun discussions and debates in programming have been made, and Tzong-Ru Terry Han, who has been very kind and supportive during my years in the laboratory. I would also like to thank Debbie Barratt and Kim Crosslan for their support throughout my long stay at Michigan State University.</p>
<p>Lastly, I wish to thank all the friends I have made along the way for their support and encouragement, including my feline companion TipToe who has always had to put up with my chaotic schedule.</p>
<h1 id="key-to-symbols"><span class="header-section-number">4</span> Key to Symbols</h1>
<ul>
<li><span class="math inline">\(\bm{x}\)</span> (bold) — matrix or vector</li>
<li><span class="math inline">\(\hat{x}\)</span> (hat) — quantum operator</li>
<li><span class="math inline">\(x^*\)</span> (superscript asterisk) — complex conjugation</li>
<li><span class="math inline">\(x^\dagger\)</span> (superscript dagger) — Hermitian adjoint</li>
<li><span class="math inline">\(\bm{1}\)</span> — identity matrix</li>
<li><span class="math inline">\(\hat{1}\)</span> — identity operator</li>
<li><span class="math inline">\(\mathbb{N}\)</span> — nonnegative integers</li>
<li><span class="math inline">\(\mathbb{Z}\)</span> — integers</li>
<li><span class="math inline">\(\mathbb{H}\)</span> — Hilbert space of a quantum system</li>
<li><span class="math inline">\(\mathbb{F}^\pm\)</span> — <span class="math inline">\(\pm\)</span>-symmetric Fock space (Sec. <a href="many-body-theory.html#sec:second-quantization">6.2</a>)</li>
<li><span class="math inline">\(\delta_{p q}\)</span> — Kronecker delta</li>
<li><span class="math inline">\(\epsilon_{i j k}\)</span> — Levi–Civita symbol</li>
<li><span class="math inline">\(\Gamma(x)\)</span> — gamma function</li>
<li><span class="math inline">\(L_n^\alpha(x)\)</span> — associated Laguerre polynomial (Eq. <a href="quantum-dots.html#eq:laguerre-polynomials">57</a>)</li>
<li><span class="math inline">\(\bar{L}_n^\alpha(x)\)</span> – normalized associated Laguerre polynomial (Eq. <a href="quantum-dots.html#eq:laguerre-polynomials">57</a>)</li>
<li><span class="math inline">\(Y_{\ell m}(\theta, \varphi)\)</span> — spherical harmonic with Condon–Shortley phase <span class="citation" data-cites="DLMF">(“NIST Digital Library of Mathematical Functions” 2016)</span></li>
<li><span class="math inline">\((-)^i\)</span> — shorthand for <span class="math inline">\((-1)^i\)</span></li>
<li><span class="math inline">\((-)^\sigma\)</span> — sign of a permutation <span class="math inline">\(\sigma\)</span></li>
<li><span class="math inline">\(\lfloor x \rfloor\)</span> — floor of <span class="math inline">\(x\)</span></li>
<li><span class="math inline">\([\hat{x}, \hat{y}]_- = [\hat{x}, \hat{y}]\)</span> — commutator</li>
<li><span class="math inline">\([\hat{x}, \hat{y}]_+ = \{\hat{x}, \hat{y}\}\)</span> — anticommutator</li>
<li><span class="math inline">\(\normord{x}\)</span> — normal ordering relative to Fermi vaccuum (Sec. <a href="many-body-theory.html#sec:normord">6.5</a>)</li>
<li><span class="math inline">\(\vnormord{x}\)</span> — normal ordering relative to physical vacuum (Sec. <a href="many-body-theory.html#sec:normord">6.5</a>)</li>
<li><span class="math inline">\(\mathbb{V} \otimes \mathbb{W}\)</span> — tensor product of vector spaces</li>
<li><span class="math inline">\(\ket{a} \otimes \ket{b}\)</span> — tensor product constructor of kets</li>
<li><span class="math inline">\(\ket{p \otimes q}\)</span> — tensor product state (Sec. <a href="many-body-theory.html#sec:prod-state">6.1.1</a>)</li>
<li><span class="math inline">\(\ket{p q}^+\)</span> — symmetrized state (Sec. <a href="many-body-theory.html#sec:symmetrization">6.1.2</a>)</li>
<li><span class="math inline">\(\ket{p q}^- = \ket{p q}\)</span> — antisymmetrized state (Sec. <a href="many-body-theory.html#sec:symmetrization">6.1.2</a>)</li>
<li><span class="math inline">\(\ket{\varnothing}\)</span> — physical vacuum state (Sec. <a href="many-body-theory.html#sec:prod-state">6.1.1</a>)</li>
<li><span class="math inline">\(\ket{\Phi}\)</span> — reference state (Sec. <a href="many-body-theory.html#sec:ph-formalism">6.4</a>)</li>
<li><span class="math inline">\(\hat{a}_p\)</span> — physical annihilation operator (Sec. <a href="many-body-theory.html#sec:second-quantization">6.2</a>)</li>
<li><span class="math inline">\(\hat{b}_p\)</span> — quasiparticle annihilation operator (Sec. <a href="many-body-theory.html#sec:ph-formalism">6.4</a>)</li>
<li><span class="math inline">\(\symm^\pm\)</span>, <span class="math inline">\(\symm^{(i)}\)</span>, <span class="math inline">\(\symm\)</span>, <span class="math inline">\(\antisymm\)</span> — symmetrization/antisymmetrization symbols (Sec. <a href="many-body-theory.html#sec:symmetrization">6.1.2</a>)</li>
<li><span class="math inline">\(\sum_{i j \backslash a b}\)</span> — summation over holes and particles (Eq. <a href="many-body-theory.html#eq:ph-summation">3</a>)</li>
<li><span class="math inline">\(\prod_{k = m}^{\to n}\)</span> — ordered product from left (<span class="math inline">\(k = m\)</span>) to right (<span class="math inline">\(k = n\)</span>)</li>
<li><span class="math inline">\(M_j = \{-j, -j + 1, \ldots, j - 1, j\}\)</span> — projection quantum numbers of a multiplet (Eq. <a href="angular-momentum-coupling.html#eq:mset">13</a>)</li>
<li><span class="math inline">\(\jweight{j}_a = \sqrt{2 j_a + 1}\)</span> — (Eq. <a href="angular-momentum-coupling.html#eq:jweight">17</a>)</li>
<li><span class="math inline">\(\check{a}\)</span> — time-reversed angular momentum (Eq. <a href="angular-momentum-coupling.html#eq:arrow-diagram">24</a>)</li>
<li><span class="math inline">\(\begin{pmatrix} j \\ m \quad m&#39; \end{pmatrix}\)</span> — Herring–Wigner 1-jm symbol (Eq. <a href="angular-momentum-coupling.html#eq:arrow">25</a>)</li>
<li><span class="math inline">\(\bkt{a \| \hat{Q} \| b}\)</span> — reduced matrix element (Sec. <a href="angular-momentum-coupling.html#sec:wigner-eckart">8.6</a>)</li>
<li><span class="math inline">\(\bkt{a, b | ab} = \bkt{j_a m_a j_b m_b | j_{a b} m_{a b}}\)</span> — Clebsch–Gordan coefficient (Sec. <a href="angular-momentum-coupling.html#sec:clebschgordan">8.2</a>)</li>
<li><span class="math inline">\((a b c) = \begin{pmatrix} j_a &amp; j_b &amp; j_c \\ m_a &amp; m_b &amp; m_c \end{pmatrix}\)</span> — Wigner 3-jm symbol (Sec. <a href="angular-momentum-coupling.html#sec:3jm">8.3</a>)</li>
<li><span class="math inline">\(\tridelta{j_a}{j_b}{j_c}\)</span> — triangular delta (Sec. <a href="angular-momentum-coupling.html#sec:tridelta">8.8.1</a>)</li>
<li><span class="math inline">\(\begin{Bmatrix} j_a &amp; j_b &amp; j_c \\ j_d &amp; j_e &amp; j_f \end{Bmatrix}\)</span> — Wigner 6-j symbol (Sec. <a href="angular-momentum-coupling.html#sec:6j">8.8.2</a>)</li>
<li><span class="math inline">\(\begin{Bmatrix} j_a &amp; j_b &amp; j_c \\ j_d &amp; j_e &amp; j_f \\ j_g &amp; j_h &amp; j_i \end{Bmatrix}\)</span> — Wigner 9-j symbol (Sec. <a href="angular-momentum-coupling.html#sec:9j">8.8.3</a>)</li>
</ul>
<h1 id="introduction"><span class="header-section-number">5</span> Introduction</h1>
<p>Quantum many-body theory is a broad discipline concerned with the behavior of quantum particles in large numbers. It is of critical relevance in many fields ranging from nuclear physics, through quantum chemistry, to condensed matter theory.</p>
<p>The fundamental challenge of quantum many-body theory lies in the difficulty of obtaining accurate results for fermionic systems in an efficient manner, owing to the combinatoric growth of the many-body Hilbert space as the number of particles increases. Certain methods such as full configuration interaction (FCI) theory <span class="citation" data-cites="shavitt2009many">(Shavitt and Bartlett 2009)</span> can achieve arbitrarily accurate results, but their cost scales factorially with respect to the basis size and the number of particles, rendering them infeasible for all but the smallest systems. In contrast, methods that scale polynomially must necessarily make certain approximations. This has led to a menagerie of many-body methods that trade varying amounts of accuracy for computational efficiency.</p>
<p>Nuclear science is an area where many-body theory has made substantial breakthroughs over the recent decades. For a long time, theories for nuclear physics have been largely limited to phenomenological methods such as density-functional theories and the nuclear shell model <span class="citation" data-cites="doi:10.1146/annurev.ns.38.120188.000333">(Brown and Wildenthal 1988)</span>, which often have limited predictive power beyond the domain in which the parameters were fit.</p>
<p>With advances in experimental technology such as the Facility for Rare Isotope Beams (FRIB) <span class="citation" data-cites="THOENNESSEN2010688c">(Thoennessen 2010)</span>, there is a growing demand for more accurate nuclear calculations and wider coverage of the nuclear chart, both of closed-shell and open-shell nuclei, and of stable and exotic ones. The needs of nuclear astrophysics should also not be understated: accurate models of nuclear systems are critical to the understanding of dense stars and supernovae. Many-body theory is also needed to calculate the rates of processes such as the neutrinoless double-beta decay, which has fundamental relevance in particle physics: whether neutrinos are Majorana fermions or not. Hence, the development of many-body theory is an essential step toward these many goals.</p>
<p>The recent introduction of chiral effective-field theory (EFT) <span class="citation" data-cites="MACHLEIDT20111">(Machleidt and Entem 2011)</span> and methods based on renormalization group (RG) theory <span class="citation" data-cites="RevModPhys.55.583 WEINBERG1979327 Lepage2005">(Wilson 1983; Weinberg 1979; Lepage 2005)</span> have dramatically changed the landscape of nuclear theory. Although the derivation of nuclear interactions from quantum chromodynamics (QCD) has not yet been achieved, there has been great progress through lattice QCD approaches <span class="citation" data-cites="Hoelbling2014 Ukawa2015 PhysRevLett.99.022001 ISHII2012437 Iritani2016">(Hoelbling 2014; Ukawa 2015; Ishii, Aoki, and Hatsuda 2007; Ishii et al. 2012; Iritani et al. 2016)</span>. At the moment, chiral EFT offers an intermediate, practical solution in which the symmetries of QCD are used to construct an ansatz of the nuclear interaction in a highly systematic way <span class="citation" data-cites="RevModPhys.81.1773">(Epelbaum, Hammer, and Meißner 2009)</span>. The development of RG theory and methods have allowed the creation of <em>soft</em> interactions that are unitarily equivalent to the original <span class="citation" data-cites="PhysRevC.75.061001">(Bogner, Furnstahl, and Perry 2007)</span>. Such interactions converge much more rapidly with respect to basis size, thereby reducing the cost of computations. The increasing availability of computing power has also played a role in amplifying the progress of nuclear many-body theory.</p>
<figure>
<img src="fig-nuclear-chart" alt="Figure 1: Nuclear chart showing the current progress of ab initio nuclear structure. Image courtesy of Heiko Hergert (Hergert et al. 2016)." id="fig:nuclear-chart" style="width:76.0%" /><figcaption>Figure 1: Nuclear chart showing the current progress of <em>ab initio</em> nuclear structure. Image courtesy of Heiko Hergert <span class="citation" data-cites="Hergert2016165">(Hergert et al. 2016)</span>.</figcaption>
</figure>
<p>The fruits of this progress can be seen in Fig. <a href="print.html#fig:nuclear-chart">1</a>. Just a decade ago, only a handful of nuclei near or below oxygen-16 could be computed by <em>ab initio</em> methods, as shown by the blue squares in the upper chart. The idea of calculating a nucleus as heavy as tin-100 through an <em>ab initio</em> method would have been considered absurd.</p>
<p>One particular many-body theory, the so-called in-medium similarity renormalization group method (IM-SRG) <span class="citation" data-cites="Hergert2016165">(Hergert et al. 2016)</span>, has gained significant attention in nuclear theory of late. IM-SRG fuses the flow equation approach of similarity renormalization group (SRG) with the particle-hole operator formalism to reduce computational cost, providing a novel <em>ab initio</em> approach for solving the many-body problem. Over the years, IM-SRG has proven to be a highly flexible and adaptable method. It offers efficient evaluation of observables beyond energy <span class="citation" data-cites="PhysRevC.92.034331 morris2016thesis">(Morris, Parzuchowski, and Bogner 2015; Morris 2016)</span>, the ability to tackle excited states <span class="citation" data-cites="PhysRevC.95.044304 parzuchowski2017thesis">(Parzuchowski, Morris, and Bogner 2017; N. M. Parzuchowski 2017)</span>, as well as extensions to open-shell nuclei <span class="citation" data-cites="HeikoReview">(Hergert 2017)</span>.</p>
<p>Unlike coupled-cluster (CC) theory, IM-SRG theory is naturally Hermitian, making it straightforward to utilize its matrix elements as an effective operator for other methods such as the nuclear shell model <span class="citation" data-cites="PhysRevLett.113.142501 PhysRevC.93.051301 PhysRevLett.118.032502">(Bogner et al. 2014; Stroberg et al. 2016, 2017)</span>. The renormalizing nature of IM-SRG eliminates many of the couplings between components of the many-body operator, simplifying post-IM-SRG calculations.</p>
<p>In our work, we take advantage of the softening property of IM-SRG to compute single-particle energies (addition and removal energies) via quasidegenerate perturbation theory (QDPT) to third order, also known as open-shell perturbation theory. Our expectation is that the use of IM-SRG ought to improve the overall quality and convergence of the perturbative results.</p>
<p>Compared to more sophisticated approaches such as the equations-of-motions method (EOM), QDPT at third order (QDPT3) is remarkably inexpensive. The ability to cheaply solve systems that are one particle away from a closed shell system can be remarkably useful in practice. Not only does it expand the scope of applicability of closed-shell IM-SRG, it can even permit access to excited states under certain circumstances.</p>
<h2 id="contributions"><span class="header-section-number">5.1</span> Contributions</h2>
<p>Our main contributions in this work are:</p>
<ul>
<li>We have created a graphical tool for performing equality-preserving transformations of angular momentum diagrams <span class="citation" data-cites="Jucys">(“Jucys,” n.d.)</span>. The diagrammatic formalism we use extends the work of <span class="citation" data-cites="Yutsis1962">(Yutsis, Levinson, and Vanagas 1962)</span>.</li>
<li>We have developed an open-source J-scheme codebase with an easy-to-use, flexible, and extensible framework for many-body calculations <span class="citation" data-cites="Lutario">(Yuan, n.d.)</span>. With this framework, we have implemented the Hartree–Fock (HF) method, Møller–Plesset perturbation theory at second order (MP2), IM-SRG method with two-body operators (IM-SRG(2)), and QDPT3. Our program supports several quantum systems, including circular quantum dots, homogeneous electron gas, infinite matter, and nuclei.</li>
<li>We have performed calculations of the quantum dot ground state and single-particle energies using HF, IM-SRG(2), and QDPT3 <span class="citation" data-cites="doi:10.1063/1.4995615">(Yuan et al. 2017)</span>, benchmarked against similar calculations using EOM and CCSD. The results have been analyzed and extrapolated to the infinite basis limit.</li>
<li>We have performed calculations of nuclear ground state and single-particle energies using HF, IM-SRG(2), and QDPT3, benchmarked against similar calculations using EOM and CCSD. We discuss the results and some preliminary analysis in this work.</li>
</ul>
<h2 id="outline"><span class="header-section-number">5.2</span> Outline</h2>
<p>The remainder of this thesis is structured as follows:</p>
<ul>
<li>We begin with a review of the many-body formalism in chapter 2. The primary purpose of this section is to establish the background theory, terminology, and notational conventions used in this work, as the field of many-body theory tends to be plagued by differences in nomenclature and notation.</li>
<li>In chapter 3, we discuss the details of angular momentum coupling. This forms a critical part of our J-scheme machinery, needed for efficient nuclear calculations. We also discuss angular momentum diagrams, which are an effective tool for manipulation of angular momentum expressions, as well as the <code>jucys</code> software that we have developed to aid simplification of such diagrams.</li>
<li>In chapter 4, we discuss each of the three major many-body methods that we use in our thesis: Hartree–Fock, IM-SRG, and QDPT. We explain and show all the critical equations that are needed to implement them.</li>
<li>In chapter 5, we discuss the theoretical background for the main quantum systems that we have chosen to study and analyze: circular quantum dots and nuclei.</li>
<li>In chapter 6, we provide an overview of our concrete implementation of many-body methods and the quantum systems. We offer explanations, rationale, and discussion of various choices that we have made throughout the evolution of the project.</li>
<li>In the penultimate chapter 7, we discuss the numerical results obtained from our codes, and compare them with results of collaborators. We perform analysis and also extrapolation of our results.</li>
<li>Finally, we conclude in chapter 8 with a review of our main results and perspectives for the future.</li>
</ul>
<p>An online version of this thesis is available<a href="print.html#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> along with any fixes to errors discovered after publication. Issues may be reported through the website. The version of this document is <code>r44-g58051a3</code>.</p>
<h1 id="many-body-formalism"><span class="header-section-number">6</span> Many-body formalism</h1>
<p>In this section we review the fundamentals of many-body theory. While we have aimed to make the presentation fairly pedagogical, the primary goal of this chapter is to define the concepts, terminology, notation, and conventions used throughout this work.</p>
<h2 id="many-particle-states"><span class="header-section-number">6.1</span> Many-particle states</h2>
<p>In single-particle time-independent quantum mechanics, the Schrödinger equation takes the following form in Dirac notation, <span class="math display">\[\hat{h} \ket{\psi} = \varepsilon \ket{\psi}\]</span> where</p>
<ul>
<li><span class="math inline">\(\hat{h}\)</span> is the single-particle Hamiltonian operator,</li>
<li><span class="math inline">\(\ket{\psi}\)</span> is a state vector, and</li>
<li><span class="math inline">\(\varepsilon\)</span> is the energy of the state.</li>
</ul>
<p>The state <span class="math inline">\(\ket{\psi}\)</span> is an abstract ket vector that lives in the Hilbert space <span class="math inline">\(\mathbb{H}\)</span> of the single-particle system. More concretely, we can also represent the state vector by a wave function <span class="math inline">\(\psi\)</span> <span class="math display">\[\ket{\psi} \leftrightarrow \psi(x)\]</span> where <span class="math inline">\(x\)</span> stands for all degrees of freedom of the particle. For example, an electron with spin in three-dimensional space would have <span class="math inline">\(x = (r_1, r_2, r_3, m_{\mathrm{s}})\)</span>, where <span class="math inline">\((r_1, r_2, r_3)\)</span> are the three spatial coordinates and <span class="math inline">\(m_{\mathrm{s}}\)</span> is the spin projection quantum number.</p>
<p>To treat systems of multiple particles, one may add additional variables to the wave function to represent the degrees of freedom of the additional particles, that is, <span class="math display">\[\ket{\Psi} \leftrightarrow \Psi(x_1, \ldots, x_N)\]</span> where</p>
<ul>
<li><span class="math inline">\(\ket{\Psi}\)</span> is an <span class="math inline">\(N\)</span>-particle state,</li>
<li><span class="math inline">\(\Psi\)</span> is its corresponding wave function,</li>
<li><span class="math inline">\(N\)</span> is the number of particles, and</li>
<li><span class="math inline">\(x_\alpha\)</span> represents the degrees of freedom of the <span class="math inline">\(\alpha\)</span>-th particle.</li>
</ul>
<p>With more than one particle, the Schrödinger equation remains conceptually the same, <span class="math display">\[\hat{H} \ket{\Psi} = E \ket{\Psi}\]</span> but there are many more degrees of freedom and thus more variables. Here, <span class="math inline">\(\hat{H}\)</span> is the <span class="math inline">\(N\)</span>-particle Hamiltonian operator and <span class="math inline">\(E\)</span> is the energy of the <span class="math inline">\(N\)</span>-particle state.</p>
<h3 id="sec:prod-state"><span class="header-section-number">6.1.1</span> Product states</h3>
<p>The simplest multi-particle system that can be solved is that of a non-interacting Hamiltonian of <span class="math inline">\(N\)</span> homogeneous particles, <span class="math display">\[\hat{H}_N^\circ = \sum_{\alpha = 1}^N \hat{h}(\hat{x}_\alpha, \hat{k}_\alpha)\]</span> where <span class="math inline">\(\hat{h}(\hat{x}_\alpha, \hat{k}_\alpha)\)</span> is some single-particle Hamiltonian with position <span class="math inline">\(\hat{x}_\alpha\)</span> and momentum<a href="print.html#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> <span class="math inline">\(\hat{k}_\alpha = -\I \hat{\nabla}_\alpha\)</span> of the <span class="math inline">\(\alpha\)</span>-th particle. We assume its single-particle Schrödinger equation has a known set of solutions, <span class="math display">\[\hat{h}(\hat{x}, \hat{k}) \ket{p} = \varepsilon_p \ket{p}\]</span> These solutions form a set of <strong>single-particle basis states</strong> for the single-particle Hilbert space <span class="math inline">\(\mathbb{H}\)</span>, <span class="math display">\[\ket{p} \leftrightarrow \varphi_p(x)\]</span> each with energy <span class="math inline">\(\varepsilon_p\)</span> and labeled by the quantum numbers <span class="math inline">\(p\)</span>. For example, if <span class="math inline">\(\hat{h}\)</span> is a single-electron atomic system, then we can choose <span class="math inline">\(p = (n, l, m_\ell, m_{\mathrm{s}})\)</span>, which are the four conventional quantum numbers for atomic orbitals. The single-particle basis states <span class="math inline">\(\ket{p}\)</span> would simply be the standard atomic orbital states.</p>
<p>From the single-particle basis, we can define a set of <span class="math inline">\(N\)</span>-particle wave functions <span class="math display">\[\ket{p_1 \otimes \cdots \otimes p_N} \leftrightarrow \Phi_{p_1 \otimes \cdots \otimes p_N}(x_1, \ldots, x_N)\]</span> via the tensor product construction<a href="print.html#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> <span class="math display">\[\begin{gather*}
  \ket{p_1 \otimes p_2} = \ket{p_1} \otimes \ket{p_2} \\
  \ket{p_1 \otimes p_2 \otimes p_3} = \ket{p_1} \otimes \ket{p_2} \otimes \ket{p_3} \\
  \ket{p_1 \otimes \cdots \otimes p_N} = \bigotimes_{\alpha = 1}^N \ket{p_\alpha}
\end{gather*}\]</span> In terms of wave functions, this is equivalent to the definition <span class="math display">\[\begin{gather*}
  \Phi_{p_1 \otimes p_2}(x_1, x_2) = \varphi_{p_1}(x_1) \varphi_{p_2}(x_2) \\
  \Phi_{p_1 \otimes p_2 \otimes p_3}(x_1, x_2, x_3) = \varphi_{p_1}(x_1) \varphi_{p_2}(x_2) \varphi_{p_3}(x_3) \\
  \Phi_{p_1 \otimes \cdots \otimes p_N}(x_1, \ldots, x_N) = \prod_{\alpha = 1}^N \varphi_{p_\alpha}(x_\alpha)
\end{gather*}\]</span> These <strong>product states</strong> (also known as <strong>Hartree products</strong>) are eigenstates of the many-body Schrödinger equation and form an orthonormal basis for the <span class="math inline">\(N\)</span>-particle Hilbert space <span class="math inline">\(\mathbb{H}^N\)</span> of the non-interacting <span class="math inline">\(N\)</span>-particle Hamiltonian <span class="math inline">\(\hat{H}_N^\circ\)</span>.</p>
<p>Formally, <span class="math inline">\(\mathbb{H}^N\)</span> is defined as the <span class="math inline">\(N\)</span>-th tensor power of the single-particle vector spaces<a href="print.html#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> <span class="math display">\[\mathbb{H}^N = \bigotimes_{\alpha = 1}^N \mathbb{H}\]</span> Each product state is labeled by the tuple <span class="math inline">\((p_1, \ldots, p_N)\)</span> and has the following energy in this non-interacting system: <span class="math display">\[E^\circ_{p_1 \otimes \ldots \otimes p_N} = \sum_{\alpha = 1}^N \varepsilon_{p_\alpha}\]</span> If we consider the special case <span class="math inline">\(N = 0\)</span>, a system with no particles, we find that the tensor product Hilbert space <span class="math inline">\(\mathbb{H}^0\)</span> has precisely one basis state,<a href="print.html#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> which we call the <strong>(physical) vacuum state</strong> <span class="math inline">\(\ket{\varnothing}\)</span>.</p>
<p>Although the product states form a basis, they span both states in which particles are distinguishable as well as states in which particles are not distinguishable. Thus, unconstrained use of product states would violate the key principle of quantum mechanics that particles are indistinguishable.</p>
<p>Mathematically, indistinguishability means that, under particle exchange, the wave function may only differ by a phase factor <span class="math inline">\(s\)</span>. Consider, say, the exchange of a two-particle wave function <span class="math inline">\(\Psi\)</span>, <span class="math display">\[\Psi(x_2, x_1) = \pm\Psi(x_1, x_2)\]</span></p>
<ul>
<li>For bosons, the phase factor <span class="math inline">\(s = +1\)</span>. This means the state is symmetric under particle exchange.</li>
<li>For fermions, the phase factor <span class="math inline">\(s = -1\)</span>. This means the state is antisymmetric under exchange.</li>
</ul>
<p>To extract the relevant states, we need to either symmetrize or antisymmetrize the product states.</p>
<h3 id="sec:symmetrization"><span class="header-section-number">6.1.2</span> Symmetrization and antisymmetrization</h3>
<p>A mathematical object <span class="math inline">\(X_{a b}\)</span> is said to be <strong><span class="math inline">\(\pm\)</span>-symmetric</strong> in the variables <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> if <span class="math display">\[X_{a b} = \pm X_{b a}\]</span> Note that:</p>
<ul>
<li><em><span class="math inline">\(+\)</span>-symmetric</em> is more commonly known as <em>symmetric</em> (without any qualification).</li>
<li><em><span class="math inline">\(-\)</span>-symmetric</em> is more commonly known as <em>antisymmetric</em> or <em>skew-symmetric</em>.</li>
</ul>
<p>Objects with more than two variables may be <span class="math inline">\(\pm\)</span>-symmetric in many combinations of variables. In particular, if it is <span class="math inline">\(\pm\)</span>-symmetric for every pair of variables in <span class="math inline">\(a_1 \ldots a_n\)</span>, then it is said to be <strong>fully <span class="math inline">\(\pm\)</span>-symmetric</strong> in <span class="math inline">\(a_1 \ldots a_n\)</span>.</p>
<p>If an object is not fully <span class="math inline">\(\pm\)</span>-symmetric, we can make it so using the <strong><span class="math inline">\(\pm\)</span>-symmetrization symbol</strong> <span class="math inline">\(\symm^\pm\)</span>, defined as <span class="math display">\[\begin{gather*}
  \symm^\pm_\varnothing X = X \\
  \symm^\pm_a X_a = X_a \\
  \symm^\pm_{a b} X_{a b} = \frac{1}{2} (X_{a b} \pm X_{b a}) \\
  \symm^\pm_{a b c} X_{a b c} = \frac{1}{6} (X_{a b c} \pm X_{b a c} + X_{b c a} \pm X_{c b a} + X_{c a b} \pm X_{a c b}) \\
  \symm^\pm_{a_1 \ldots a_n} X_{a_1 \ldots a_n} = \frac{1}{N!} \sum_{\sigma \in S_n} (\pm)^\sigma X_{\sigma(a_1 \ldots a_n)}
\end{gather*}\]</span> where</p>
<ul>
<li><span class="math inline">\(X_{a_1 \ldots a_n}\)</span> is an arbitrary formula with free variables <span class="math inline">\(a_1, \ldots, a_n\)</span>,</li>
<li><span class="math inline">\(S_n\)</span> is the symmetric group, which contains all possible permutations of <span class="math inline">\(n\)</span> objects,</li>
<li><span class="math inline">\((-)^\sigma = \operatorname{sgn}(\sigma)\)</span>, i.e. the sign of the permutation <span class="math inline">\(\sigma\)</span>,</li>
<li><span class="math inline">\((+)^\sigma = 1\)</span>, and</li>
<li><span class="math inline">\(\sigma(a_1 \ldots a_n)\)</span> applies the permutation <span class="math inline">\(\sigma\)</span> to the sequence of indices <span class="math inline">\(a_1 \ldots a_n\)</span>.</li>
</ul>
<p>We will often use the abbreviations <span class="math inline">\(\symm = \symm^+\)</span> and <span class="math inline">\(\antisymm = \symm^-\)</span>. We will also sometimes use the shorthand <span class="math display">\[\symm^{(i)} = \symm^{(-)^i} = \begin{cases}
  \symm^+ &amp; \text{if } i \text{ is even} \\
  \symm^- &amp; \text{if } i \text{ is odd} \\
\end{cases}\]</span></p>
<p>Note that the <span class="math inline">\(\pm\)</span>-symmetrization symbol <span class="math inline">\(\symm^\pm\)</span> is merely a notational shorthand, much like the summation symbol <span class="math inline">\(\sum\)</span>. It is not a quantum operator, but we can use it to define one. Let us introduce the <strong><span class="math inline">\(N\)</span>-particle <span class="math inline">\(\pm\)</span>-symmetrizer</strong> <span class="math inline">\(\hat{S}^\pm_N\)</span>, an operator defined as<a href="print.html#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> <span class="math display">\[\begin{gather*}
  \hat{S}^\pm_0 \ket{\varnothing} = \ket{\varnothing} \\
  \hat{S}^\pm_1 \ket{p} = \ket{p} \\
  \hat{S}^\pm_2 \ket{p_1 \otimes p_2} = \frac{\ket{p_1 \otimes p_2} \pm \ket{p_2 \otimes p_1}}{2} \\
  \hat{S}^\pm_3 \ket{p_1 \otimes p_2 \otimes p_3} = \frac{\ket{p_1 \otimes p_2 \otimes p_3} \pm \ket{p_2 \otimes p_1 \otimes p_3} + \ket{p_2 \otimes p_3 \otimes p_1} \pm \cdots}{6} \\
  \hat{S}^\pm_N \ket{p_1 \otimes \cdots \otimes p_N} = \symm^\pm_{p_1 \ldots p_N} \ket{p_1 \otimes \cdots \otimes p_N}
\end{gather*}\]</span> Despite the involvement of a specific single-particle basis <span class="math inline">\(\ket{p}\)</span> in the definition of <span class="math inline">\(\hat{S}^\pm_N\)</span>, one can show that the operator is actually independent of the basis choice.</p>
<p>The <span class="math inline">\(\hat{S}^\pm_N\)</span> operator is idempotent and therefore a projection operator. It projects the <span class="math inline">\(N\)</span>-particle Hilbert space <span class="math inline">\(\mathbb{H}^N\)</span> to the <span class="math inline">\(\pm\)</span>-symmetric subspace of <span class="math inline">\(\mathbb{H}^N\)</span>. By abuse of notation, we will denote this subspace <span class="math inline">\(\hat{S}^\pm_N(\mathbb{H}^N)\)</span>.</p>
<p>We can now define <span class="math inline">\(N\)</span>-particle <strong><span class="math inline">\(\pm\)</span>-symmetrized states</strong> in terms of product states, <span class="math display">\[\begin{gather*}
  \ket{p_1 p_2}^\pm = \sqrt{\frac{2}{C_{p_1 p_2}}} \hat{S}^\pm_2 \ket{p_1 \otimes p_2} = \frac{\ket{p_1 \otimes p_2} \pm \ket{p_2 \otimes p_1}}{\sqrt{2 (1 + \delta_{p_1 p_2})}} \\
  \ket{p_1 p_2 p_3}^\pm = \sqrt{\frac{6}{C_{p_1 p_2 p_3}}} \hat{S}^\pm_3 \ket{p_1 \otimes p_2 \otimes p_3} \\
  \ket{p_1 \ldots p_N}^\pm = \sqrt{\frac{N!}{C_{p_1 \ldots p_N}}} \hat{S}^\pm_N \ket{p_1 \otimes \cdots \otimes p_N}
\end{gather*}\]</span> where <span class="math inline">\(\delta_{a b}\)</span> denotes the Kronecker delta, and <span id="eq:compensating-factor"><span class="math display">\[C_{p_1 \ldots p_N} = \prod_p n_p!\qquad(1)\]</span></span> is a factor that compensates for overcounting due to multiple particles occupying the same state. Here, <span class="math inline">\(n_p\)</span> is the <strong>occupation number</strong> of the single-particle state <span class="math inline">\(\ket{p}\)</span>, which counts the number of times that <span class="math inline">\(p\)</span> appears in the list <span class="math inline">\(p_1 \ldots p_N\)</span>. In the case of fermions, <span class="math inline">\(n_p\)</span> can never be more than one due to the Pauli exclusion principle, and so <span class="math inline">\(C_{p_1 \ldots p_N}\)</span> is always one.</p>
<p>Given a <span class="math inline">\(\pm\)</span>-symmetric state <span class="math inline">\(\ket{p_1 \ldots p_N}^\pm\)</span>, the particles are said to <strong>occupy</strong> the single-particle states <span class="math inline">\(\ket{p_1}, \ldots, \ket{p_N}\)</span>. Any remaining unused single-particle states are said to be <strong>unoccupied</strong>.</p>
<p>These states are solutions of the non-interacting Hamiltonian <span class="math inline">\(\hat{H}^\circ\)</span> and they form an orthonormal basis for the <span class="math inline">\(N\)</span>-particle <span class="math inline">\(\pm\)</span>-symmetric Hilbert space <span class="math inline">\(\hat{S}^\pm_N(\mathbb{H}^N)\)</span>. Symmetric states are associated with bosons, and antisymmetric states are associated with fermions. Notationally, we distinguish <span class="math inline">\(\pm\)</span>-symmetrized states from product states by the absence of the <span class="math inline">\(\otimes\)</span> symbol in the ket.</p>
<p>In the case of fermions, antisymmetrized states are also known as <strong>Slater determinants</strong>, because their wave functions <span class="math display">\[\ket{p_1 \ldots p_N}^- \leftrightarrow \Phi^-_{p_1 \ldots p_N}(x_1, \ldots, x_N)\]</span> can be written as a matrix determinant <span class="math display">\[\Phi^-_{p_1 \ldots p_N}(x_1, \ldots, x_N) =
  \frac{1}{\sqrt{N!}}
  \begin{vmatrix}
    \varphi_{p_1}(x_1) &amp; \cdots &amp; \varphi_{p_N}(x_1) \\
    \vdots &amp; \ddots &amp; \vdots \\
    \varphi_{p_1}(x_N) &amp; \cdots &amp; \varphi_{p_N}(x_N) \\
  \end{vmatrix}\]</span> Slater determinants are guaranteed to satisfy the Pauli exclusion principle. One cannot construct a state in which two particles share the same single-particle state as such states are always projected to zero by the antisymmetrizer.</p>
<h2 id="sec:second-quantization"><span class="header-section-number">6.2</span> Second quantization</h2>
<p>In everything we have discussed so far, the number of particles <span class="math inline">\(N\)</span> always appears as an explicit parameter. We will now shift toward the <strong>second quantization</strong> formalism, which avoids explicit mention of <span class="math inline">\(N\)</span> by treating all values of <span class="math inline">\(N\)</span> simultaneously. This offers significant simplifications to the mathematics at the cost of adding a new layer of abstraction. The prior formalism will henceforth be known as <strong>first quantization</strong>.</p>
<p>The first step is to direct sum all of the <span class="math inline">\(N\)</span>-particle <span class="math inline">\(\pm\)</span>-symmetric Hilbert spaces <span class="math inline">\(\hat{S}^\pm_N(\mathbb{H}^N)\)</span> into a unified space, through the so-called <strong>Fock space construction</strong>, <span class="math display">\[\mathbb{F}^\pm = \bigoplus_{N = 0}^\infty \hat{S}^\pm_N(\mathbb{H}^N) = \mathbb{H}^0 \oplus \mathbb{H} \oplus \hat{S}^\pm_2 (\mathbb{H} \otimes \mathbb{H}) \oplus \hat{S}^\pm_3(\mathbb{H} \otimes \mathbb{H} \otimes \mathbb{H}) \oplus \cdots\]</span> Here, <span class="math inline">\(\mathbb{F}^\pm\)</span> is the <strong><span class="math inline">\(\pm\)</span>-symmetric Fock space</strong>.</p>
<p>Next, we introduce a set of creation and annihilation operators, collectively known as the <strong>(physical) field operators</strong>, which serve to connect each <span class="math inline">\(N\)</span>-particle Hilbert space to an adjacent <span class="math inline">\(N \pm 1\)</span>-particle Hilbert space. The field operators are dependent on the choice of <span class="math inline">\(\pm\)</span>-symmetry but we opt to suppress this detail for clarity.</p>
<p>The <strong>annihilation operator</strong> for the single-particle state <span class="math inline">\(\ket{p}\)</span> is denoted <span class="math inline">\(\hat{a}_p\)</span> and has the effect of removing one of the particles that occupy the <span class="math inline">\(\ket{p}\)</span> state, <span class="math display">\[\hat{a}_p \ket{p p_1 \ldots p_N}^\pm = \sqrt{n_p} \ket{p_1 \ldots p_N}^\pm\]</span> where <span class="math inline">\(n_p\)</span> denotes the occupation number of <span class="math inline">\(\ket{p}\)</span> in <span class="math inline">\(\ket{p p_1 \ldots p_N}^\pm\)</span>, i.e. the number of occurrences of <span class="math inline">\(p\)</span> in <span class="math inline">\(p p_1 \ldots p_N\)</span>. In particular, if <span class="math inline">\(\ket{p}\)</span> is not occupied in a state <span class="math inline">\(\ket{\Phi}^\pm\)</span>, then the operator collapses it to zero, <span class="math display">\[\hat{a}_p \ket{\Phi}^\pm = 0\]</span></p>
<p>The <strong>creation operator</strong> for the single-particle state <span class="math inline">\(\ket{p}\)</span> is denoted <span class="math inline">\(\hat{a}_p^{\dagger}\)</span> and is the Hermitian adjoint of <span class="math inline">\(\hat{a}_p\)</span>. It has the effect of adding a new particle that occupies the <span class="math inline">\(\ket{p}\)</span> state, <span class="math display">\[\hat{a}_p^\dagger \ket{p_1 \ldots p_N}^\pm = \sqrt{1 \pm n_p} \ket{p p_1 \ldots p_N}^\pm\]</span> where <span class="math inline">\(n_p\)</span> denotes the occupation number of <span class="math inline">\(\ket{p}\)</span> in <span class="math inline">\(\ket{p_1 \ldots p_N}^\pm\)</span>. For fermions, if <span class="math inline">\(\ket{p}\)</span> is already occupied, then the operator collapses it to zero, <span class="math display">\[\hat{a}_p^\dagger \ket{p p_1 \ldots p_N}^- = 0\]</span></p>
<p>A <span class="math inline">\(\pm\)</span>-symmetric state can be constructed by a chain of creation operators applied to the vacuum state <span class="math inline">\(\ket{\varnothing}\)</span>, <span class="math display">\[\ket{p_1 \ldots p_N} = \frac{\hat{a}_{p_1}^\dagger \ldots \hat{a}_{p_N}^\dagger \ket{\varnothing}}{\sqrt{C_{p_1 \ldots p_N}}}\]</span> where <span class="math inline">\(C_{p_1 \ldots p_N}\)</span> is the compensating factor defined in Eq. <a href="print.html#eq:compensating-factor">1</a>. From the <span class="math inline">\(\pm\)</span>-symmetry of the the state, we obtain the commutation relations that define the essential behavior of field operators: <span class="math display">\[\begin{align*}
  [\hat{a}_{p_1}, \hat{a}_{p_2}^\dagger]_\mp &amp;= \delta_{p_1 p_2} &amp;
  [\hat{a}_{p_1}, \hat{a}_{p_2}]_\mp &amp;= [\hat{a}_{p_1}^\dagger, \hat{a}_{p_2}^\dagger]_\mp = 0
\end{align*}\]</span> where</p>
<ul>
<li><span class="math inline">\([\hat{X}, \hat{Y}]_- = [\hat{X}, \hat{Y}]\)</span> denotes the commutator, chosen for symmetric states, and</li>
<li><span class="math inline">\([\hat{X}, \hat{Y}]_+ = \{\hat{X}, \hat{Y}\}\)</span> denotes the anticommutator, chosen for antisymmetric states.</li>
</ul>
<h2 id="sec:many-body-oper"><span class="header-section-number">6.3</span> Many-body operators</h2>
<p>From this section onward, we will focus mainly on fermions, so all field operators will be anticommuting.</p>
<p>Given a set of <span class="math inline">\(N\)</span>-particle operators <span class="math inline">\(\hat{Q}_N\)</span> acting on the <span class="math inline">\(N\)</span>-particle Hilbert space, we can direct sum all of them to form a particle-number-agnostic operator <span class="math inline">\(\hat{Q}\)</span> that acts on the entire Fock space, <span class="math display">\[\hat{Q} = \bigoplus_{N = 0}^\infty \hat{Q}_N\]</span> This can be applied to any operator from first quantization, including the <span class="math inline">\(\pm\)</span>-symmetrizer <span class="math inline">\(\hat{S}^\pm_N \mapsto \hat{S}^\pm\)</span> and the Hamiltonian <span class="math inline">\(\hat{H}_N \mapsto \hat{H}\)</span>.</p>
<p>Many-body operators are classified by <strong>rank</strong>, which determines the maximum number of particles that the operator can couple at any given instant. A rank-<span class="math inline">\(k\)</span> operator is more conventionally known as a <strong><span class="math inline">\(k\)</span>-body operator</strong>.</p>
<h3 id="zero-body-operators"><span class="header-section-number">6.3.1</span> Zero-body operators</h3>
<p>The most trivial kind of operator are <strong>zero-body operators</strong>, which multiplies a state by a number. Formally, we can write a zero-body operator <span class="math inline">\(\hat{Z}\)</span> in the form <span class="math display">\[\hat{Z} = Z \hat{1}\]</span> where <span class="math inline">\(Z\)</span> a complex number and <span class="math inline">\(\hat{1}\)</span> is the identity operator, but for simplicity, it suffices to call <span class="math inline">\(Z\)</span> itself the “operator” as the distinction between <span class="math inline">\(\hat{Z}\)</span> and <span class="math inline">\(Z\)</span> is largely irrelevant. The value of <span class="math inline">\(Z\)</span> can be inferred from its expectation value in the vacuum state, <span class="math display">\[Z = \bra{\varnothing} Z \ket{\varnothing}\]</span> although its expectation value in any state will still yield the same result. They do not contribute anything if the bra and ket states differ.</p>
<h3 id="one-body-operators"><span class="header-section-number">6.3.2</span> One-body operators</h3>
<p>The next simplest kind of operator are <strong>one-body operators</strong>, which are of the form <span class="math display">\[\hat{T} = \sum_{p q} T_{p q} \hat{a}_p^\dagger \hat{a}_q\]</span> where <span class="math inline">\(T_{p q}\)</span> defines a matrix of complex numbers indexed by <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span>, known as the <strong>matrix elements</strong> of <span class="math inline">\(\hat{T}\)</span>. In first quantization, one-body operators are of the form, <span class="math display">\[\hat{T}_N = \sum_{\alpha = 1}^N \hat{t}(\hat{x}_\alpha, \hat{k}_\alpha)\]</span> Kinetic energy and external potentials are examples of such operators. The matrix elements of such operators may be obtained via the integral, <span class="math display">\[T_{p q} = \bra{p} \hat{T} \ket{q} = \int \varphi_p^*(x) \hat{t} \varphi_q(x) \D x\]</span> One-body operators have two notable properties:</p>
<ul>
<li>Their expectation value in the vacuum state is zero: <span class="math display">\[\bra{\varnothing} \hat{T} \ket{\varnothing} = 0\]</span></li>
<li>They do not contribute if the bra and ket states differ in more than one single-particle state. That is, unless the set intersection <span class="math inline">\(\{p_1, \ldots, p_N\} \cap \{q_1, \ldots, q_N\}\)</span> has at least <span class="math inline">\(N - 1\)</span> elements, then <span class="math display">\[\bra{p_1 \cdots p_N} \hat{T} \ket{q_1 \cdots q_N} = 0\]</span></li>
</ul>
<h3 id="two-body-operators"><span class="header-section-number">6.3.3</span> Two-body operators</h3>
<p><strong>Two-body operators</strong> take the form<a href="print.html#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> <span id="eq:two-body-operator"><span class="math display">\[\hat{V} = \frac{1}{4} \sum_{p q r s} V_{p q r s} \hat{a}_p^\dagger \hat{a}_q^\dagger \hat{a}_s \hat{a}_r = \frac{1}{4} \sum_{p q r s} V_{p q r s} \hat{a}_p^\dagger \hat{a}_r \hat{a}_q^\dagger \hat{a}_s\qquad(2)\]</span></span> where <span class="math inline">\(V_{p q r s}\)</span> denotes an <strong>antisymmetrized matrix element</strong> of <span class="math inline">\(\hat{V}\)</span>. Such matrix elements have the following symmetry properties, <span class="math display">\[V_{p q r s} = \antisymm_{p q} \antisymm_{r s} V_{p q r s} \quad \leftrightarrow \quad V_{p q r s} = -V_{q p r s} = V_{q p s r} = -V_{p q s r}\]</span> In first quantization, two-body operators are of the form, <span class="math display">\[\hat{V}_N = \frac{1}{2} \sum_{\alpha = 1}^N \sum_{\beta = 1}^N \hat{v}(\hat{x}_\alpha, \hat{x}_\beta, \hat{k}_\alpha, \hat{k}_\beta)\]</span> Interactions, such as the Coulomb interactions, are two-body (or higher) operators. The matrix elements of such operators may be obtained via <span class="math display">\[V_{p q r s} = \bra{p q} \hat{V} \ket{r s} = 2 \antisymm_{r s} V^\otimes_{p q r s}\]</span> where <span class="math display">\[V^\otimes_{p q r s} = \bra{p \otimes q} \hat{V} \ket{r \otimes s} = \iint \varphi_p^*(x_1) \varphi_q^*(x_2) \hat{v} \varphi_r(x_1) \varphi_s(x_2) \D x_1 \D x_2\]</span> are the <strong>non-antisymmetrized matrix elements</strong> of <span class="math inline">\(\hat{V}\)</span>, which may considered matrix elements in the product state basis. These matrix elements have a weaker symmetry, <span class="math display">\[V^\otimes_{p q r s} = \symm_{(p, r) (q, s)} V^\otimes_{p q r s}\]</span> In other words, <span class="math inline">\(V^\otimes_{p q r s} = V^\otimes_{q p s r}\)</span>. This arises from the indistinguishability of particles.</p>
<p>Two-body operators have two notable properties:</p>
<ul>
<li>Matrix elements of states with one or fewer particles vanish: <span class="math display">\[\begin{align*}
  \bra{\varnothing} \hat{V} \ket{\varnothing} &amp;= 0 &amp;
  \bra{p} \hat{V} \ket{q} &amp;= 0
\end{align*}\]</span></li>
<li>They do not contribute if the bra and ket states differ in more than two single-particle states. That is, unless the set intersection <span class="math inline">\(\{p_1, \ldots, p_N\} \cap \{q_1, \ldots, q_N\}\)</span> has at least <span class="math inline">\(N - 2\)</span> elements, then <span class="math display">\[\bra{p_1 \cdots p_N} \hat{V} \ket{q_1 \cdots q_N} = 0\]</span></li>
</ul>
<h3 id="three-body-operators-and-beyond"><span class="header-section-number">6.3.4</span> Three-body operators and beyond</h3>
<p>Three-body and, more generally, <span class="math inline">\(k\)</span>-body operators take the form<a href="print.html#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> <span class="math display">\[\begin{gather*}
  \hat{W} = \frac{1}{36} \sum_{p q r s t u} W_{p q r s t u} \hat{a}_p^\dagger \hat{a}_q^\dagger \hat{a}_r^\dagger \hat{a}_u \hat{a}_t \hat{a}_s = \frac{1}{36} \sum_{p q r s t u} W_{p q r s t u} \hat{a}_p^\dagger \hat{a}_s \hat{a}_q^\dagger \hat{a}_t \hat{a}_r^\dagger \hat{a}_u \\
  \begin{aligned}
    \hat{X}
    &amp;= \frac{1}{k!^2} \sum_{p_1 \ldots p_k q_1 \ldots q_k} X_{p_1 \ldots p_k q_1 \ldots q_k} \hat{a}_{p_1}^\dagger \ldots \hat{a}_{p_k}^\dagger \hat{a}_{q_k} \ldots \hat{a}_{q_1} \\
    &amp;= \frac{1}{k!^2} \sum_{p_1 \ldots p_k q_1 \ldots q_k} X_{p_1 \ldots p_k q_1 \ldots q_k} (\hat{a}_{p_1}^\dagger \hat{a}_{q_1}) \ldots (\hat{a}_{p_k}^\dagger \hat{a}_{q_k})
  \end{aligned}
\end{gather*}\]</span> with non-antisymmetrized matrix elements <span class="math display">\[\begin{gather*}
  W^\otimes_{p q r s t u} = \langle p \otimes q \otimes r | \hat{W} | s \otimes t \otimes u \rangle \\
  X^\otimes_{p_1 \ldots p_k q_1 \ldots q_k} = \langle p_1 \otimes \cdots \otimes p_k | \hat{X} | q_1 \otimes \cdots \otimes q_k \rangle
\end{gather*}\]</span> and antisymmetrized matrix elements <span class="math display">\[\begin{gather*}
  W_{p q r s t u} = \langle p q r | \hat{W} | s t u \rangle = 6 \antisymm_{s t u}  W^\otimes_{p q r s t u} \\
  X_{p_1 \ldots p_k q_1 \ldots q_k} = \langle p_1 \ldots p_k | \hat{X} | q_1 \ldots q_k \rangle = k! \antisymm_{q_1 \ldots q_k}  X^\otimes_{p_1 \ldots p_k q_1 \ldots q_k}
\end{gather*}\]</span> and symmetries <span class="math display">\[\begin{gather*}
  W^\otimes_{p q r s t u} = \symm_{(p, s) (q, t) (r, u)} W^\otimes_{p q r s t u} \\
  X^\otimes_{p_1 \ldots p_k q_1 \ldots q_k} = \symm_{(p_1, q_1) \ldots (p_k, q_k)} X^\otimes_{p_1 \ldots p_k q_1 \ldots q_k} \\
  W_{p q r s t u} = \antisymm_{p q r} \antisymm_{s t u} W_{p q r s t u} \\
  X_{p_1 \ldots p_k q_1 \ldots q_k} = \antisymm_{p_1 \ldots p_k} \antisymm_{q_1 \ldots q_k} X_{p_1 \ldots p_k q_1 \ldots q_k}
\end{gather*}\]</span></p>
<p><span class="math inline">\(k\)</span>-body operators have two notable properties:</p>
<ul>
<li>Matrix elements of states with one or fewer particles vanish. That is, if <span class="math inline">\(m &lt; k\)</span>, then <span class="math display">\[\bra{p_1 \ldots p_m} \hat{X} \ket{q_1 \ldots q_m} = 0\]</span></li>
<li>They do not contribute if the bra and ket states differ in more than <span class="math inline">\(k\)</span> single-particle states. That is, unless the set intersection <span class="math inline">\(\{p_1, \ldots, p_N\} \cap \{q_1, \ldots, q_N\}\)</span> has at least <span class="math inline">\(N - k\)</span> elements, then <span class="math display">\[\bra{p_1 \cdots p_N} \hat{X} \ket{q_1 \cdots q_N} = 0\]</span></li>
</ul>
<h2 id="sec:ph-formalism"><span class="header-section-number">6.4</span> Particle-hole formalism</h2>
<p>Any state in Fock space can be described by a chain of creation operators applied to the vacuum state. In many-body systems, the number of particles can be quite large, leading to long chains of creation operators.</p>
<p>Instead of starting from scratch (i.e. vacuum state), it can be more convenient to start from a pre-existing <span class="math inline">\(N\)</span>-particle Slater determinant <span class="math inline">\(|\Phi\rangle\)</span>, called the <strong>reference state</strong>, <span class="math display">\[|\Phi\rangle = \hat{a}_{p_1}^\dagger \cdots \hat{a}_{p_N}^\dagger |\varnothing\rangle\]</span> Then, to access other states we would create and/or annihilate particles relative to the reference state. For example, <span class="math display">\[\hat{a}_p^\dagger \hat{a}_{p_1} |\Phi\rangle = \hat{a}_p^\dagger \hat{a}_{p_2}^\dagger \cdots \hat{a}_{p_N}^\dagger |\varnothing\rangle\]</span></p>
<p>In addition to simplifying the algebra, this also provides a coarse measure of “distance” from the reference state, quantified by the number of field operators applied to the reference state that is needed.</p>
<p>Formally, we can construct a set of <strong>quasiparticle (particle-hole) field operators</strong> <span class="math inline">\(\hat{b}_p^\dagger\)</span> and <span class="math inline">\(\hat{b}_p\)</span>, <span class="math display">\[\hat{b}_p = \begin{cases}
  \hat{a}_p &amp; \text{if $p$ is unoccupied in the reference state} \\
  \hat{a}_p^\dagger &amp; \text{if $p$ is occupied in the reference state}
\end{cases}\]</span> In this context, <span class="math inline">\(\hat{b}_p^\dagger\)</span> applied to an occupied state <span class="math inline">\(p\)</span> is said to <em>create</em> a <strong>hole state</strong>, whereas <span class="math inline">\(\hat{b}_p^\dagger\)</span> applied to an unoccupied state <span class="math inline">\(p\)</span> is said to create a <strong>particle state</strong>. These operators define the so-called <strong>particle-hole formalism</strong>.</p>
<p>The quasiparticle operators have an algebra analogous to the original field operators <span class="math inline">\(\hat{a}_p^\dagger\)</span> and <span class="math inline">\(\hat{a}_p\)</span>: <span class="math display">\[\begin{align*}
  \anticomm{\hat{b}_p, \hat{b}_q^\dagger} &amp;= \delta_{p q} &amp;
  \anticomm{\hat{b}_p, \hat{b}_q} = \anticomm{\hat{b}_p^\dagger, \hat{b}_q^\dagger} &amp;= 0 &amp;
  \hat{b}_p \ket{\Phi} = 0
\end{align*}\]</span> The quasiparticle field operators treat <span class="math inline">\(\ket{\Phi}\)</span> as their “vacuum” state, similar to how original field operators treat <span class="math inline">\(\ket{\varnothing}\)</span> as their vacuum state. For this reason, the reference state <span class="math inline">\(\ket{\Phi}\)</span> is also known as a <strong>Fermi vacuum</strong>.</p>
<p>So far, we have used the letters <span class="math inline">\(p\)</span>, <span class="math inline">\(q\)</span>, <span class="math inline">\(r\)</span>, … to label single-particle states, which contain both hole and particle states relative to the Fermi vacuum. We will continue to use this convention. It is often convenient to sum over only hole states, or only particle states. To this end, we introduce a convention where <span class="math inline">\(i\)</span>, <span class="math inline">\(j\)</span>, <span class="math inline">\(k\)</span>, … are used to label hole states and <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\(c\)</span>, … label particle states. We also introduce a special notation for <strong>summation over holes and particles</strong>: <span id="eq:ph-summation"><span class="math display">\[\sum_{i j k \ldots \backslash a b c \ldots} \cdots\qquad(3)\]</span></span> The backslash serves as an additional reminder that <span class="math inline">\(i\)</span>, <span class="math inline">\(j\)</span>, <span class="math inline">\(k\)</span>, … should be summed over hole states only, and <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\(c\)</span>, … should be summed over particle states only.</p>
<p>In this formalism, we use the following concise notation to denote states near the reference state, <span class="math display">\[\ket{\Phi_{a_1 \ldots a_k i_1 \ldots i_k}} = \hat{b}_{a_1}^\dagger \ldots \hat{b}_{a_k}^\dagger \hat{b}_{i_k}^\dagger \ldots \hat{b}_{i_1}^\dagger \ket{\Phi} = \hat{a}_{a_1}^\dagger \ldots \hat{a}_{a_k}^\dagger \hat{a}_{i_k} \ldots \hat{a}_{i_1} \ket{\Phi}\]</span> Note that although this state has <span class="math inline">\(2 k\)</span> quasi-particles, it still has exactly <span class="math inline">\(N\)</span> physical particles, because the particles and holes cancel out exactly. We also introduce a shorthand for its energy, <span class="math display">\[E_{\Phi_{a_1 \ldots a_k i_1 \ldots i_k}} = \bra{\Phi_{a_1 \ldots a_k i_1 \ldots i_k}} \hat{H} \ket{\Phi_{a_1 \ldots a_k i_1 \ldots i_k}}\]</span></p>
<h2 id="sec:normord"><span class="header-section-number">6.5</span> Normal ordering</h2>
<p>We say a product of field operators is in <strong>normal order</strong> if all creation operators appear before all annihilation operators.</p>
<p>More generally, we may define normal ordering to be an arbitrarily chosen total order subject to the constraint that if both <span class="math inline">\(\hat{\alpha} \hat{\beta}\)</span> and <span class="math inline">\(\hat{\beta} \hat{\alpha}\)</span> are normal ordered then <span class="math inline">\([\hat{\alpha}, \hat{\beta}]_\mp = 0\)</span>. But we will not need this general definition here. Wick’s theorem (introduced later) does hold in this general setting, though.</p>
<p>Given a monomial <span class="math inline">\(c \hat{\Pi}\)</span>, where <span class="math inline">\(c\)</span> is a numeric coefficient and <span class="math inline">\(\hat{\Pi}\)</span> is a product of field operators,<a href="print.html#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> we define its <strong>normal ordering</strong> as <span class="math display">\[\normord{c \hat{\Pi}} = (\pm)^\sigma c \, \sigma(\hat{\Pi})\]</span> where <span class="math inline">\(\sigma\)</span> is a permutation that rearranges the field operators in <span class="math inline">\(\hat{\Pi}\)</span> such that <span class="math inline">\(\sigma(\Pi)\)</span> is in normal order, and</p>
<ul>
<li>for bosons, <span class="math inline">\((+)^\sigma = +\)</span>;</li>
<li>for fermions, <span class="math inline">\((-)^\sigma\)</span> is the sign of the permutation <span class="math inline">\(\sigma\)</span>.</li>
</ul>
<p>Although the definition leaves the permutation underdetermined, the definition of normal order ensures that normal ordering will yield the same result no matter which permutation is chosen.</p>
<p>The operation is dependent on the choice of field operators. In this text, we have two choices:</p>
<ul>
<li>When normal ordering relative to the <em>physical vacuum</em>, the physical field operators <span class="math inline">\(\hat{a}_p^\dagger\)</span> and <span class="math inline">\(\hat{a}_p\)</span> are used.</li>
<li>When normal ordering relative to the <em>Fermi vacuum</em>, the quasiparticle field operators <span class="math inline">\(\hat{b}_p^\dagger\)</span> and <span class="math inline">\(\hat{b}_p\)</span> are used.</li>
</ul>
<p>We will typically work with normal ordering relative to the Fermi vacuum. For normal ordering relative to the physical vacuum, we use three dots instead of a colon: <span class="math display">\[\vnormord{c \hat{\Pi}}\]</span></p>
<p>Several notations exist for this operation: <span class="math display">\[\begin{align*}
  &amp;\normord{c \hat{\Pi}} &amp;
  &amp;\mathrm{N}[ c \hat{\Pi} ] &amp;
  &amp;\bigl\{ c \hat{\Pi} \bigr\}
\end{align*}\]</span> The colon notation is common in nuclear physics, <span class="citation" data-cites="PhysRevC.95.044304">(Parzuchowski, Morris, and Bogner 2017)</span> whereas delimiters prefixed with the letter “N” <span class="citation" data-cites="shavitt2009many">(Shavitt and Bartlett 2009)</span> or curly braces <span class="citation" data-cites="reimann2013quantum">(Reimann 2013)</span> are common in quantum chemistry.</p>
<p>As an example, consider the fermionic monomial <span class="math inline">\(-2 \hat{b}_p \hat{b}_q^\dagger\)</span> with coefficient <span class="math inline">\(c = -2\)</span> and operators <span class="math inline">\(\hat{\Pi} = \hat{b}_p \hat{b}_q^\dagger\)</span>. We can normal order it relative to the Fermi vacuum: <span class="math display">\[\normord{-2 \hat{b}_p \hat{b}_q^\dagger} = 2 \hat{b}_q^\dagger \hat{b}_p\]</span> Since this permutation has odd parity, the sign is flipped.</p>
<p>As another example, consider the fermionic monomial <span class="math inline">\(\hat{a}_p \hat{a}_q^\dagger \hat{a}_r^\dagger \hat{a}_s \hat{a}_t\)</span>. It has several normal-ordered forms: <span class="math display">\[\vnormord{\hat{a}_p \hat{a}_q^\dagger \hat{a}_r^\dagger \hat{a}_s \hat{a}_t}
= \hat{a}_q^\dagger \hat{a}_r^\dagger \hat{a}_p \hat{a}_s \hat{a}_t
= -\hat{a}_q^\dagger \hat{a}_r^\dagger \hat{a}_p \hat{a}_t \hat{a}_s
= \hat{a}_r^\dagger \hat{a}_q^\dagger \hat{a}_p \hat{a}_t \hat{a}_s
= \cdots
\]</span> They are all equally valid.</p>
<p>Normal ordering is idempotent, and moreover supersedes existing normal orderings: <span class="math display">\[\normord{(\hat{\Pi} \normord{\hat{\Gamma}} \hat{\Lambda})} = \normord{\hat{\Pi} \hat{\Gamma} \hat{\Lambda}}\]</span> Bosonic/fermionic normal-ordered products are symmetric/antisymmetric under operator exchange, i.e. for any permutation <span class="math inline">\(\sigma\)</span>, <span class="math display">\[\normord{\hat{\Pi}} = (\pm)^\sigma \normord{\sigma(\hat{\Pi})}\]</span></p>
<h3 id="matrix-elements-relative-to-the-fermi-vacuum"><span class="header-section-number">6.5.1</span> Matrix elements relative to the Fermi vacuum</h3>
<p>The primary application of normal ordering is in the redistribution of matrix elements between different ranks of operators, as the rank of an operator is dependent on the vacuum used.</p>
<p>Usually, many-body operators are given relative to the physical vacuum. For example, a (0, 1, 2, 3)-body operator <span class="math inline">\(\hat{H}\)</span> has the standard form <span class="math display">\[\hat{H} = E_\varnothing + \hat{H}_1^\varnothing + \hat{H}_2^\varnothing + \hat{H}_3^\varnothing\]</span> where <span class="math inline">\(E_\varnothing\)</span> is the physical vacuum energy (0-body component) and <span class="math inline">\(\hat{H}_k^\varnothing\)</span> denotes its <span class="math inline">\(k\)</span>-body component relative to the physical vacuum. In other words, the monomials of each component are already in normal order relative to the physical vacuum, <span class="math display">\[\begin{gather*}
  \hat{H}_1^\varnothing = \sum_{p q} H_{p q}^\varnothing \vnormord{\hat{a}_p^\dagger \hat{a}_q} \\
  \hat{H}_2^\varnothing = \frac{1}{4} \sum_{p q r s} H_{p q r s}^\varnothing \vnormord{\hat{a}_p^\dagger \hat{a}_q^\dagger \hat{a}_s \hat{a}_r} \\
  \hat{H}_3^\varnothing = \frac{1}{36} \sum_{p q r s t u} H_{p q r s t u}^\varnothing \vnormord{\hat{a}_p^\dagger \hat{a}_q^\dagger \hat{a}_r^\dagger \hat{a}_u \hat{a}_t \hat{a}_s}
\end{gather*}\]</span> These definitions are identical to those in Sec. <a href="print.html#sec:many-body-oper">6.3</a>. The normal ordering notation is present only for emphasis.</p>
<p>If we rearrange their monomials so that they are in normal order relative to the <em>Fermi</em> vacuum, portions of higher-rank operators would migrate to lower-rank operators. Take, for example, the two-body component: <span class="math display">\[\vnormord{\hat{a}_p^\dagger \hat{a}_q^\dagger \hat{a}_s \hat{a}_r} = \normord{\hat{a}_p^\dagger \hat{a}_q^\dagger \hat{a}_s \hat{a}_r} + 4 \antisymm_{p q} \antisymm_{r s} n_q \delta_{q s} \normord{\hat{a}_p^\dagger \hat{a}_r} + 2 \antisymm_{r s} n_p n_q \delta_{p r} \delta_{q s}\]</span> This leads to a different decomposition of the operators into particle-hole components, <span class="math display">\[\hat{H} = E_\Phi + \hat{H}_1^\Phi + \hat{H}_2^\Phi + \hat{H}_3^\Phi\]</span> where <span class="math inline">\(E_\Phi\)</span> is the Fermi vacuum energy and <span class="math inline">\(\hat{H}_k^\Phi\)</span> denotes<a href="print.html#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> its <span class="math inline">\(k\)</span>-body component relative to the Fermi vacuum <span class="math inline">\(\ket{\Phi}\)</span>, <span class="math display">\[\begin{gather*}
  \hat{H}^\Phi_1 = \sum_{p q} H^\Phi_{p q} \normord{\hat{a}_p^\dagger \hat{a}_q} \\
  \hat{H}^\Phi_2 = \frac{1}{4} \sum_{p q r s} H^\Phi_{p q r s} \normord{\hat{a}_p^\dagger \hat{a}_q^\dagger \hat{a}_s \hat{a}_r} \\
  \hat{H}^\Phi_3 = \frac{1}{36} \sum_{p q r s t u} H^\Phi_{p q r s t u} \normord{\hat{a}_p^\dagger \hat{a}_q^\dagger \hat{a}_r^\dagger \hat{a}_u \hat{a}_t \hat{a}_s}
\end{gather*}\]</span> and with matrix elements given by <span id="eq:normord-ph"><span class="math display">\[\begin{aligned}
  E_\Phi &amp;= E_\varnothing + \sum_{i \backslash} H^\varnothing_{i i} + \frac{1}{2} \sum_{i j \backslash} H^\varnothing_{i j i j} + \frac{1}{6} \sum_{i j k \backslash} H^\varnothing_{i j k i j k} \\
  H^\Phi_{p q} &amp;= H^\varnothing_{p q} + \sum_{i \backslash} H^\varnothing_{p i q i} + \frac{1}{2} \sum_{i j \backslash} H^\varnothing_{p i j q i j} \\
  H^\Phi_{p q r s} &amp;= H^\varnothing_{p q r s} + \sum_{i \backslash} H^\varnothing_{p q i r s i} \\
  H^\Phi_{p q r s t u} &amp;= H^\varnothing_{p q r s t u}
\end{aligned}\qquad(4)\]</span></span> Note that these particle-hole components <span class="math inline">\(\hat{H}_k^\Phi\)</span> do not conserve the number of quasiparticles, so their algebraic properties are not entirely analogous to the physical components <span class="math inline">\(\hat{H}_k^\varnothing\)</span>. Properly rewriting the operators in terms of quasiparticle field operators would lead to tedious results such as: <span class="math display">\[\hat{H}^\Phi_1 = \sum_{i \backslash a} H^\Phi_{a i} \normord{\hat{b}_a^\dagger \hat{b}_i^\dagger} + \sum_{\backslash a b} H^\Phi_{a b} \normord{\hat{b}_a^\dagger \hat{b}_b} - \sum_{i j \backslash} H^\Phi_{i j} \normord{\hat{b}_j^\dagger \hat{b}_i} + \sum_{i \backslash a} H^\Phi_{i a} \normord{\hat{b}_i \hat{b}_a}\]</span> Fortunately, we do not need to do this.</p>
<p>The matrix elements in Eq. <a href="print.html#eq:normord-ph">4</a> can be derived using the definition of normal ordering and the usual commutation relations, more efficiently, using Wick’s theorem or many-body diagrams.</p>
<h3 id="ambiguity-of-normal-ordering-on-non-monomials"><span class="header-section-number">6.5.2</span> Ambiguity of normal ordering on non-monomials</h3>
<p>The following expressions are not monomials: <span class="math display">\[\begin{align*}
  &amp;1 + \hat{a}_p \hat{a}_q^\dagger &amp;
  &amp;\E^{\hat{a}_p^\dagger \hat{a}_q}
  &amp;\hat{H}
\end{align*}\]</span> Normal ordering is <em>ill-defined</em> (ambiguous) on such non-monomial operators. The following paradox illustrates the problem: consider the fermionic product <span class="math inline">\(\hat{a}_p^\dagger \hat{a}_q \hat{a}_r\)</span>, <span class="math display">\[\begin{align*}
  \hat{a}_p^\dagger \hat{a}_q \hat{a}_r
  &amp;= \vnormord{\hat{a}_p^\dagger \hat{a}_q \hat{a}_r} \\
  &amp;\stackrel{?}{=} \vnormord{\delta_{p q} \hat{a}_r - \hat{a}_q \hat{a}_p^\dagger \hat{a}_r} \\
  &amp;\stackrel{?}{=} \vnormord{\delta_{p q} \hat{a}_r} - \vnormord{\hat{a}_q \hat{a}_p^\dagger \hat{a}_r} \\
  &amp;= \delta_{p q} \hat{a}_r + \hat{a}_p^\dagger \hat{a}_q \hat{a}_r
\end{align*}\]</span> To eliminate ambiguity one must expand the expression in a very specific way, causing normal ordering of non-monomial expressions to be sensitive to how it is written (its syntactic form). It is possible for two non-monomial expressions that are semantically equal to have semantically unequal normal-ordered results, leading to the paradox above. This paradox does not occur if we focus solely on monomial operators.</p>
<p>When normal ordering is applied non-monomial expressions, it is conventional to choose the most “direct” expansion without any usage of the <span class="math inline">\(\pm\)</span>-commutation relations. For example, <span class="math display">\[\begin{matrix}
  \normord{1 + \hat{b}_p^\dagger \hat{b}_q} &amp; \to &amp;
  1 + \normord{\hat{b}_p^\dagger \hat{b}_q} \\
  \normord{\E^{\hat{b}_p^\dagger \hat{b}_q}} &amp; \to &amp;
  1 + \normord{\hat{b}_p^\dagger \hat{b}_q} + \normord{\frac{1}{2} \hat{b}_p^\dagger \hat{b}_q \hat{b}_p^\dagger \hat{b}_q} + \cdots \\
  \normord{\hat{H}} &amp; \to &amp;
  E + \normord{\hat{H}_1} + \normord{\hat{H}_2} + \cdots
\end{matrix}\]</span></p>
<h2 id="wicks-theorem"><span class="header-section-number">6.6</span> Wick’s theorem</h2>
<p>Wick’s theorem <span class="citation" data-cites="PhysRev.80.268">(Wick 1950)</span> is an algebraic theorem for simplifying products of bosonic (commuting) or fermionic (anticommuting) field operators into sums of normal-ordered products. Many of the equations in the previous sections can be derived much more quickly and systematically using this theorem.</p>
<p>To describe the theorem, it is necessary to introduce the concept of Wick contractions.</p>
<h3 id="adjacent-wick-contractions"><span class="header-section-number">6.6.1</span> Adjacent Wick contractions</h3>
<p>In the simplest case, a <strong>Wick contraction</strong> between two adjacent field operators <span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\beta}\)</span>, denoted by a connecting line, is defined as, <span id="eq:wick-contr"><span class="math display">\[\lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\beta}} = \hat{\alpha} \hat{\beta} - \normord{\hat{\alpha} \hat{\beta}}\qquad(5)\]</span></span> For Wick’s theorem to apply, we require the result of a contraction to be a number, not an operator.<a href="print.html#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></p>
<p>Intuitively, contractions are the “remainder” of normal ordering. We can elaborate the definition to <span id="eq:wick-contr-alt"><span class="math display">\[\lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\beta}} = \begin{cases}
0 &amp; \text{if $\hat{\alpha} \hat{\beta}$ is in normal order} \\
\comm{\hat{\alpha}, \hat{\beta}}_\mp &amp; \text{if $\hat{\alpha} \hat{\beta}$ is not in normal order} \\
\end{cases}\qquad(6)\]</span></span> where commutator <span class="math inline">\(\comm{,}_- = \comm{,}\)</span> is chosen for bosons and anticommutator <span class="math inline">\(\comm{,}_+ = \anticomm{,}\)</span> is chosen for fermions. Observe that contractions have no effect if a product is already normal ordered.</p>
<p>For fermionic physical operators <span class="math inline">\(\hat{a}_p\)</span>, we obtain these cases for contractions relative to the physical vacuum: <span class="math display">\[\begin{align*}
  \lcontr{-1}{\hat{a}}_p \rcontr{-1}{\hat{a}}_q^\dagger &amp;= \delta_{p q} &amp;
  \lcontr{-1}{\hat{a}}_p \rcontr{-1}{\hat{a}}_q =
  \lcontr{-1}{\hat{a}}_p^\dagger \rcontr{-1}{\hat{a}}_q =
  \lcontr{-1}{\hat{a}}_p^\dagger \rcontr{-1}{\hat{a}}_q^\dagger &amp;= 0
\end{align*}\]</span> Here, connecting lines are drawn at the bottom of the symbols to indicate that these are contractions relative to the <em>physical</em> vacuum. That is, <span class="math display">\[\lcontr{-1}{\hat{\alpha}} \rcontr{-1}{\hat{\beta}} = \hat{\alpha} \hat{\beta} - \vnormord{\hat{\alpha} \hat{\beta}}\]</span></p>
<p>We obtain analogous relations for contractions of fermionic quasiparticle operators <span class="math inline">\(\hat{b}_p\)</span> relative to the Fermi vacuum: <span class="math display">\[\begin{align*}
  \lcontr{1}{\hat{b}}_p \rcontr{1}{\hat{b}}_q^\dagger &amp;= \delta_{p q} &amp;
  \lcontr{1}{\hat{b}}_p \rcontr{1}{\hat{b}}_q =
  \lcontr{1}{\hat{b}}_p^\dagger \rcontr{1}{\hat{b}}_q =
  \lcontr{1}{\hat{b}}_p^\dagger \rcontr{1}{\hat{b}}_q^\dagger &amp;= 0
\end{align*}\]</span> However, contraction of physical operators <span class="math inline">\(\hat{a}_p\)</span> relative to the Fermi vacuum are different: <span class="math display">\[\begin{align*}
  \lcontr{1}{\hat{a}}_p \rcontr{1}{\hat{a}}_q^\dagger &amp;= (1 - n_p) \delta_{p q} &amp;
  \lcontr{1}{\hat{a}}_p^\dagger \rcontr{1}{\hat{a}}_q &amp;= n_p \delta_{p q} &amp;
  \lcontr{1}{\hat{a}}_p \rcontr{1}{\hat{a}}_q =
  \lcontr{1}{\hat{a}}_p^\dagger \rcontr{1}{\hat{a}}_q^\dagger &amp;= 0
\end{align*}\]</span> where <span class="math inline">\(n_p\)</span> is equal to <span class="math inline">\(1\)</span> if <span class="math inline">\(p\)</span> is occupied in the reference state, <span class="math inline">\(0\)</span> otherwise.</p>
<h3 id="normal-ordered-wick-contractions"><span class="header-section-number">6.6.2</span> Normal-ordered Wick contractions</h3>
<p>Next, we consider non-adjacent Wick contractions, which is only defined <em>within</em> a normal-ordered product. Note that the contraction operation takes place prior to the normal ordering operation, otherwise the operation would be useless (it would always vanish according to Eq. <a href="print.html#eq:wick-contr-alt">6</a>).</p>
<p>Let <span class="math inline">\(\hat{\Pi}\)</span> be a product of <span class="math inline">\(m\)</span> field operators. We define the Wick contraction of <span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\beta}\)</span> within a normal ordered product <span class="math inline">\(\normord{\hat{\alpha} \hat{\Pi} \hat{\beta}}\)</span> as <span class="math display">\[\normord{\lcontr{1}{\hat{\alpha}} \hat{\Pi} \rcontr{1}{\hat{\beta}}} = (\pm)^m \lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\beta}} \normord{\hat{\Pi}}\]</span> where the sign is <span class="math inline">\((+)\)</span> for bosonic operators and <span class="math inline">\((-)\)</span> for fermionic operators.</p>
<p>In effect, we unite the two contracted operators using the <span class="math inline">\(\pm\)</span>-symmetries of the normal-ordered product before attempting to evaluate the contraction. Consider this example with fermionic operators, <span class="math display">\[\normord{\lcontr{1}{\hat{\alpha}} \hat{\beta} \rcontr{1}{\hat{\gamma}} \hat{\delta}} = -\normord{\hat{\beta} \lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\gamma}} \hat{\delta}} = -\lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\gamma}} \normord{\hat{\beta} \hat{\delta}}\]</span> Note that it does not matter whether <span class="math inline">\(\{\hat{\alpha}, \hat{\beta}\}\)</span> is zero, because inside a normal-ordered product all operators behave <em>as though</em> their <span class="math inline">\(\pm\)</span>-commutators are zero.</p>
<h3 id="multiple-wick-contractions"><span class="header-section-number">6.6.3</span> Multiple Wick contractions</h3>
<p>Given a normal-ordered product of <span class="math inline">\(n\)</span> field operators, there can be multiple ways to contract its contents. Consider the case <span class="math inline">\(n = 4\)</span>, <span class="math display">\[\begin{gather*}
  \begin{matrix}
    \normord{\hat{\alpha} \hat{\beta} \hat{\gamma} \hat{\delta}}
  \end{matrix} \\ \\
  \begin{matrix}
    \normord{\lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\beta}} \hat{\gamma} \hat{\delta}} &amp;
    \normord{\lcontr{1}{\hat{\alpha}} \hat{\beta} \rcontr{1}{\hat{\gamma}} \hat{\delta}} &amp;
    \normord{\lcontr{1}{\hat{\alpha}} \hat{\beta} \hat{\gamma} \rcontr{1}{\hat{\delta}}} &amp;
    \normord{\hat{\alpha} \lcontr{1}{\hat{\beta}} \rcontr{1}{\hat{\gamma}} \hat{\delta}} &amp;
    \normord{\hat{\alpha} \lcontr{1}{\hat{\beta}} \hat{\gamma} \rcontr{1}{\hat{\delta}}} &amp;
    \normord{\hat{\alpha} \hat{\beta} \lcontr{1}{\hat{\gamma}} \rcontr{1}{\hat{\delta}}}
  \end{matrix} \\ \\
  \begin{matrix}
    \normord{\lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\beta}} \lcontr{1}{\hat{\gamma}} \rcontr{1}{\hat{\delta}}} &amp;
    \normord{\lcontr{2}{\hat{\alpha}} \lcontr{1}{\hat{\beta}} \rcontr{2}{\hat{\gamma}} \rcontr{1}{\hat{\delta}}} &amp;
    \normord{\lcontr{2}{\hat{\alpha}} \lcontr{1}{\hat{\beta}} \rcontr{1}{\hat{\gamma}} \rcontr{2}{\hat{\delta}}}
  \end{matrix}
\end{gather*}\]</span> The first row contains all normal-ordered products with zero contractions. This is the trivial case.</p>
<p>The second row contains all normal-ordered products with exactly one contraction. We shall denote the sum of all entries in the second row by <span class="math display">\[\normord{\mathcal{C}^1(\hat{\alpha} \hat{\beta} \hat{\gamma} \hat{\delta})} =
  \normord{\lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\beta}} \hat{\gamma} \hat{\delta}} +
  \normord{\lcontr{1}{\hat{\alpha}} \hat{\beta} \rcontr{1}{\hat{\gamma}} \hat{\delta}} +
  \normord{\lcontr{1}{\hat{\alpha}} \hat{\beta} \hat{\gamma} \rcontr{1}{\hat{\delta}}} +
  \normord{\hat{\alpha} \lcontr{1}{\hat{\beta}} \rcontr{1}{\hat{\gamma}} \hat{\delta}} +
  \normord{\hat{\alpha} \lcontr{1}{\hat{\beta}} \hat{\gamma} \rcontr{1}{\hat{\delta}}} +
  \normord{\hat{\alpha} \hat{\beta} \lcontr{1}{\hat{\gamma}} \rcontr{1}{\hat{\delta}}}\]</span></p>
<p>The third row contains all normal-ordered products with exactly two contractions. Analogous to the second row, we shall denote the sum of all entries in the third row by <span class="math display">\[\normord{\mathcal{C}^2(\hat{\alpha} \hat{\beta} \hat{\gamma} \hat{\delta})} =
  \normord{\lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\beta}} \lcontr{1}{\hat{\gamma}} \rcontr{1}{\hat{\delta}}} +
  \normord{\lcontr{2}{\hat{\alpha}} \lcontr{1}{\hat{\beta}} \rcontr{2}{\hat{\gamma}} \rcontr{1}{\hat{\delta}}} +
  \normord{\lcontr{2}{\hat{\alpha}} \lcontr{1}{\hat{\beta}} \rcontr{1}{\hat{\gamma}} \rcontr{2}{\hat{\delta}}}\]</span></p>
<p>We can generalize this notation. If we have a product <span class="math inline">\(\hat{\Pi}\)</span> of <span class="math inline">\(n\)</span> field operators, the notation <span class="math inline">\(\normord{\mathcal{C}^k(\hat{\Pi})}\)</span> denotes the sum of all normal-ordered products with exactly <span class="math inline">\(k\)</span> contractions. In particular:</p>
<ul>
<li><p>If <span class="math inline">\(k = 0\)</span>, then there are no contractions. Therefore, <span class="math display">\[\normord{\mathcal{C}^0(\hat{\Pi})} = \normord{\hat{\Pi}}\]</span></p></li>
<li><p>It is impossible to have more than <span class="math inline">\(\lfloor n / 2 \rfloor\)</span> contractions. Therefore, <span class="math display">\[\begin{align*}
  2 k &amp;&gt; n &amp; &amp;\implies &amp; \normord{\mathcal{C}^k(\hat{\Pi})} &amp;= 0
\end{align*}\]</span></p></li>
</ul>
<h3 id="statement-of-wicks-theorem"><span class="header-section-number">6.6.4</span> Statement of Wick’s theorem</h3>
<p>We are now ready to state <strong>Wick’s theorem</strong>: A product of <span class="math inline">\(n\)</span> field operators <span class="math inline">\(\hat{\Pi}\)</span> may be expanded as <span class="math display">\[\hat{\Pi} = \sum_{k = 0}^\infty \normord{\mathcal{C}^k(\hat{\Pi})} = \normord{\hat{\Pi}} + \sum_{k = 1}^{\lfloor n / 2 \rfloor} \normord{\mathcal{C}^k(\hat{\Pi})}\]</span> That is, any product of field operators may be expanded as a sum of every possible combination of contractions within its normal-ordered product.</p>
<p>The definition of contractions in Eq. <a href="print.html#eq:wick-contr">5</a> yields a special case of Wick’s theorem for exactly two field operators, <span class="math display">\[\hat{\alpha} \hat{\beta} = \normord{\hat{\alpha} \hat{\beta}} + \lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\beta}}\]</span></p>
<p>There is also a <strong>generalized Wick’s theorem</strong>: A product of two normal-ordered products <span class="math inline">\(\normord{\hat{\Pi}}\)</span> and <span class="math inline">\(\normord{\hat{\Gamma}}\)</span> may be expanded as <span class="math display">\[\normord{\hat{\Pi}} \times \normord{\hat{\Gamma}} = \sum_{k = 0}^\infty \normord{\mathcal{C}^k(\normord{\hat{\Pi}} \times \normord{\hat{\Gamma}})}\]</span> where <span class="math inline">\(\normord{\mathcal{C}^k(\normord{\hat{\Pi}} \times \normord{\hat{\Gamma}})}\)</span> is a sum of every possible combination of <span class="math inline">\(k\)</span> contractions between elements of <span class="math inline">\(\normord{\hat{\Pi}}\)</span> and elements of <span class="math inline">\(\normord{\hat{\Gamma}}\)</span> within the normal-ordered product <span class="math inline">\(\normord{(\normord{\hat{\Pi}} \times \normord{\hat{\Gamma}})}\)</span>. Contractions among elements of <span class="math inline">\(\normord{\hat{\Pi}}\)</span> are excluded (and likewise for <span class="math inline">\(\normord{\hat{\Gamma}}\)</span>) because contraction between elements that are already in normal order is zero (Eq. <a href="print.html#eq:wick-contr-alt">6</a>). Despite its name, the generalized Wick’s theorem is not actually a generalization but a special case of Wick’s theorem when the product is already partly in normal order.</p>
<h3 id="proof-of-wicks-theorem"><span class="header-section-number">6.6.5</span> Proof of Wick’s theorem</h3>
<p>To prove Wick’s theorem, we need the following lemma: <span class="math display">\[\hat{\alpha} \hat{\gamma}_1 \ldots \hat{\gamma}_j = (\pm)^j \hat{\gamma}_1 \ldots \hat{\gamma}_j \hat{\alpha} + \sum_{i = 1}^j (\pm)^{i - 1} \hat{\gamma}_1 \ldots \hat{\gamma}_{i - 1} [\hat{\alpha}, \hat{\gamma}_i]_\mp \hat{\gamma}_{i + 1} \ldots \hat{\gamma}_j\]</span> which describes the process of moving <span class="math inline">\(\hat{\alpha}\)</span> from the left of a product <span class="math inline">\(\hat{\gamma}_1 \ldots \hat{\gamma}_j\)</span> to the right. In doing so, it accumulates a series of <span class="math inline">\(\pm\)</span>-commutators involving <span class="math inline">\(\hat{\alpha}\)</span>.</p>
<p>To prove the lemma by induction, we start with the obvious base case for <span class="math inline">\(j = 0\)</span>, <span class="math display">\[\hat{\alpha} = (\pm)^0 \hat{\alpha} + 0\]</span> For the induction step, assume the lemma holds for <span class="math inline">\(j\)</span>. Then, we can prove it holds for <span class="math inline">\(j + 1\)</span> as well, <span class="math display">\[\begin{align*}
  &amp;\hat{\alpha} \hat{\gamma}_1 \ldots \hat{\gamma}_{j + 1} \\
  &amp;= (\pm)^j \hat{\gamma}_1 \ldots \hat{\gamma}_j \hat{\alpha} \hat{\gamma}_{j + 1} + \sum_{i = 1}^j (\pm)^{i - 1} \hat{\gamma}_1 \ldots \hat{\gamma}_{i - 1} [\hat{\alpha}, \hat{\gamma}_i]_\mp \hat{\gamma}_{i + 1} \ldots \hat{\gamma}_{j + 1} \\
  &amp;= (\pm)^j \hat{\gamma}_1 \ldots \hat{\gamma}_j (\pm \hat{\gamma}_{j + 1} \hat{\alpha} + [\hat{\alpha}, \hat{\gamma}_{j + 1}]_\mp) + \sum_{i = 1}^j (\pm)^{i - 1} \hat{\gamma}_1 \ldots \hat{\gamma}_{i - 1} [\hat{\alpha}, \hat{\gamma}_i]_\mp \hat{\gamma}_{i + 1} \ldots \hat{\gamma}_{j + 1} \\
  &amp;= (\pm)^{j + 1} \hat{\gamma}_1 \ldots \hat{\gamma}_{j + 1} \hat{\alpha} + \sum_{i = 1}^{j + 1} (\pm)^{i - 1} \hat{\gamma}_1 \ldots \hat{\gamma}_{i - 1} [\hat{\alpha}, \hat{\gamma}_i]_\mp \hat{\gamma}_{i + 1} \ldots \hat{\gamma}_{j + 1}
\end{align*}\]</span> thus we have proven the case for <span class="math inline">\(j + 1\)</span>. <span class="math inline">\(\blacksquare\)</span></p>
<p>The lemma is very general but also verbose. If we assume the <span class="math inline">\(\pm\)</span>-commutators are all numbers, then there is another way to state the lemma using Wick contractions and normal ordering. Suppose we have a product <span class="math inline">\(\hat{\gamma}_1 \ldots \hat{\gamma}_j \hat{\alpha} \hat{\gamma}_{j + 1} \ldots \hat{\gamma}_m\)</span> that is in normal order. Observe that:</p>
<ul>
<li><p>If <span class="math inline">\(i \le j\)</span>, then <span class="math inline">\(\lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\gamma}}_i = [\hat{\alpha}, \hat{\gamma}_i]_\mp\)</span> because either (a) <span class="math inline">\(\hat{\alpha} \hat{\gamma}_i\)</span> is not in normal order, or (b) both <span class="math inline">\(\hat{\alpha} \hat{\gamma}_i\)</span> and <span class="math inline">\(\hat{\gamma}_i \hat{\alpha}\)</span> are in normal order, in which case both the <span class="math inline">\(\pm\)</span>-commutator and contraction are zero.</p></li>
<li><p>If <span class="math inline">\(i &gt; j\)</span>, then <span class="math inline">\(\lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\gamma}}_i = 0\)</span> because <span class="math inline">\(\hat{\alpha} \hat{\gamma}_i\)</span> is in normal order.</p></li>
</ul>
<p>Therefore, we can replace the <span class="math inline">\(\pm\)</span>-commutators with Wick contractions and artifically raise the upper limit of the summation from <span class="math inline">\(j\)</span> to <span class="math inline">\(m\)</span> because all those extra <span class="math inline">\(\pm\)</span>-commutators are zero, leading to <span class="math display">\[\hat{\alpha} \hat{\gamma}_1 \ldots \hat{\gamma}_m = (\pm)^j \hat{\gamma}_1 \ldots \hat{\gamma}_j \hat{\alpha} \hat{\gamma}_{j + 1} \ldots \hat{\gamma}_m + \sum_{i = 1}^m (\pm)^{i - 1} \lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\gamma}}_i \hat{\gamma}_1 \ldots \hat{\gamma}_{i - 1} \hat{\gamma}_{i + 1} \ldots \hat{\gamma}_m\]</span> We can rewrite this using our definition of normal ordering and Wick contraction within normal-ordered products, <span class="math display">\[\hat{\alpha} \normord{\hat{\gamma}_1 \ldots \hat{\gamma}_m} = \normord{\hat{\alpha} \hat{\gamma}_1 \ldots \hat{\gamma}_m} + \sum_{i = 1}^m \normord{\lcontr{1}{\hat{\alpha}} \hat{\gamma}_1 \ldots \rcontr{1}{\hat{\gamma}}_i \ldots \hat{\gamma}_m}\]</span> If we define <span class="math inline">\(\normord{\hat{\Gamma}} = s \normord{\hat{\gamma}_1 \ldots \hat{\gamma}_m}\)</span> with some sign <span class="math inline">\(s\)</span>, we may rewrite the previous equation as: <span id="eq:wick-lemma-pre"><span class="math display">\[\frac{1}{s} \hat{\alpha} \normord{\hat{\Gamma}} = \frac{1}{s} \normord{\hat{\alpha} \hat{\Gamma}} + \frac{1}{s} \normord{\lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\Gamma}}}\qquad(7)\]</span></span> where <span class="math inline">\(\normord{\lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\Gamma}}}\)</span> is a shorthand for <span class="math display">\[\normord{\lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\Gamma}}} = \sum_{i = 1}^m s \normord{\lcontr{1}{\hat{\alpha}} \hat{\gamma}_1 \ldots \rcontr{1}{\hat{\gamma}}_i \ldots \hat{\gamma}_m}\]</span> Then, Eq. <a href="print.html#eq:wick-lemma-pre">7</a> simplifies to: <span id="eq:wick-lemma"><span class="math display">\[\hat{\alpha} \normord{\hat{\Gamma}} = \normord{\hat{\alpha} \hat{\Gamma}} + \normord{\lcontr{1}{\hat{\alpha}} \rcontr{1}{\hat{\Gamma}}}\qquad(8)\]</span></span></p>
<p>Now we may prove Wick’s theorem using induction. The base case is obvious, <span class="math display">\[1 = \normord{1}\]</span> For the inductive step, we start by assuming that Wick’s theorem holds for the product <span class="math inline">\(\hat{\Pi}\)</span> and wish to prove that it holds for <span class="math inline">\(\hat{\alpha} \hat{\Pi}\)</span>. From the assumption, we write <span class="math display">\[\hat{\alpha} \hat{\Pi} = \sum_{k = 0}^\infty \hat{\alpha} \normord{\mathcal{C}^k(\hat{\Pi})}\]</span> Now we may use the lemma in Eq. <a href="print.html#eq:wick-lemma">8</a> with <span class="math inline">\(\hat{\Gamma} = \mathcal{C}^k(\hat{\Pi})\)</span>, <span class="math display">\[\begin{align*}
  \sum_{k = 0}^\infty \hat{\alpha} \normord{\mathcal{C}^k(\hat{\Pi})}
  &amp;= \sum_{k = 0}^\infty \normord{\hat{\alpha} \mathcal{C}^k(\hat{\Pi})} + \sum_{k = 0}^\infty \normord{\lcontr{1}{\hat{\alpha}} \mathcal{C}^k(\rcontr{1}{\hat{\Pi}})} \\
  &amp;= \normord{\hat{\alpha} \mathcal{C}^0(\hat{\Pi})} + \sum_{k = 1}^\infty (\normord{\hat{\alpha} \mathcal{C}^k(\hat{\Pi})} + \normord{\lcontr{1}{\hat{\alpha}} \mathcal{C}^{k - 1}(\rcontr{1}{\hat{\Pi}})})
\end{align*}\]</span> Observe that <span class="math inline">\(\normord{\mathcal{C}^0(\hat{\Pi})} = \normord{\hat{\Pi}}\)</span> and <span class="math display">\[\normord{\mathcal{C}^k(\hat{\alpha} \hat{\Pi})} = \normord{\hat{\alpha} \mathcal{C}^k(\hat{\Pi})} + \normord{\lcontr{1}{\hat{\alpha}} \mathcal{C}^{k - 1}(\rcontr{1}{\hat{\Pi}})}\]</span> In other words, <span class="math inline">\(k\)</span> contractions in <span class="math inline">\(\hat{\alpha} \hat{\Pi}\)</span> can be either</p>
<ul>
<li><span class="math inline">\(k\)</span> contractions only within <span class="math inline">\(\hat{\Pi}\)</span>, or</li>
<li>one contraction between <span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\Pi}\)</span> and <span class="math inline">\(k - 1\)</span> contractions within <span class="math inline">\(\hat{\Pi}\)</span>.</li>
</ul>
<p>Hence, <span class="math display">\[\hat{\alpha} \hat{\Pi} = \normord{\hat{\alpha} \hat{\Pi}} + \sum_{k = 1}^\infty \normord{\mathcal{C}^k(\hat{\alpha} \hat{\Pi})}\]</span> <span class="math inline">\(\blacksquare\)</span></p>
<h1 id="many-body-diagrams"><span class="header-section-number">7</span> Many-body diagrams</h1>
<p>Many-body diagrams <span class="citation" data-cites="Goldstone267 HUGENHOLTZ1957481">(Goldstone 1957; Hugenholtz 1957)</span> provide a graphical way to apply Wick’s theorem in the Fermi vacuum and express summations of matrix elements. They are analogous to Feymann diagrams <span class="citation" data-cites="PhysRev.76.7496">(Feynman 1949)</span> but with single-particle states in lieu of fundamental particles. We will provide an overview of many-body diagrams, but as it is a fairly substantial topic, we refer interested readers to <span class="citation" data-cites="shavitt2009many">(Shavitt and Bartlett 2009)</span> for a more in-depth explanation.</p>
<p>A diagram is composed of a set of <strong>nodes</strong> (vertices) and a set of possibly directed <strong>lines</strong> (edges), arranged in a layout similar to graphs. However, diagrams do have a few differences that distinguish them from graphs in the conventional sense:</p>
<ul>
<li>Nodes may not be point-like entities. They may be drawn in various shapes, and the particular arrangement of lines around a given node can be semantically meaningful.</li>
<li>The ends of a line do not have to be attached to any node. Such lines, where at least one of the ends is dangling, are called <strong>external lines</strong>, whereas lines that are attached to nodes on both ends are called <strong>internal lines</strong>.</li>
<li>In Feynmann-like diagrams, including many-body diagrams, one of the axes is defined to be the so-called <strong>time axis</strong> and thus the orientation of the diagram can be semantically meaningful. Either the vertical (upward) or horizontal (leftward) axis may be chosen as the time axis depending on convention. We will use the vertical axis as the time axis. Particles that are created later in time will appear higher in the diagram.</li>
</ul>
<p>In many-body diagrams, nodes represent operators. Specifically, a node representing a <span class="math inline">\(k\)</span>-body operator has <span class="math inline">\(k\)</span> outgoing (creation) lines and <span class="math inline">\(k\)</span> incoming (annihilation) lines, corresponding to a normal-ordered operator of the form <span class="math display">\[\begin{gather*}
  \frac{1}{k!^2} \sum_{p_1 \ldots p_k q_1 \ldots q_k} X_{p_1 \ldots p_k q_1 \ldots q_k} \normord{(\hat{a}_{p_1}^\dagger \hat{a}_{q_1}) \ldots (\hat{a}_{p_k}^\dagger \hat{a}_{q_k})}
\end{gather*}\]</span> There are two varieties of many-body diagrams, which render operators differently:</p>
<ul>
<li><p>In the <strong>Brandow diagrams</strong> (or <strong>antisymmetrized Goldstone diagrams</strong>) <span class="citation" data-cites="RevModPhys.39.771">(Brandow 1967)</span>, nodes are represented by <span class="math inline">\(k\)</span> dots connected by dashed lines. Each dot has exactly one outgoing and one incoming line, thus a dot corresponds to a single creation-annihilation pair <span class="math inline">\(\hat{a}_p^\dagger \hat{a}_q\)</span>. The ordering of the dots among themselves is insignificant as creation-annihilation pairs commute with each other within a normal-ordered product.</p></li>
<li><p>In the <strong>Hugenholtz diagrams</strong> <span class="citation" data-cites="HUGENHOLTZ1957481">(Hugenholtz 1957)</span>, nodes are collapsed to a single dot with <span class="math inline">\(k\)</span> outgoing and <span class="math inline">\(k\)</span> incoming lines. Since it is no longer feasible to track the pairing between the outgoing and incoming lines, the sign of Hugenholtz diagrams is ambiguous. To transcribe Hugenholtz diagrams into equations with a definite sign, it is necessary to expand Hugenholtz diagrams to Brandow diagrams by pairing up the creation and annihilation operators in an arbitrary manner.</p></li>
</ul>
<p>Lines represent variables that label single-particle states. The direction of a line tells us which end has the creation operator (tail) and which end has the annihilation operator (head). There are three kinds of lines:</p>
<ul>
<li><p>Internal lines (neither end is dangling): these represent Wick contractions and are always directed (have arrows). The orientation of their arrows with respect to the time axis is significant:</p>
<ul>
<li><p>If the direction of the arrow goes <em>along</em> the time axis (in our convention, if the arrow points up), then it represents a <em>particle state</em> <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\(c\)</span>, … since its creation occurs before its annihilation.</p></li>
<li><p>If the direction of the arrow goes <em>against</em> the time axis (in our convention, if the arrow points down), then it represents a <em>hole state</em> <span class="math inline">\(i\)</span>, <span class="math inline">\(j\)</span>, <span class="math inline">\(k\)</span>, … since its creation occurs after its annihilation.</p></li>
</ul></li>
<li><p>External lines where one of the ends is dangling: these represent the variables <span class="math inline">\(p\)</span>, <span class="math inline">\(q\)</span>, <span class="math inline">\(r\)</span>, … of uncontracted field operators and their orientation with respect to the time axis is irrelevant. Outgoing lines (lines that leave the node) represent creation operators, and ingoing lines (lines that enter the node) represent annihilation operators. If all operators conserve particle number, then one can often elide the directions of external lines and have them inferred from context.</p></li>
<li><p>External lines where both ends are dangling: this is a degenerate case. Such a line represents a Kronecker delta <span class="math inline">\(\delta_{p q}\)</span>, where <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> are the variables on each end of the line. The presence or absence of an arrow is irrelevant.</p></li>
</ul>
<p>To illustrate the various parts of a diagram, consider this normal-ordered, partially contracted product <span class="math inline">\(\hat{R}\)</span>, <span id="eq:example-diagram"><span class="math display">\[\hat{R} = \frac{1}{8} \sum_{\substack{p q r s \\ i \backslash a b c}} W_{i p q a b c} F_{a i} \Gamma_{b c r s} \normord{
  (\lcontr{2}{\hat{a}}_i^\dagger \lcontr{1}{\hat{a}}_a \hat{a}_p^\dagger \lcontr{3}{\hat{a}}_b \hat{a}_q^\dagger \lcontr{4}{\hat{a}}_c)
  (\rcontr{1}{\hat{a}}_a^\dagger \rcontr{2}{\hat{a}}_i)
  (\rcontr{3}{\hat{a}}_b^\dagger \hat{a}_r \rcontr{4}{\hat{a}}_c^\dagger \hat{a}_s)
}\qquad(9)\]</span></span> where <span class="math inline">\(\hat{W}\)</span> is a three-body operator, <span class="math inline">\(\hat{F}\)</span> is a one-body operator, and <span class="math inline">\(\hat{\Gamma}\)</span> is a two-body operator, all defined relative to the Fermi vacuum. The diagrammatic representation of this expression is shown in Fig. <a href="print.html#fig:example-diagram">2</a>.</p>
<figure>
<img src="fig-example-diagram" alt="Figure 2: An example of a Brandow diagram representing to Eq. 9. We have intentionally labeled many parts of this diagram to provide a clear correspondence to the algebraic expression. To emphasize the distinction between internal and external lines, we have drawn the arrows of external lines with a different shape than those of internal lines." id="fig:example-diagram" /><figcaption>Figure 2: An example of a Brandow diagram representing to Eq. <a href="print.html#eq:example-diagram">9</a>. We have intentionally labeled many parts of this diagram to provide a clear correspondence to the algebraic expression. To emphasize the distinction between internal and external lines, we have drawn the arrows of external lines with a different shape than those of internal lines.</figcaption>
</figure>
<p>The factor of <span class="math inline">\(1/8\)</span> is the <strong>weight</strong> of the diagram. To obtain this number, we examine the symmetries in the Hugenholtz diagram, shown in Fig. <a href="print.html#fig:example-diagram-hugenholtz">3</a>. Observe that <span class="math inline">\(\{p, q\}\)</span> are topologically equivalent, and so are <span class="math inline">\(\{b, c\}\)</span> and <span class="math inline">\(\{r, s\}\)</span>. Thus, the factor should be <span class="math inline">\(1 / (2! \times 2! \times 2!) = 1/8\)</span>.</p>
<p>The Brandow diagram makes it simple to compute the resultant <em>sign</em> (phase) of the expression in Eq. <a href="print.html#eq:example-diagram">9</a>:</p>
<ol type="1">
<li><p>Pair up each outgoing external line with each incoming external line and connect them with a dotted line. The assignment is arbitrary, but once the choice is made, it fixes the ordering of the operators of the resultant expression.</p>
<p>For example, if we pick <span class="math inline">\((p, r)\)</span> and <span class="math inline">\((q, s)\)</span> in Fig. <a href="print.html#fig:example-diagram">2</a>, then the resultant expression will have the ordering <span class="math inline">\(\normord{\hat{a}_p^\dagger \hat{a}_r \hat{a}_q^\dagger \hat{a}_s}\)</span>.</p></li>
<li><p>Count (a) number of dotted lines <span class="math inline">\(d\)</span>, (b) the number of internal hole lines <span class="math inline">\(h\)</span>, and (c) the number of loops <span class="math inline">\(\ell\)</span>, including those that are completed by dotted lines. The sign is equal to <span class="math display">\[(-)^{d + h + \ell}\]</span></p>
<p>In the previous example, we have introduced two dotted lines connecting <span class="math inline">\(p\)</span> to <span class="math inline">\(r\)</span> and <span class="math inline">\(q\)</span> to <span class="math inline">\(s\)</span>. There is one hole line, and a total three loops (two of which contain dotted lines). The sign is therefore positive.</p></li>
</ol>
<p>This leads to the final result: <span class="math display">\[\hat{R} = + \frac{1}{8} \sum_{\substack{p q r s \\ i \backslash a b c}} W_{i p q a b c} F_{a i} \Gamma_{b c r s} \normord{\hat{a}_p^\dagger \hat{a}_r \hat{a}_q^\dagger \hat{a}_s}\]</span></p>
<figure>
<img src="fig-example-diagram-hugenholtz" alt="Figure 3: A Hugenholtz diagram representing to Eq. 9. This diagram is useful for determining the weight." id="fig:example-diagram-hugenholtz" /><figcaption>Figure 3: A Hugenholtz diagram representing to Eq. <a href="print.html#eq:example-diagram">9</a>. This diagram is useful for determining the weight.</figcaption>
</figure>
<h2 id="sec:perturbative-diagrams"><span class="header-section-number">7.1</span> Perturbative diagrams</h2>
<figure>
<img src="fig-example-qdpt-diagram" alt="Figure 4: Interpretation of a perturbative Goldstone diagram" id="fig:example-qdpt-diagram" /><figcaption>Figure 4: Interpretation of a perturbative Goldstone diagram</figcaption>
</figure>
<p>A variant of many-body diagrams is used in perturbation theory, which introduces an unusual kind of node called <strong>resolvents</strong> or <strong>energy denominators</strong>, drawn as a horizontal line that cuts across the diagram.</p>
<p>An example of such a diagram is shown on the right-hand side of Fig. <a href="print.html#fig:example-qdpt-diagram">4</a>. Note that to interpret such a diagram correctly, all incoming external lines must be <strong>folded</strong> upward, as shown on the right-hand side. For every denominator line, one divides the summation by the following Møller–Plesset denominator (see also Eq. <a href="hartree-fock.html#eq:moellerplessetdenominator">45</a>): <span class="math display">\[\Delta_{q_1 \ldots q_k p_1 \ldots p_k} = \sum_{i = 1}^k (\varepsilon_{q_i} - \varepsilon_{p_i})\]</span> where <span class="math inline">\(q_1 \ldots q_k\)</span> are all downward lines that cut across the denominator line (including ingoing external lines), <span class="math inline">\(p_1 \ldots p_k\)</span> are all upward lines that cut across the denominator line (including outgoing external lines), and <span class="math inline">\(\varepsilon_p\)</span> denotes the energy of the single-particle state <span class="math inline">\(p\)</span>.</p>
<p>In the example, the upper denominator is given by <span class="math display">\[\Delta_{i j q a b p} = \varepsilon_i + \varepsilon_j + \varepsilon_q - \varepsilon_a - \varepsilon_b - \varepsilon_p\]</span> whereas the lower denominator is given by <span class="math display">\[\Delta_{i j c p} = \varepsilon_i + \varepsilon_j - \varepsilon_c - \varepsilon_p\]</span></p>
<p>For presentation purposes, it is common to omit the denominator lines and to unfold a diagram back into the usual non-perturbative layout, as shown on the left-hand side of Fig. <a href="print.html#fig:example-qdpt-diagram">4</a>. To interpret this diagram perturbatively, simply refold the diagram and reinsert denominators between every pair of the <span class="math inline">\(\hat{V}\)</span> interaction nodes.</p>
<h1 id="angular-momentum-coupling"><span class="header-section-number">8</span> Angular momentum coupling</h1>
<p>We shall first discuss the details of angular momentum coupling in general, and then more specifically in the context of many-body theory. The objective of this chapter is to lay out the formalism (J-scheme, Sec. <a href="print.html#sec:j-scheme">8.11</a>) that one needs to derive the angular-momentum-coupled equations in many-body theory, which are essential for efficient computations in spherically symmetric systems such as nuclei. We also include a brief discussion of our graphical angular momentum software (Sec. <a href="print.html#sec:jucys">8.10</a>) used for derivations of angular momentum quantities.</p>
<h2 id="angular-momentum-and-isospin"><span class="header-section-number">8.1</span> Angular momentum and isospin</h2>
<p>In classical physics, <strong>orbital angular momentum</strong> <span class="math inline">\(\bm{L}\)</span> is defined as <span class="math inline">\(\bm{L} = \bm{r} \times \bm{p}\)</span>, where <span class="math inline">\(\bm{r}\)</span> is position and <span class="math inline">\(\bm{p}\)</span> is linear momentum. This definition carries over to quantum mechanics with the appropriate replacement of each quantity by their corresponding operator: <span class="math display">\[\hat{\bm{L}} = \hat{\bm{r}} \times \hat{\bm{p}} = -\I \hbar \hat{\bm{r}} \times \hat{\bm{\nabla}}\]</span> In three-dimensional space, the standard eigenstates of orbital angular momentum are the spherical harmonics <span class="math display">\[\ket{\ell m_\ell} \leftrightarrow Y_{\ell m_\ell}(\theta, \varphi)\]</span> which are labeled by the orbital angular momentum magnitude <span class="math inline">\(\ell\)</span> and orbital angular momentum projection <span class="math inline">\(m_\ell\)</span> (also known as <em>magnetic quantum number</em> in chemistry), satisfying <span class="math display">\[\begin{align*}
  \ell &amp;\in \mathbb{N} &amp;
  m_\ell &amp;\in M_\ell
\end{align*}\]</span> where <span class="math inline">\(\mathbb{N} = \{0, 1, 2, \ldots\}\)</span> is the set of nonnegative integers and <span class="math inline">\(M_\ell\)</span> denotes the set <span id="eq:mlset"><span class="math display">\[\{-\ell, -\ell + 1, -\ell + 2, \ldots, +\ell - 2, +\ell - 1, +\ell\}\qquad(10)\]</span></span> The quantum numbers are related to eigenvalues of <span class="math inline">\(\hat{\bm{L}}^2\)</span> and <span class="math inline">\(\hat{L}_3\)</span> (<span class="math inline">\(z\)</span>-component of <span class="math inline">\(\hat{\bm{L}}\)</span>): <span class="math display">\[\begin{gather*}
  \hat{\bm{L}}^2 \ket{\ell m_\ell} = \hbar \ell (\ell + 1) \ket{\ell m_\ell} \\
  \hat{L}_3 \ket{\ell m_\ell} = \hbar m_\ell \ket{\ell m_\ell}
\end{gather*}\]</span> Notice that these are not eigenstates of <span class="math inline">\(\hat{L}_1\)</span> or <span class="math inline">\(\hat{L}_2\)</span>. It is impossible to find eigenstates of all three components, because <span class="math inline">\(\hat{L}_1\)</span>, <span class="math inline">\(\hat{L}_2\)</span>, and <span class="math inline">\(\hat{L}_3\)</span> do not commute with each other, as evidenced by the noncommuting nature of rotations in three-dimensional space. Instead, they satisfy the commutation relations, <span class="math display">\[[\hat{L}_i, \hat{L}_j] = \I \hbar \sum_{k = 1}^3 \epsilon_{i j k} \hat{L}_k\]</span> where <span class="math inline">\(\epsilon_{i j k}\)</span> is the Levi–Civita symbol.</p>
<p>In quantum mechanics, there is the addition of <strong>spin</strong> <span class="math inline">\(\hat{\bm{S}}\)</span>, a kind of angular momentum intrinsic to each particle. There is an analogous set of standard eigenstates <span class="math inline">\(\ket{s m_s}\)</span> labeled by spin magnitude <span class="math inline">\(s\)</span> and spin projection <span class="math inline">\(m_s\)</span>, <span class="math display">\[\begin{gather*}
  \hat{\bm{S}}^2 \ket{s m_s} = \hbar s (s + 1) \ket{s m_s} \\
  \hat{S}_3 \ket{s m_s} = \hbar m_s \ket{s m_s}
\end{gather*}\]</span> Again, note that these are not eigenstates of <span class="math inline">\(\hat{S}_1\)</span> nor <span class="math inline">\(\hat{S}_2\)</span>.</p>
<p>Unlike orbital angular momentum, the quantum numbers of spin are not confined to integers, but could be <strong>half-integers</strong> <span class="math inline">\(\frac{1}{2} \mathbb{Z}\)</span>, given by <span id="eq:half-integer"><span class="math display">\[\frac{1}{2} \mathbb{Z} = \left\{\ldots, -\frac{3}{2}, -1, -\frac{1}{2}, 0, +\frac{1}{2}, +2, \frac{3}{2}, \ldots\right\}\qquad(11)\]</span></span> They are subject to the following conditions: <span class="math display">\[s \in \frac{1}{2}\mathbb{N} \qquad\qquad
  m_s \in M_s\]</span> where <span class="math inline">\(\frac{1}{2}\mathbb{N}\)</span> denotes the set of nonnegative half-integers: <span id="eq:half-natural"><span class="math display">\[\frac{1}{2}\mathbb{N} = \left\{0, \frac{1}{2}, 1, \frac{3}{2}, \ldots\right\}\qquad(12)\]</span></span> and <span class="math inline">\(M_s\)</span> follows the same definition as Eq. <a href="print.html#eq:mlset">10</a>, but with the argument <span class="math inline">\(s\)</span> extended to support nonnegative integers, <span id="eq:mset"><span class="math display">\[M_s = \{-s, -s + 1, -s + 2, \ldots, +s - 2, +s - 1, +s\}\qquad(13)\]</span></span> Note that if <span class="math inline">\(s\)</span> is a <em>half-odd</em> integer – a half-integer that is not also an integer – then <span class="math inline">\(M_s\)</span> does not contain <span class="math inline">\(0\)</span>.</p>
<p>Spin states are not wave functions of position – they live within their own abstract Hilbert subspace. Most fermions studied in many-body theory, such as electrons or nucleons, are spin-<span class="math inline">\(\frac{1}{2}\)</span> particles, which means <span class="math inline">\(s\)</span> is always <span class="math inline">\(\frac{1}{2}\)</span> and the dimension of this subspace is two. Conventionally, the spin operator for a spin-<span class="math inline">\(\frac{1}{2}\)</span> particle may be represented by a vector of Pauli matrices <span class="math inline">\(\hat{\bm{\sigma}}\)</span>: <span class="math display">\[\hat{\bm{S}} = \frac{\hbar}{2} \hat{\bm{\sigma}}
= \frac{\hbar}{2}
\begin{bmatrix}
  \hat{\sigma}_1 \\
  \hat{\sigma}_2 \\
  \hat{\sigma}_3 \\
\end{bmatrix}\]</span> Each Pauli matrix <span class="math inline">\(\sigma_i\)</span> acts on the two-dimensional Hilbert subspace of spin.</p>
<p>The spin operator satisfies commutation relations similar to the orbital angular momentum operator, <span class="math display">\[[\hat{S}_i, \hat{S}_j] = \I \hbar \sum_{k = 1}^3 \epsilon_{i j k} \hat{S}_k\]</span></p>
<p>Spin can be combined with orbital angular momentum to form the <strong>total angular momentum</strong> of a particle, <span class="math display">\[\hat{\bm{J}} = \hat{\bm{L}} + \hat{\bm{S}}\]</span> Likewise, there is a standard set of total angular momentum eigenstates <span class="math inline">\(\ket{j m_j}\)</span>, labeled by total angular momentum magnitude <span class="math inline">\(j\)</span> and total angular momentum projection <span class="math inline">\(m_j\)</span>, with completely analogous relations, <span class="math display">\[\begin{gather*}
  \hat{\bm{J}}^2 \ket{j m_j} = \hbar j (j + 1) \ket{j m_j} \\
  \hat{J}_3 \ket{j m_j} = \hbar m_j \ket{j m_j} \\
  [\hat{J}_i, \hat{J}_j] = \I \hbar \sum_{k = 1}^3 \epsilon_{i j k} \hat{J}_k
\end{gather*}\]</span> The quantum numbers are subject to the same constraints as for spin, <span class="math display">\[
  j \in \frac{1}{2} \mathbb{N} \qquad \qquad
  m_j \in M_j
\]</span></p>
<p>Lastly, there is a mathematically similar quantity known as <strong>isospin</strong> <span class="math inline">\(\hat{\bm{I}}\)</span>, which arises in the physics of nucleons. However, unlike spin, it is not physically considered as an angular momentum despite the confusing name. The isospin eigenstates may be denoted <span class="math inline">\(\ket{t m_t}\)</span>, labeled by isospin magnitude <span class="math inline">\(t\)</span> and isospin projection <span class="math inline">\(m_t\)</span>, with relations just like angular momentum, <span class="math display">\[\begin{gather*}
  \hat{\bm{I}}^2 \ket{t m_t} = t (t + 1) \ket{t m_t} \\
  \hat{I}_3 \ket{t m_t} = m_t \ket{t m_t} \\
  [\hat{I}_i, \hat{I}_j] = \I \sum_{k = 1}^3 \epsilon_{i j k} \hat{I}_k
\end{gather*}\]</span> and analogous constraints on the quantum numbers as for spin or total angular momentum.</p>
<p>Because isospin is not a kind of angular momentum, the three components of isospin are abstract and have no physical relation to the <span class="math inline">\(x\)</span>-, <span class="math inline">\(y\)</span>-, <span class="math inline">\(z\)</span>-axes of space. They do not transform under spatial rotations.</p>
<p>For neutrons and protons, isospin is mathematically isomorphic to the spin of spin-<span class="math inline">\(\frac{1}{2}\)</span> particles, so <span class="math inline">\(\hat{\bm{I}}\)</span> too can be defined in terms of Pauli matrices. However, these <em>isospin</em> Pauli matrices act on a different subspace from the <em>spin</em> Pauli matrices, so they are conventionally denoted using <span class="math inline">\(\hat{\bm{\tau}}\)</span> instead of <span class="math inline">\(\hat{\bm{\sigma}}\)</span>: <span class="math display">\[\hat{\bm{I}} = \frac{1}{2} \hat{\bm{\tau}}
= \frac{1}{2}
\begin{bmatrix}
  \hat{\tau}_1 \\
  \hat{\tau}_2 \\
  \hat{\tau}_3 \\
\end{bmatrix}\]</span> Each Pauli matrix <span class="math inline">\(\hat{\tau}_i\)</span> acts on the two-dimensional Hilbert subspace of isospin. The two eigenstates of isospin <span class="math inline">\(\ket{t = \frac{1}{2}, m_t = \pm\frac{1}{2}}\)</span> correspond to neutrons and protons, with two possible conventions:</p>
<ul>
<li><span class="math inline">\(m_t = -\frac{1}{2}\)</span> corresponds to neutrons and <span class="math inline">\(m_t = +\frac{1}{2}\)</span> corresponds to protons (sometimes referred to as the <em>particle physics convention</em>)</li>
<li><span class="math inline">\(m_t = +\frac{1}{2}\)</span> corresponds to neutrons and <span class="math inline">\(m_t = -\frac{1}{2}\)</span> corresponds to protons (sometimes referred to as the <em>nuclear physics convention</em>)</li>
</ul>
<p>Mathematically, the quantities <span class="math inline">\(\hat{\bm{L}}\)</span>, <span class="math inline">\(\hat{\bm{S}}\)</span>, <span class="math inline">\(\hat{\bm{J}}\)</span>, and <span class="math inline">\(\hat{\bm{I}}\)</span> are all very similar. Specifically, these operators are representations of the <span class="math inline">\(\mathfrak{su}(2)\)</span> Lie algebra, which are generators of the special unitary group of two-dimensional matrices, <span class="math inline">\(\mathrm{SU}(2)\)</span>. Elements of the Lie algebra are characterized by commutation relations of the form <span class="math display">\[\begin{gather*}
  [\hat{J}_i, \hat{J}_j] \propto \sum_{k = 1}^3 \epsilon_{i j k} \hat{J}_k
\end{gather*}\]</span> from which many of the familiar properties follow, including the structure of eigenstates and eigenvalues. The operator <span class="math inline">\(\hat{J}^2\)</span> is known as the <em>Casimir element</em> in this context, and commutes with each component <span class="math inline">\(\hat{J}_i\)</span>.</p>
<p>Incidentally, the <span class="math inline">\(\mathrm{SU}(2)\)</span> group is <em>locally</em> similar to the special orthogonal group of 3-dimensional rotations, which means the corresponding <span class="math inline">\(\mathfrak{so}(3)\)</span> Lie algebra is completely isomorphic to <span class="math inline">\(\mathfrak{su}(2)\)</span>. This explains algebraic similarity between <span class="math inline">\(\hat{\bm{L}}\)</span> and <span class="math inline">\(\hat{\bm{S}}\)</span> despite <span class="math inline">\(\hat{\bm{L}}\)</span> being generators of three-dimensional rotations.</p>
<h2 id="sec:clebschgordan"><span class="header-section-number">8.2</span> Clebsch–Gordan coefficients</h2>
<p>There are many situations in which angular momentum is added. The total angular momentum <span class="math inline">\(\hat{\bm{J}} = \hat{\bm{L}} + \hat{\bm{S}}\)</span> is one example. Another situation occurs in many-body systems, where the <strong>composite angular momentum</strong> of two (or more) particles is of interest, <span class="math display">\[\hat{\bm{J}}^{(1, 2)} = \hat{\bm{J}}^{(1)} + \hat{\bm{J}}^{(2)}\]</span> where <span class="math inline">\(\hat{\bm{J}}^{(1)}\)</span> denotes the total angular momentum of particle 1, <span class="math inline">\(\hat{\bm{J}}^{(2)}\)</span> denotes the total angular momentum of particle 2, <span class="math inline">\(\hat{\bm{J}}^{(1, 2)}\)</span> denotes the total angular momentum of both particles together.</p>
<p>Let us consider a general angular momentum-like quantity defined as <span class="math display">\[\hat{\bm{J}} = \hat{\bm{L}} + \hat{\bm{S}}\]</span> with <span class="math inline">\(\hat{\bm{L}}\)</span> and <span class="math inline">\(\hat{\bm{S}}\)</span> being angular momentum-like quantities as well. The discussion in this section is abstract: we do not assign physical interpretations to these quantities. They simply need to be representations of the <span class="math inline">\(\mathfrak{su}(2)\)</span> Lie algebra satisfying the usual commutation relations. (In particular, <span class="math inline">\(\hat{\bm{L}}\)</span> need not be restricted to orbital angular momentum.)</p>
<p>Observe that <span class="math inline">\(\hat{\bm{J}}^2\)</span> commutes with <span class="math inline">\(\hat{\bm{L}}^2\)</span> and <span class="math inline">\(\hat{\bm{S}}^2\)</span>, but does not commute with <span class="math inline">\(\hat{L}_3\)</span> nor <span class="math inline">\(\hat{S}_3\)</span>, because <span class="math display">\[\hat{\bm{J}}^2 = \hat{\bm{L}}^2 + 2 \hat{\bm{L}} \cdot \hat{\bm{S}} + \hat{\bm{S}}^2\]</span> The term <span class="math inline">\(2 \hat{\bm{L}} \cdot \hat{\bm{S}}\)</span> does not commute with <span class="math inline">\(\hat{L}_3\)</span> nor <span class="math inline">\(\hat{S}_3\)</span>. This means we can choose the eigenstates of <span class="math inline">\((\hat{\bm{J}}^2, \hat{J}_3)\)</span> to be eigenstates of <span class="math inline">\(\hat{\bm{L}}^2\)</span> and <span class="math inline">\(\hat{\bm{S}}^2\)</span> as well, but they cannot not in general be eigenstates of <span class="math inline">\(\hat{J}_3\)</span> nor <span class="math inline">\(\hat{S}_3\)</span>. We may label such a state as <span class="math display">\[\ket{j m_j \ell s}\]</span> This is known in general as a <strong>coupled state</strong>, and if <span class="math inline">\(\hat{\bm{L}}\)</span> is orbital angular momentum and <span class="math inline">\(\hat{\bm{S}}\)</span> is spin, then this particular example would be referred to as <em>LS coupling</em>. Such states have the following eigenvalues, <span class="math display">\[\begin{gather*}
  \hat{\bm{J}}^2 \ket{j m_j \ell s} = \hbar j (j + 1) \ket{j m_j \ell s} \\
  \hat{J}_3 \ket{j m_j \ell s} = \hbar m_j \ket{j m_j \ell s} \\
  \hat{\bm{L}}^2 \ket{j m_j \ell s} = \hbar \ell (\ell + 1) \ket{j m_j \ell s} \\
  \hat{\bm{S}}^2 \ket{j m_j \ell s} = \hbar s (s + 1) \ket{j m_j \ell s}
\end{gather*}\]</span></p>
<p>In contrast, if we want an eigenstate of <span class="math inline">\((\hat{J}_3, \hat{\bm{L}}^2, \hat{L}_3, \hat{\bm{S}}^2, \hat{S}_3)\)</span>, then we can simply construct it as a tensor product of the standard eigenstates of <span class="math inline">\((\hat{\bm{L}}^2, \hat{L}_3)\)</span> and <span class="math inline">\((\hat{\bm{S}}^2, \hat{S}_3)\)</span>, denoted <span class="math display">\[\ket{\ell m_\ell s m_s} = \ket{\ell m_\ell} \otimes \ket{s m_s}\]</span> with eigenvalues <span class="math display">\[\begin{gather*}
  \hat{J}_3 \ket{\ell m_\ell s m_s} = \hbar (m_\ell + m_s) \ket{\ell m_\ell s m_s} \\
  \hat{\bm{L}}^2 \ket{\ell m_\ell s m_s} = \hbar \ell (\ell + 1) \ket{\ell m_\ell s m_s} \\
  \hat{L}_3 \ket{\ell m_\ell s m_s} = \hbar m_\ell \ket{\ell m_\ell s m_s} \\
  \hat{\bm{S}}^2 \ket{\ell m_\ell s m_s} = \hbar s (s + 1) \ket{\ell m_\ell s m_s} \\
  \hat{S}_3 \ket{\ell m_\ell s m_s} = \hbar m_s \ket{\ell m_\ell s m_s}
\end{gather*}\]</span> These are known as <strong>uncoupled</strong> states.</p>
<p>The two sets of eigenstates are related by a linear transformation, <span id="eq:cgtransform"><span class="math display">\[\ket{j m_j \ell s} = \sum_{m_\ell \in M_\ell, m_s \in M_s} \ket{\ell m_\ell s m_s} \bkt{\ell m_\ell s m_s | j m_j}\qquad(14)\]</span></span> where <span class="math inline">\(\bkt{\ell m_\ell s m_s | j m_j}\)</span> denotes a set of coefficients known as the <strong>Clebsch–Gordan (CG) coefficients</strong>.</p>
<p>The CG coefficients are subject to a set of constraints – <strong>selection rules</strong> – that we divide into two categories. First, there are the <strong>local selection rules</strong>: <span class="math display">\[\begin{align*}
  &amp;\ell, s, j \in \frac{1}{2}\mathbb{N} &amp;
  &amp;m_\ell \in M_\ell &amp;
  &amp;m_s \in M_s &amp;
  &amp;m_j \in M_j
\end{align*}\]</span> These kinds of constraints are intrinsic to each <span class="math inline">\((j, m)\)</span>-pair and are omnipresent in angular momentum algebra. Thus, to avoid having to repeat ourselves, we will implicitly assume they are satisfied in all equations.</p>
<p>The pairing between the magnitude (<span class="math inline">\(j\)</span>-like) and projection (<span class="math inline">\(m\)</span>-like) variables is established by a notational convention: the subscript on the <span class="math inline">\(m\)</span>-like variable is used to to link to the <span class="math inline">\(j\)</span>-like variable. For example, <span class="math inline">\(m_j\)</span> pairs with <span class="math inline">\(j\)</span>, and <span class="math inline">\(m_\ell\)</span> pairs with <span class="math inline">\(\ell\)</span>. If the <span class="math inline">\(j\)</span> variable itself also has a subscript, then we will typically use the subscript of <span class="math inline">\(j\)</span> directly as a subscript of <span class="math inline">\(m\)</span>, e.g. <span class="math inline">\(m_1\)</span> pairs with <span class="math inline">\(j_1\)</span>, <span class="math inline">\(m_p\)</span> pairs with <span class="math inline">\(j_p\)</span>, etc.</p>
<p>The second category are the <strong>nonlocal selection rules</strong>, consisting of <span class="math display">\[m_j = m_\ell + m_s\]</span> which simply states the additive nature of projections, and <span class="math display">\[|\ell - s| \le j \le \ell + s\]</span> This latter constraint is called the <strong>triangle condition</strong> and is equivalent to the geometrical constraint that <span class="math inline">\(\ell\)</span>, <span class="math inline">\(s\)</span>, and <span class="math inline">\(j\)</span> are lengths of a triangle. It can alternatively be restated as the symmetric combination of constraints, <span class="math display">\[\begin{align*}
  &amp;j \le \ell + s &amp;
  &amp;\ell \le s + j &amp;
  &amp;s \le j + \ell
\end{align*}\]</span></p>
<p>It is convenient to define the CG coefficients such that if any of the selection rules are violated, then the CG coefficient is zero. This allows us to omit the constraints on the summation of <span class="math inline">\(m_\ell\)</span> and <span class="math inline">\(m_s\)</span> in Eq. <a href="print.html#eq:cgtransform">14</a> and simply let the selection rule pick the terms that contribute.</p>
<p>In principle, there can be several conventions for CG coefficients. The obvious choice is to limit ourselves to only <em>real</em> coefficients, but there remains an arbitrary choice in sign, which is then fixed by the Condon–Shortley phase convention.</p>
<p>In this choice, the linear transformation of CG coefficients is completely symmetric, so we can use the same coefficients to undo the coupling: <span class="math display">\[\ket{\ell m_\ell s m_s} = \sum_{j m_j} \ket{j m_j \ell s} \bkt{\ell m_\ell s m_s | j m_j}\]</span> where summation over <span class="math inline">\(j\)</span> and <span class="math inline">\(m_j\)</span> is constrained by the selection rules of CG.</p>
<p>Hence, the CG coefficients satisfy the orthogonality relations, <span class="math display">\[\begin{gather*}
  \sum_{j m_j} \bkt{\ell m_\ell s m_s | j m_j} \bkt{\ell m_\ell&#39; s m_s&#39; | j m_j} = \delta_{m_\ell m_\ell} \delta_{m_s m_s&#39;} \\
  \sum_{m_\ell m_s} \bkt{\ell m_\ell s m_s | j m_j} \bkt{\ell m_\ell s m_s | j&#39; m_j&#39;} = \delta_{j j&#39;} \delta_{m_j m_j&#39;} \tridelta{\ell}{s}{j}
\end{gather*}\]</span> where <span class="math inline">\(\tridelta{\ell}{s}{j}\)</span> is the <strong>triangular delta</strong>, defined as <span id="eq:tridelta"><span class="math display">\[\tridelta{a}{b}{c} = \begin{cases}
  1 &amp; \text{if $|a - b| \le c \le a + b$} \\
  0 &amp; \text{otherwise} \\
\end{cases}\qquad(15)\]</span></span> In other words, the triangular delta is the analog of Kronecker delta for the triangle condition.</p>
<p>There are additional symmetry properties of CG coefficients, but it is more convenient to state them indirectly through a similar quantity known as the Wigner 3-jm symbol.</p>
<h2 id="sec:3jm"><span class="header-section-number">8.3</span> Wigner 3-jm symbol</h2>
<p>The <strong>Wigner 3-jm symbol</strong> is a function of six arguments used for coupling angular momenta with a high degree of symmetry, denoted<a href="print.html#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a> <span class="math display">\[\begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    m_1 &amp; m_2 &amp; m_3 \\
  \end{pmatrix}\]</span> The <span class="math inline">\(j_i\)</span> arguments could be any nonnegative half-integer <span class="math inline">\(\frac{1}{2} \mathbb{N}\)</span> (Eq. <a href="print.html#eq:half-natural">12</a>), including both integers and half-odd integers. The <span class="math inline">\(m_i\)</span> arguments are constrained to the <span class="math inline">\(M_{j_i}\)</span> set as defined in Eq. <a href="print.html#eq:mset">13</a>. These form the local selection rules. The nonlocal selection rules are given by <span class="math display">\[
  |j_1 - j_2| \le j_3 \le j_1 + j_2 \qquad \qquad
  m_1 + m_2 + m_3 = 0
\]</span></p>
<p>The 3-jm symbol is related to the Clebsch–Gordan coefficient by the formula, <span id="eq:cgw3jm"><span class="math display">\[
  \bkt{j_1 m_1 j_2 m_2 | j_{1 2} m_{1 2}} =
  (-)^{2 j_2 + j_{1 2} - m_{1 2}} \jweight{j}_{1 2}
  \begin{pmatrix}
    j_1 &amp; j_{1 2} &amp; j_2 \\
    m_1 &amp; -m_{1 2} &amp; m_2 \\
  \end{pmatrix}
\qquad(16)\]</span></span> where we introduce the shorthand <span id="eq:jweight"><span class="math display">\[\jweight{j} = \sqrt{2 j + 1}\qquad(17)\]</span></span> as the factor appears frequently in angular momentum algebra.</p>
<p>When three angular momentum states are coupled using the 3-jm symbol, <span class="math display">\[\sum_{m_1 m_2 m_3} \begin{pmatrix}
j_1 &amp; j_2 &amp; j_3 \\
m_1 &amp; m_2 &amp; m_3 \\
\end{pmatrix} \ket{j_1 m_1} \otimes \ket{j_2 m_2} \otimes \ket{j_3 m_3}\]</span> the result is invariant (a spherical scalar) under SU(2) transformations.</p>
<p>The 3-jm symbol is given by the following symmetric formula <span class="citation" data-cites="Wigner1993">(Wigner 1993)</span> <span class="math display">\[
  \begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    m_1 &amp; m_2 &amp; m_3 \\
  \end{pmatrix} =
  \sqrt{\Delta(j_1\ j_2\ j_3)}
  \sum_{k_1 k_2 k_3}
    \prod_{i = 1}^3
      \frac{(-)^{j_1 / 2 + k_i}
      \sqrt{(j_i - m_i)! (j_i + m_i)!}
          }{(J / 2 - j_i - k_i)! (J / 2 - j_i + k_i)!}
\]</span> where:</p>
<ul>
<li><p><span class="math inline">\(J = j_1 + j_2 + j_3\)</span></p></li>
<li><p>The summation is performed over all half-integers <span class="math inline">\(k_i\)</span> subject to the following constraints:</p>
<ol type="1">
<li><span class="math inline">\(m_1 + k_2 - k_3 = m_2 + k_3 - k_1 = m_3 + k_1 - k_2 = 0\)</span></li>
<li>Argument of every factorial involving <span class="math inline">\(k_i\)</span> must be a nonnegative integer.</li>
</ol></li>
<li><p><span class="math inline">\(\Delta(j_1\ j_2\ j_3)\)</span> is the <strong>triangle coefficient</strong>:</p>
<p><span class="math display">\[\Delta(j_1\ j_2\ j_3) = \frac{\prod_{i = 1}^3 (J - 2 j_i)!}{(J + 1)!}\]</span></p></li>
</ul>
<p>The summation over <span class="math inline">\(k_i\)</span> has only one effective degree of freedom. If we break the symmetry by choosing <span class="math display">\[k = \frac{J}{2} - j_3 - k_3\]</span> we obtain the more conventional form used by Racah <span class="citation" data-cites="PhysRev.62.438">(Racah 1942)</span> <span class="math display">\[\begin{align*}
  &amp;\begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    m_1 &amp; m_2 &amp; m_3 \\
  \end{pmatrix} \\
  &amp;= \delta_{m_1 + m_2 + m_3, 0} (-)^{j_1 - j_2 - m_3} \sqrt{\Delta(j_1\ j_2\ j_3) \prod_{i = 1}^3 (j_i + m_i)! (j_i - m_i)!} \sum_k \\
&amp;\qquad \frac{(-1)^k}{k! (j_1 + j_2 - j_3 - k)! (j_1 - m_1 - k)! (j_2 + m_2 - k)!} \\
&amp;\qquad \times \frac{1}{(j_3 - j_2 + m_1 + k)! (j_3 - j_1 - m_2 + k)!}
\end{align*}\]</span> The summation is performed over all half-integers <span class="math inline">\(k\)</span> such that the argument of every factorial involving <span class="math inline">\(k\)</span> is a nonnegative integer.</p>
<p>The 3-jm symbol is invariant under even permutations of its columns, <span class="math display">\[
  \begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    m_1 &amp; m_2 &amp; m_3 \\
  \end{pmatrix} =
  \begin{pmatrix}
    j_2 &amp; j_3 &amp; j_1 \\
    m_2 &amp; m_3 &amp; m_1 \\
  \end{pmatrix} =
  \begin{pmatrix}
    j_3 &amp; j_1 &amp; j_2 \\
    m_3 &amp; m_1 &amp; m_2 \\
  \end{pmatrix}
\]</span> Odd permutations lead to a phase factor, <span class="math display">\[
  \begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    m_1 &amp; m_2 &amp; m_3 \\
  \end{pmatrix} =
  (-)^{j_1 + j_2 + j_3}
  \begin{pmatrix}
    j_3 &amp; j_2 &amp; j_1 \\
    m_3 &amp; m_2 &amp; m_1 \\
  \end{pmatrix}
\]</span> The same phase factor arises from time reversal, <span class="math display">\[
  \begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    m_1 &amp; m_2 &amp; m_3 \\
  \end{pmatrix} =
  (-)^{j_1 + j_2 + j_3}
  \begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    -m_1 &amp; -m_2 &amp; -m_3 \\
  \end{pmatrix}
\]</span> The 3-jm symbol also has an additional set of symmetries called Regge symmetries <span class="citation" data-cites="Regge1958">(Regge 1958)</span>, but these are seldomly used in angular momentum algebra. They are, however, useful for storage and caching of 3-jm symbols in computations <span class="citation" data-cites="doi:10.1137/S1064827503422932">(Rasch and Yu 2004)</span>.</p>
<p>The orthogonality relations of CG coefficients carry over to 3-jm symbols. The first orthogonality relation is given by <span id="eq:3jm-orthogonality"><span class="math display">\[\sum_{j_3 m_3}
  \jweight{j}^2_3
  \begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    m_1 &amp; m_2 &amp; m_3 \\
  \end{pmatrix}
  \begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    m_1&#39; &amp; m_2&#39; &amp; m_3 \\
  \end{pmatrix}
  = \delta_{m_1 m_1&#39;} \delta_{m_2 m_2&#39;}\qquad(18)\]</span></span> while the second orthogonality relation is <span id="eq:3jm-orthogonality-2"><span class="math display">\[\sum_{m_2 m_3}
  \begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    m_1 &amp; m_2 &amp; m_3 \\
  \end{pmatrix}
  \begin{pmatrix}
    j_2 &amp; j_3 &amp; j_4 \\
    m_2 &amp; m_3 &amp; m_4 \\
  \end{pmatrix}
  = \frac{\delta_{j_1 j_4} \delta_{m_1 m_4}}{\jweight{j}^2_1}
    \tridelta{j_1}{j_2}{j_3}\qquad(19)\]</span></span></p>
<p>In the case where one of the angular momenta is zero, the 3-jm symbol has a very simple formula: <span id="eq:3jm-zero"><span class="math display">\[(-)^{j_1 - m_1} \begin{pmatrix}
    j_1 &amp; 0 &amp; j_2 \\
    -m_1 &amp; 0 &amp; m_2 \\
  \end{pmatrix} = \frac{\delta_{j_1 j_2} \delta_{m_1 m_2}}{\jweight{j}_1}\qquad(20)\]</span></span></p>
<p>There is a special relation that converts a summation over a 3-jm symbol into Kronecker deltas, <span class="math display">\[\sum_{m_2} (-)^{j_2 - m_2}
  \begin{pmatrix}
    j_2 &amp; j_1 &amp; j_2 \\
    -m_2 &amp; m_1 &amp; m_2 \\
  \end{pmatrix} = \delta_{j_1 0} \delta_{m_1 0} \jweight{j}_2\]</span> Read in reverse, this means one can also represent Kronecker deltas with zeros as a 3-jm symbol.</p>
<h2 id="angular-momentum-diagrams"><span class="header-section-number">8.4</span> Angular momentum diagrams</h2>
<p>Angular momentum diagrams, originally introduced by Jucys (whose name is also translated as Yutsis) <span class="citation" data-cites="Yutsis1962">(Yutsis, Levinson, and Vanagas 1962)</span>, provide a graphical way to manipulate expressions of coupling coefficients of angular momentum states. Our presentation of diagrams differs from <span class="citation" data-cites="Yutsis1962 WORMER200659 BalcarLovesey2009">(Yutsis, Levinson, and Vanagas 1962; Wormer and Paldus 2006; Balcar and Lovesey 2009)</span> in the treatment of arrows.<a href="print.html#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a> In other literature, arrows are used to distinguish between covariant and contravariant angular momenta. However, we treat them mechanically as 1-jm symbols (see Sec. <a href="print.html#sec:1jm">8.4.3</a>). Other differences in presentation are largely superficial. For practical reasons we do not use graphics to describe <span class="math inline">\(\sqrt{2 j + 1}\)</span> factors unlike <span class="citation" data-cites="BalcarLovesey2009">(Balcar and Lovesey 2009)</span>.</p>
<h3 id="nodes"><span class="header-section-number">8.4.1</span> Nodes</h3>
<figure>
<img src="fig-3jm" alt="Figure 5: Diagram of the 3-jm symbol (1 2 3) in Eq. 21" id="fig:3jm" /><figcaption>Figure 5: Diagram of the 3-jm symbol <span class="math inline">\((1 2 3)\)</span> in Eq. <a href="print.html#eq:3jm-node">21</a></figcaption>
</figure>
<p>The main ingredient of angular momentum algebra are 3-jm symbols. Since they are functions of six variables, one might be tempted to introduce a node with six lines emanating from it. However, this quickly becomes unwieldy. Instead, it is better to treat each <span class="math inline">\((j, m)\)</span>-pair as a combined entity.</p>
<p>In Fig. <a href="print.html#fig:3jm">5</a>, we introduce the diagram for the 3-jm symbol, <span id="eq:3jm-node"><span class="math display">\[(1 2 3) = \begin{pmatrix} j_1 &amp; j_2 &amp; j_3 \\ m_1 &amp; m_2 &amp; m_3 \\ \end{pmatrix}\qquad(21)\]</span></span> for which we have assigned the shorthand <span class="math inline">\((1 2 3)\)</span>. Note that 3-jm symbols are the only kind of primitive <strong>node</strong> (vertex) that appears in angular momentum diagrams. Hence, they are the basic building block of such diagrams.</p>
<p>Because 3-jm symbols are invariant under <em>even</em> permutations only, it is necessary to assign a definite ordering to the lines. This is denoted by the circular arrow within the node. In other literature, circular arrows are usually replaced by a sign: <span class="math inline">\(+\)</span> for anticlockwise and <span class="math inline">\(-\)</span> for clockwise.</p>
<h3 id="lines"><span class="header-section-number">8.4.2</span> Lines</h3>
<p>The <strong>lines</strong> (edges) in angular momentum diagrams serve to link the <span class="math inline">\(m\)</span>-type arguments on both ends of the line. The domain <span class="math inline">\(M_j\)</span> over which the <span class="math inline">\(m\)</span> variable is valid is indicated by the label on the line.<a href="print.html#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a> For example, if a line is labeled “1”, this means the <span class="math inline">\(m\)</span> variable must lie within the domain <span class="math inline">\(M_{j_1}\)</span> of the <span class="math inline">\(j_1\)</span> variable.</p>
<p>As a convenience (or perhaps a source of confusion), we introduce a special exception to this interpretation when the label is “0”. In this case, we instead interpret it to indicate that the domain is <span class="math inline">\(M_0 = \{ 0 \}\)</span>, i.e. <span class="math inline">\(m = j = 0\)</span>. To alert the reader of this special interpretation, the line is drawn in a faded grey color.</p>
<figure>
<img src="fig-lines" alt="Figure 6: Degenerate line diagrams: upper diagram: (0&#39; 0&#39;&#39;) in Eq. 23; middle diagram: (1 1&#39;) in Eq. 22; lower diagram: (\check{2} 2&#39;) in Eq. 24" id="fig:lines" /><figcaption>Figure 6: Degenerate line diagrams: upper diagram: <span class="math inline">\((0&#39; 0&#39;&#39;)\)</span> in Eq. <a href="print.html#eq:zero-line">23</a>; middle diagram: <span class="math inline">\((1 1&#39;)\)</span> in Eq. <a href="print.html#eq:mdelta-line">22</a>; lower diagram: <span class="math inline">\((\check{2} 2&#39;)\)</span> in Eq. <a href="print.html#eq:arrow-diagram">24</a></figcaption>
</figure>
<p>Lines can appear in isolation, as shown in Fig. <a href="print.html#fig:lines">6</a>. The middle diagram of Fig. <a href="print.html#fig:lines">6</a> represents the Kronecker delta, <span id="eq:mdelta-line"><span class="math display">\[(1 1&#39;) = \delta_{m_1 m_1&#39;}\qquad(22)\]</span></span> The upper diagram is also a Kronecker delta, but with the extra constraint that <span class="math inline">\(m_0&#39; \in M_0\)</span>, hence <span id="eq:zero-line"><span class="math display">\[(0&#39; 0&#39;&#39;) = \delta_{m_0&#39; m_0&#39;&#39;} \delta_{m_0&#39; 0}\qquad(23)\]</span></span></p>
<h3 id="sec:1jm"><span class="header-section-number">8.4.3</span> Herring–Wigner 1-jm symbol</h3>
<p>In the lower diagram of Fig. <a href="print.html#fig:lines">6</a>, we introduce the notion of an <strong>arrow</strong> on a line. Lines with arrows (<em>directed</em> lines) are associated with a <span class="math inline">\((-)^{j - m}\)</span> phase as well as a sign reversal in <span class="math inline">\(m\)</span>, i.e. the <strong>time-reversal</strong> of angular momentum. More precisely, the diagram represents the quantity: <span id="eq:arrow-diagram"><span class="math display">\[(\check{2} 2&#39;) = \delta_{m_2, -m_2&#39;} (-)^{j_2 - m_2&#39;}\qquad(24)\]</span></span> This is sometimes referred to as a <strong>Herring–Wigner 1-jm symbol</strong>, denoted by <span id="eq:arrow"><span class="math display">\[\begin{pmatrix}
j \\
m \quad m&#39;  \\
\end{pmatrix} = \jweight{j} \begin{pmatrix}
j &amp; 0 &amp; j \\
m &amp; 0 &amp; m&#39;  \\
\end{pmatrix} = \delta_{m, -m&#39;} (-)^{j - m&#39;}\qquad(25)\]</span></span> It acts like a metric tensor for SU(2), since the quantity <span class="math display">\[\sum_{m m&#39;} \begin{pmatrix}
j \\
m \quad m&#39; \\
\end{pmatrix} |j m\rangle \otimes |j m&#39;\rangle\]</span> is invariant under SU(2) transformations.</p>
<h3 id="terminals"><span class="header-section-number">8.4.4</span> Terminals</h3>
<p>The <strong>terminals</strong> of lines, highlighted by the grey circles, represent the free <span class="math inline">\(m\)</span> variables (i.e. those that are not summed over). We label the terminals so as to provide a correspondence to the algebraic equations. For example, in Fig. <a href="print.html#fig:3jm">5</a> we label the terminals “1”, “2”, and “3” to indicate their correspondence to <span class="math inline">\(m_1\)</span>, <span class="math inline">\(m_2\)</span>, and <span class="math inline">\(m_3\)</span>.</p>
<figure>
<img src="fig-3jm-zero" alt="Figure 7: 3-jm symbol when an argument is zero: (\check{1} 0 2) = (1 2) / \jweight{j}_1 in Eq. 20" id="fig:3jm-zero" /><figcaption>Figure 7: 3-jm symbol when an argument is zero: <span class="math inline">\((\check{1} 0 2) = (1 2) / \jweight{j}_1\)</span> in Eq. <a href="print.html#eq:3jm-zero">20</a></figcaption>
</figure>
<p>There is one exceptional situation where a terminal may be absent: when the line is zero. This occurs in, for example, the simplification of a 3-jm symbol when one of the angular momenta is zero in Eq. <a href="print.html#eq:3jm-zero">20</a>. This is depicted diagrammatically in Fig. <a href="print.html#fig:3jm-zero">7</a>, and shown here in shorthand notation: <span class="math display">\[(\check{1} 0 2) = \frac{(1 2)}{\jweight{j}_1}\]</span></p>
<h3 id="closed-diagrams"><span class="header-section-number">8.4.5</span> Closed diagrams</h3>
<figure>
<img src="fig-3jm-orthogonality-2" alt="Figure 8: Second orthogonality relation for 3-jm symbols: (1 2 3) (2 3 4) = (1 4) (1&#39; 2 3) (1&#39; 2 3) in Eq. 19" id="fig:3jm-orthogonality-2" /><figcaption>Figure 8: Second orthogonality relation for 3-jm symbols: <span class="math inline">\((1 2 3) (2 3 4) = (1 4) (1&#39; 2 3) (1&#39; 2 3)\)</span> in Eq. <a href="print.html#eq:3jm-orthogonality-2">19</a></figcaption>
</figure>
<p>In lines with no terminals – the <em>internal</em> lines – their <span class="math inline">\(m\)</span> variables are always summed over. This is exemplified in Fig. <a href="print.html#fig:3jm-orthogonality-2">8</a>, which depicts the second orthogonality relation for 3-jm symbols in Eq. <a href="print.html#eq:3jm-orthogonality-2">19</a> as <span class="math display">\[(1 2 3) (2 3 4) = (1 4) (1&#39; 2 3) (1&#39; 2 3) = (1 4) \{1&#39; 2 3\}\]</span> On the left-hand side, the <span class="math inline">\(m_2\)</span> and <span class="math inline">\(m_3\)</span> lines are both internal and therefore summed over. On the right-hand side, <span class="math inline">\(1 = 4\)</span> label indicates the presence of a <span class="math inline">\(j\)</span>-relating Kronecker delta <span class="math inline">\(\delta_{j_1 j_4}\)</span> in addition to the usual <span class="math inline">\(\delta_{m_1 m_4}\)</span>. In the upper right, there is a special subdiagram <span class="math inline">\((1&#39; 2 3) (1&#39; 2 3)\)</span>, which is in fact the triangular delta <span class="math inline">\(\tridelta{j_1}{j_2}{j_3}\)</span> as defined in Eq. <a href="print.html#eq:tridelta">15</a>.</p>
<figure>
<img src="fig-tridelta" alt="Figure 9: Triangular delta: \{1 2 3\} = (1 2 3) (1 2 3) in Eq. 26" id="fig:tridelta" /><figcaption>Figure 9: Triangular delta: <span class="math inline">\(\{1 2 3\} = (1 2 3) (1 2 3)\)</span> in Eq. <a href="print.html#eq:tridelta-diagram">26</a></figcaption>
</figure>
<p>In diagrammatic notation, the triangular delta is represented by the following sum as shown in Fig. <a href="print.html#fig:tridelta">9</a>: <span id="eq:tridelta-diagram"><span class="math display">\[
  \{1 2 3\} = (1 2 3) (1 2 3) = \sum_{m_1 m_2 m_3}
  \begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    m_1 &amp; m_2 &amp; m_3 \\
  \end{pmatrix}^2 = \tridelta{j_1}{j_2}{j_3}
\qquad(26)\]</span></span></p>
<p>The triangular delta is the simplest <strong>irreducible closed diagram</strong>: it cannot be broken down into simpler components in a nontrivial way (<em>irreducible</em>), and there are no free <span class="math inline">\(m\)</span>-type variables (<em>closed</em>). Specifically, we say a diagram is irreducible if it cannot be factorized into subdiagrams without either (a) introducing a summation over a new <span class="math inline">\(j\)</span>-type variable, or (b) introducing another triangular delta. The (b) constraint comes from the fact that a triangular delta can be split (factorized) into a finite number of identical triangular deltas, which is not very interesting.</p>
<p>The triangular delta is a rather degenerate case of an irreducible closed diagram. In Secs. <a href="print.html#sec:6j">8.8.2</a>, <a href="print.html#sec:9j">8.8.3</a>, we introduce more interesting cases: the 6-j and 9-j symbols. In graph theory, irreducible closed diagrams correspond to cubic graphs that are <em>cyclically 4-connected</em>, namely, 3-edge-connected graphs in which every split by the deletion of 3 edges yields at least one disconnected vertex. The triangular delta is unusual in that it is the only non-simple graph of this family.</p>
<h3 id="sec:summed-lines"><span class="header-section-number">8.4.6</span> Summed lines</h3>
<figure>
<img src="fig-3jm-orthogonality" alt="Figure 10: First orthogonality relation for 3-jm symbols: \sum_{j_3} \jweight{j}_3^2 (1 2 3) (1&#39; 2&#39; 3) = (1 1&#39;) (2 2&#39;) in Eq. 18" id="fig:3jm-orthogonality" /><figcaption>Figure 10: First orthogonality relation for 3-jm symbols: <span class="math inline">\(\sum_{j_3} \jweight{j}_3^2 (1 2 3) (1&#39; 2&#39; 3) = (1 1&#39;) (2 2&#39;)\)</span> in Eq. <a href="print.html#eq:3jm-orthogonality">18</a></figcaption>
</figure>
<p>There are a few occasions where the <span class="math inline">\(j\)</span>-type variables do need to be summed over. This occurs in the first orthogonality relation in Eq. <a href="print.html#eq:3jm-orthogonality">18</a>, shown diagrammatically in Fig. <a href="print.html#fig:3jm-orthogonality">10</a> as <span class="math display">\[\sum_{j_3} \jweight{j}_3^2 (1 2 3) (1&#39; 2&#39; 3) = (1 1&#39;) (2 2&#39;)\]</span> The doubling of the line serves as an additional reminder that <span class="math inline">\(j_3\)</span> is being summed over.</p>
<h2 id="phase-rules"><span class="header-section-number">8.5</span> Phase rules</h2>
<p>Let us begin by considering just one particular angular momentum pair <span class="math inline">\((j_i, m_i)\)</span> in isolation. In this case, we have the properties <span class="math display">\[\begin{align*}
  (-)^{4 j_i} &amp;= 1 &amp;
  (-)^{2 (j_i - m_i)} &amp;= 1
\end{align*}\]</span> We may call this the <strong>local phase rules</strong>. Given an arbitrary phase <span class="math inline">\((-)^{a j_i + b m_i}\)</span> with <span class="math inline">\(a, b \in \mathbb{Z}\)</span>, one can always use local rules to <em>uniquely</em> decompose the phase as <span class="math display">\[(-)^{a j_i + b m_i} = (-)^{c j_i + d (j_i - m_i)}\]</span> where <span class="math inline">\(c \in \{0, 1, 2, 3\}\)</span> and <span class="math inline">\(d \in \{0, 1\}\)</span>. We will call this the <strong>locally canonical</strong> form of the phase. Hence, phases of a single angular momentum may be represented as a pair <span class="math inline">\((c, d)\)</span> where <span class="math inline">\(c\)</span> uses modulo-4 arithmetic and <span class="math inline">\(d\)</span> uses modulo-2 arithmetic. There are only 8 unique phases: <span class="math display">\[\begin{array}{r|rrrr}
&amp; 0j &amp; 1j &amp; 2j &amp; 3j \\
\hline
0(j-m) &amp;     0 &amp; +j &amp;    2j &amp; -j \\
1(j-m) &amp; j - m &amp; +m &amp; j + m &amp; -m \\
\end{array}\]</span> The table has a toroidal topology: it wraps around both horizontally and vertically.</p>
<p>Canonicalization provides a mechanical approach for deciding whether two phases are equivalent. Unfortunately, when non-local rules are involved, there is no longer an obvious way to canonicalize phases – the symmetries of the phases become entangled with the topology of the angular momentum diagram. Nonetheless, local canonicalization provides an easy way to eliminate one of the sources of redundancy.</p>
<p>It is common to work with only real recoupling coefficients, thus it is unusual for <span class="math inline">\((-)^j\)</span> or <span class="math inline">\((-)^{3 j}\)</span> to appear in isolation. They typically appear in groups, such as triplets <span class="math inline">\((-)^{j_1 + j_2 + j_3}\)</span> or quadruplets.</p>
<figure>
<img src="fig-arrow-cancellation" alt="Figure 11: Upper diagram: arrow cancellation: (\check{1} \check{1}&#39;) = (1 1&#39;) in Eq. 27; lower diagram: arrow reversal: (\check{1} 1&#39;) = (-)^{2 j_1} (1 \check{1}) in Eq. 28" id="fig:arrow-cancellation" /><figcaption>Figure 11: Upper diagram: arrow cancellation: <span class="math inline">\((\check{1} \check{1}&#39;) = (1 1&#39;)\)</span> in Eq. <a href="print.html#eq:arrow-cancellation">27</a>; lower diagram: arrow reversal: <span class="math inline">\((\check{1} 1&#39;) = (-)^{2 j_1} (1 \check{1})\)</span> in Eq. <a href="print.html#eq:arrow-reversal">28</a></figcaption>
</figure>
<p>Note that the <span class="math inline">\((-)^{j_i - m_i}\)</span> phase comes from the 1-jm symbol, which are arrows in diagrammatic notation (see Eq. <a href="print.html#eq:arrow">25</a>). The algebraic properties of the 1-jm symbol can be encoded as two arrow rules in diagrammatic theory. The first rule is <strong>arrow cancellation</strong>: <span id="eq:arrow-cancellation"><span class="math display">\[\sum_{m_1&#39;&#39;} \begin{pmatrix}
j \\
m \quad m&#39;&#39;  \\
\end{pmatrix} \begin{pmatrix}
j \\
m&#39; \quad m&#39;&#39;  \\
\end{pmatrix} = \delta_{m, m&#39;}\qquad(27)\]</span></span> which is depicted in the upper diagram of Fig. <a href="print.html#fig:arrow-cancellation">11</a>. In the lower diagram, we have the second rule of <strong>arrow reversal</strong>: <span id="eq:arrow-reversal"><span class="math display">\[\begin{pmatrix}
j \\
m \quad m&#39;  \\
\end{pmatrix} = (-)^{2 j} \begin{pmatrix}
j \\
m&#39; \quad m  \\
\end{pmatrix}\qquad(28)\]</span></span></p>
<p>Now let us consider the <strong>nonlocal phase rules</strong>, which govern phase triplets related by 3-jm symbols. These arise from the properties of the 3-jm symbol and the selection rules.</p>
<p>One of the nonlocal selection rules of the 3-jm symbol is <span class="math display">\[m_1 + m_2 + m_3 = 0\]</span> This implies that <span class="math inline">\(m_1\)</span>, <span class="math inline">\(m_2\)</span>, and <span class="math inline">\(m_3\)</span> are either all integers or one of them is an integer and the rest are half-odd integers. The <span class="math inline">\(j_1\)</span>, <span class="math inline">\(j_2\)</span>, and <span class="math inline">\(j_3\)</span> variables are constrained by this same condition as a consequence. Thus we have the <strong>sweeping rule</strong>: <span class="math display">\[
  \begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    m_1 &amp; m_2 &amp; m_3 \\
  \end{pmatrix}
  =
  (-)^{2 j_1 + 2 j_2 + 2 j_3}
  \begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    m_1 &amp; m_2 &amp; m_3 \\
  \end{pmatrix}
\]</span> This rule enables <span class="math inline">\((-)^{2 j}\)</span>-type phases to be introduced, eliminated, or migrated (“sweeped”) around the diagram. In contrast, <span class="math inline">\((-)^j\)</span>-type phases by themselves are generally immobile without the aid of Kronecker deltas.</p>
<figure>
<img src="fig-triple-arrow" alt="Figure 12: Triple arrow rule: (1 2 3) = (\check{1} \check{2} \check{3}) in Eq. 29" id="fig:triple-arrow" /><figcaption>Figure 12: Triple arrow rule: <span class="math inline">\((1 2 3) = (\check{1} \check{2} \check{3})\)</span> in Eq. <a href="print.html#eq:triple-arrow">29</a></figcaption>
</figure>
<p>The analog of the sweeping rule for arrows is the <strong>triple arrow rule</strong>, which allows three similar arrows to be introduced around any 3-jm node: <span id="eq:triple-arrow"><span class="math display">\[
  \begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    m_1 &amp; m_2 &amp; m_3 \\
  \end{pmatrix}
  =
  (-)^{j_1 - m_1 + j_2 - m_2 + j_3 - m_3}
  \begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    -m_1 &amp; -m_2 &amp; -m_3 \\
  \end{pmatrix}
\qquad(29)\]</span></span> Like the sweeping rule, these can be used introduce, eliminate, or migrate arrows around the diagram.</p>
<figure>
<img src="fig-node-reversal" alt="Figure 13: Node reversal rule: (1 2 3) = (-)^{j_1 + j_2 + j_3} (3 2 1) in Eq. 30" id="fig:node-reversal" /><figcaption>Figure 13: Node reversal rule: <span class="math inline">\((1 2 3) = (-)^{j_1 + j_2 + j_3} (3 2 1)\)</span> in Eq. <a href="print.html#eq:node-reversal">30</a></figcaption>
</figure>
<p>Lastly, it is often necessary to reverse the order of arguments in a 3-jm symbol. This is handled by the <strong>node reversal rule</strong>, which allows the orientation of a 3-jm symbol to be reversed at the cost of three <span class="math inline">\((-)^j\)</span>-type phases: <span id="eq:node-reversal"><span class="math display">\[
  \begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    m_1 &amp; m_2 &amp; m_3 \\
  \end{pmatrix}
  =
  (-)^{j_1 + j_2 + j_3}
  \begin{pmatrix}
    j_3 &amp; j_2 &amp; j_1 \\
    m_3 &amp; m_2 &amp; m_1 \\
  \end{pmatrix}
\qquad(30)\]</span></span></p>
<h2 id="sec:wigner-eckart"><span class="header-section-number">8.6</span> Wigner–Eckart theorem</h2>
<p>The Wigner–Eckart theorem allows matrix elements of a spherical tensor operator to be factorized into an operator-dependent, <span class="math inline">\(m\)</span>-independent component and an operator-independent, <span class="math inline">\(m\)</span>-dependent factor. The latter factor is composed of a 3-jm symbol (or equivalently a CG coefficient). The theorem is highly advantageous for numerical computations as summations over 3-jm symbols can often be simplified substantially.</p>
<p>The usual statement of the theorem is as follows: if <span class="math inline">\(\hat{T}^{j_T}_{m_T}\)</span> is a rank-<span class="math inline">\(j_T\)</span> spherical tensor operator with components labeled by <span class="math inline">\(m_T\)</span>, then its matrix elements can be factorized in the following manner <span class="math display">\[\bra{j_1 m_1 \alpha_1} \hat{T}^{j_T}_{m_T} \ket{j_2 m_2 \alpha_2}
  = (-)^{j_1 - m_1}
  \begin{pmatrix}
    j_1 &amp; j_T &amp;  j_2 \\
    -m_1 &amp; m_T &amp; m_2
  \end{pmatrix}
  \bkt{j_1 \alpha_1 \| \hat{T}^{j_T} \| j_2 \alpha_2}\]</span> where <span class="math inline">\(\bkt{j_1 \alpha_1 \| \hat{T}^{j_T} \| j_2 \alpha_2}\)</span> is called the <strong>reduced matrix element under the 3-jm convention</strong>. This is the same convention as the one used in <span class="citation" data-cites="PhysRev.62.438">(Racah 1942)</span>.</p>
<p>There are several other conventions. Some conventions differ by a factor of <span class="math inline">\((-)^{2 j_T}\)</span>: <span class="math display">\[\begin{align*}
  \bra{j_1 m_1 \alpha_1} \hat{T}^{j_T}_{m_T} \ket{j_2 m_2 \alpha_2}
  &amp;= (-)^{2 j_T + j_1 - m_1}
  \begin{pmatrix}
    j_1 &amp; j_T &amp;  j_2 \\
    -m_1 &amp; m_T &amp; m_2
  \end{pmatrix}
  \bkt{j_1 \alpha_1 \| \hat{T}^{j_T} \| j_2 \alpha_2}&#39; \\
  &amp;= \frac{1}{\jweight{j}_1} \bkt{j_2 m_2 j_T m_T | j_1 m_1}
  \bkt{j_1 \alpha_1 \| \hat{T}^{j_T} \| j_2 \alpha_2}&#39;
\end{align*}\]</span> This phase factor is often irrelevant as <span class="math inline">\(j_T\)</span> is commonly an integer. Another convention is to simply use the CG coefficient directly: <span class="math display">\[\bra{j_1 m_1 \alpha_1} \hat{T}^{j_T}_{m_T} \ket{j_2 m_2 \alpha_2}
  = \bkt{j_2 m_2 j_T m_T | j_1 m_1}
  \bkt{j_1 \alpha_1 \| \hat{T}^{j_T} \| j_2 \alpha_2}&#39;&#39;\]</span> We call <span class="math inline">\(\bkt{j_1 \alpha_1 \| \hat{T}^{j_T} \| j_2 \alpha_2}&#39;&#39;\)</span> the <strong>reduced matrix element under the CG convention</strong>. This convention is convenient for scalar operators where it simplifies to: <span class="math display">\[\bra{j_1 m_1 \alpha_1} \hat{T}^0_0 \ket{j_2 m_2 \alpha_2}
  = \delta_{j_1 j_2} \delta_{m_1 m_2} \bkt{j_1 \alpha_1 \| \hat{T}^0 \| j_2 \alpha_2}&#39;&#39;\]</span></p>
<p>An unusual way to state the Wigner–Eckart theorem is through the following inverse equation: <span class="math display">\[\bkt{j_1 \alpha_1 \| \hat{T}^{j_T} \| j_2 \alpha_2}
  = \sum_{m&#39;_1 m_T m&#39;_2}
  (-)^{j_1 - m&#39;_1}
  \begin{pmatrix}
    j_1 &amp; j_T &amp; j_2 \\
    -m&#39;_1 &amp; m_T &amp; m&#39;_2
  \end{pmatrix}
  \bra{j_1 m&#39;_1 \alpha_1} \hat{T}^{j_T}_{m_T} \ket{j_2 m&#39;_2 \alpha_2}\]</span> The advantage of this form is that it can be readily translated to diagrams. Of course, in practice the summation is unnecessary as one could simply compute: <span class="math display">\[\bkt{j_1 \alpha_1 \| \hat{T}^{j_T} \| j_2 \alpha_2}
  = \frac{(-)^{j_1} \bra{j_1 0 \alpha_1} \hat{T}^{j_T}_0 \ket{j_2 0 \alpha_2}}{\begin{pmatrix}
    j_1 &amp; j_T &amp;  j_2 \\
    0 &amp; 0 &amp; 0
  \end{pmatrix}}\]</span></p>
<h2 id="sec:cutting-rule"><span class="header-section-number">8.7</span> Separation rules</h2>
<figure>
<img src="fig-cutting-rule" alt="Figure 14: Separation rules: (a) single-line separation rule: f(j_1, m_1) = \delta_{j_1 0} \delta_{m_1 0} f(0, 0) in Eq. 31; (b) double-line separation rule; (c) triple-line separation rule." id="fig:cutting-rule" /><figcaption>Figure 14: Separation rules: (a) single-line separation rule: <span class="math inline">\(f(j_1, m_1) = \delta_{j_1 0} \delta_{m_1 0} f(0, 0)\)</span> in Eq. <a href="print.html#eq:cutting-rule">31</a>; (b) double-line separation rule; (c) triple-line separation rule.</figcaption>
</figure>
<p>There is a general diagrammatic rule that is closely related to the more specialized Wigner–Eckart theorem. Suppose we have an angular momentum diagram <span class="math inline">\(f(j_1, m_1)\)</span> composed of 3-jm nodes with exactly one external line and every one of its internal lines has an arrow. Then, we can partition the diagram into two pieces: <span id="eq:cutting-rule"><span class="math display">\[f(j_1, m_1) = \delta_{j_1 0} \delta_{m_1 0} f(0, 0)\qquad(31)\]</span></span> In other words, <span class="math inline">\(f\)</span> must be invariant (a spherical scalar). We call this the <strong>single-line separation rule</strong> because it allows us to cut the lone external line to separate the diagram into two disconnected pieces. This rule is shown in Fig. <a href="print.html#fig:cutting-rule">14</a> (a).</p>
<figure>
<img src="fig-cutting-rule-schematic-proof" alt="Figure 15: A schematic derivation of the separation rule for five lines. The topologies of the diagrams are shown but most details (such as phases or other factors) have been omitted. Double lines indicate summed lines as before (Sec. 8.4.6). The meaning of the yellow rectangles is the same as in Fig. 14." id="fig:cutting-rule-schematic-proof" /><figcaption>Figure 15: A schematic derivation of the separation rule for five lines. The topologies of the diagrams are shown but most details (such as phases or other factors) have been omitted. Double lines indicate summed lines as before (Sec. <a href="print.html#sec:summed-lines">8.4.6</a>). The meaning of the yellow rectangles is the same as in Fig. <a href="print.html#fig:cutting-rule">14</a>.</figcaption>
</figure>
<p>This seemingly simple rule can be used to separate arbitrarily complicated diagrams through a mechanical process (Fig. <a href="print.html#fig:cutting-rule-schematic-proof">15</a>) in which lines are repeatedly pairwise combined using the first orthogonality relation (Fig. <a href="print.html#fig:3jm-orthogonality">10</a>) until a single line remains, which can then be cut using Eq. <a href="print.html#eq:cutting-rule">31</a>.</p>
<p>Separation rules for the special cases of two and three lines are shown in Fig. <a href="print.html#fig:cutting-rule">14</a> (b) and (c) respectively. Both can be derived using (a) and the first orthogonality relation. Analogous separation rules for four or more lines can be derived, but they always introduce new angular momentum variables to be summed over. With six or more lines, there can be multiple non-equivalent separation rules.</p>
<p>Separation rules are used in the derivation of recoupling coefficients. They can also be used to <em>derive</em> the second orthogonality relation of 3-jm symbols.</p>
<h2 id="recoupling-coefficients-and-3n-j-symbols"><span class="header-section-number">8.8</span> Recoupling coefficients and 3n-j symbols</h2>
<h3 id="sec:tridelta"><span class="header-section-number">8.8.1</span> Triangular delta</h3>
<p>Consider the usual CG coupling of <span class="math inline">\(\ket{j_1 m_1}\)</span> and <span class="math inline">\(\ket{j_2 m_2}\)</span> to form the coupled state <span class="math inline">\(\ket{(12) j_{1 2} m_{1 2} j_1 j_2}\)</span> as in Eq. <a href="print.html#eq:cgtransform">14</a>, <span class="math display">\[\ket{(12) j_{1 2} m_{1 2} j_1 j_2} = \sum_{m_1 m_2} \ket{j_1 m_1 j_2 m_2} \bkt{1, 2 | 12}\]</span> Here, we introduce a shorthand for Clebsch–Gordan coefficients: <span class="math display">\[\bkt{a, b | c} = \bkt{j_a m_a j_b m_b | j_c m_c}\]</span> We call this coupling “(12)” because in the CG coefficient angular momentum 1 appears before angular momentum 2. We could have also coupled them in reverse: <span class="math display">\[\ket{(21) j_{1 2} m_{1 2} j_1 j_2} = \sum_{m_1 m_2} \ket{j_1 m_1 j_2 m_2} \bkt{2, 1 | 12}\]</span> This leads to a <em>different</em> set of coupled eigenstates, which we call (21). They are still eigenstates of <span class="math inline">\((\hat{\bm{J}}^{(12)})^2\)</span>, <span class="math inline">\(\hat{J}^{(12)}_3\)</span>, <span class="math inline">\(\hat{\bm{J}}^{(1)}\)</span>, and <span class="math inline">\(\hat{\bm{J}}^{(2)}\)</span>, just like the (12) states. Since the two states are bases of the same Hilbert space we expect there to exist a linear transformation between the two: <span class="math display">\[\ket{(21) j_{1 2} m_{1 2} j_1 j_2} = \sum_{j_{1 2}&#39; j_1&#39; j_2&#39;} \ket{(12) j_{1 2}&#39; m_{1 2} j_1&#39; j_2&#39;} \bkt{(12) j_{1 2}&#39; j_1&#39; j_2&#39; | (21) j_{1 2} j_2 j_1}\]</span> The quantity <span class="math inline">\(\bkt{(12) j_{1 2}&#39; j_1&#39; j_2&#39; | (21) j_{1 2} j_2 j_1}\)</span> denotes the <strong>recoupling</strong> coefficient from (12)-coupling to (21)-coupling, one of the simplest recoupling coefficients. From symmetry considerations alone (see Sec. <a href="print.html#sec:cutting-rule">8.7</a>) we already deduced that the coefficient is both block diagonal in <span class="math inline">\(m_{1 2}\)</span> and does not depend on <span class="math inline">\(m_{1 2}\)</span>.</p>
<p>Each recoupling coefficient has a set of selection rules that can be determined in a straightforward manner. In this case, we know that <span class="math inline">\(j_{1 2}&#39; = j_{1 2}\)</span>, <span class="math inline">\(j_1&#39; = j_1\)</span>, and <span class="math inline">\(j_2&#39; = j_2\)</span>, because they are eigenvalues of the same operators. Thus we find that <span class="math display">\[\bkt{(12) j_{1 2}&#39; j_1&#39; j_2&#39; | (21) j_{1 2} j_2 j_1} =
\delta_{j_{1 2}&#39; j_{1 2}} \delta_{j_1&#39; j_1} \delta_{j_2&#39; j_2} \bkt{(12) j_{1 2} j_1 j_2 | (21) j_{1 2} j_2 j_1}\]</span> The remaining part of this particular recoupling coefficient has a very simple formula: <span id="eq:cg-flip-phase"><span class="math display">\[\begin{aligned} \bkt{(12) j_{1 2} j_1 j_2 | (21) j_{1 2} j_2 j_1} &amp;= \frac{1}{\jweight{j}_{1 2}^2}\sum_{m_1 m_2 m_{1 2}} \bkt{1, 2 | 12} \bkt{2, 1 | 12} \\ &amp;= (-)^{j_1 + j_2 - j_{1 2}} \tridelta{j_1}{j_2}{j_3} \end{aligned}\qquad(32)\]</span></span> We thus observe that the coupling of states is <em>not</em> commutative, even though the addition of angular momenta operators is.</p>
<p>Notice that the recoupling coefficient contains a triangular delta <span class="math inline">\(\tridelta{j_1}{j_2}{j_3}\)</span>, which was previously defined in Eq. <a href="print.html#eq:tridelta">15</a> and shown diagrammatically in Fig. <a href="print.html#fig:tridelta">9</a>. As we have noted, the triangular delta is the simplest irreducible closed diagram. This is a general property of recoupling coefficients: every recoupling coefficient can be decomposed into a product of irreducible closed diagrams, times simple factor containing phases or <span class="math inline">\(\jweight{j}\)</span>-like quantities.</p>
<p>As we will see in the next few sections, the irreducible closed diagrams are more commonly known as <strong>3n-j symbols</strong>, which contains both 6-j symbols and 9-j symbols. The triangular delta is part of this family too, thus it is fitting to give it the name of a <em>3-j symbol</em> by analogy <span class="citation" data-cites="WORMER200659">(Wormer and Paldus 2006)</span>. However, we do not use this terminology to avoid the inevitable confusion with <em>3-jm symbols</em>.</p>
<h3 id="sec:6j"><span class="header-section-number">8.8.2</span> 6-j symbol</h3>
<p>Now, consider another case where we have a sum of three angular momenta <span class="math display">\[\hat{\bm{J}}^{(123)} = \hat{\bm{J}}^{(1)} + \hat{\bm{J}}^{(2)} + \hat{\bm{J}}^{(3)}\]</span> and we want to find a set of coupled eigenstates for <span class="math inline">\((\hat{\bm{J}}^{(123)})^2\)</span> and <span class="math inline">\(\hat{J}^{(123)}_3\)</span>. One possibility is to first obtain eigenstates <span class="math inline">\(\ket{j_{1 2} m_{1 2} j_1 j_2}\)</span> of <span class="math inline">\((\hat{\bm{J}}^{(12)})^2\)</span> and <span class="math inline">\(\hat{J}^{(12)}_3\)</span>, where <span class="math inline">\(\hat{\bm{J}}^{(12)}\)</span> is defined as <span class="math display">\[\hat{\bm{J}}^{(12)} = \hat{\bm{J}}^{(1)} + \hat{\bm{J}}^{(2)}\]</span> and then couple these states with <span class="math inline">\(\ket{j_3 m_3}\)</span>, leading to states of the form <span class="math display">\[\ket{((1 2) 3) j_{1 2 3} m_{1 2 3} j_{1 2} j_1 j_2 j_3} = \sum_{m_1 m_2 m_{1 2} m_3} \ket{j_1 m_1 j_2 m_2 j_3 m_3} \bkt{1, 2 | 12} \bkt{12, 3 | 123}\]</span> which are eigenstates of <span class="math inline">\((\hat{\bm{J}}^{(123)})^2\)</span>, <span class="math inline">\(\hat{J}^{(123)}_3\)</span>, <span class="math inline">\((\hat{\bm{J}}^{(12)})^2\)</span>, <span class="math inline">\((\hat{\bm{J}}^{(1)})^2\)</span>, <span class="math inline">\((\hat{\bm{J}}^{(2)})^2\)</span>, and <span class="math inline">\((\hat{\bm{J}}^{(3)})^2\)</span>.</p>
<p>It is clear that we have introduced a bias to the <span class="math inline">\(\hat{\bm{J}}^{(12)}\)</span> here. What if instead we couple <span class="math inline">\(\hat{\bm{J}}^{(2)}\)</span> to <span class="math inline">\(\hat{\bm{J}}^{(3)}\)</span>, and then couple <span class="math inline">\(\hat{\bm{J}}^{(1)}\)</span> to that? Then we would obtain the states <span class="math display">\[\ket{(1 (2 3)) j_{1 2 3} m_{1 2 3} j_{2 3} j_1 j_2 j_3} = \sum_{m_1 m_2 m_3 m_{2 3}} \ket{j_1 m_1 j_2 m_2 j_3 m_3} \bkt{2, 3 | 23} \bkt{1, 23 | 123}\]</span> Or we also couple <span class="math inline">\(\hat{\bm{J}}^{(1)}\)</span> to <span class="math inline">\(\hat{\bm{J}}^{(3)}\)</span>, and then to <span class="math inline">\(\hat{\bm{J}}^{(2)}\)</span>, leading to the states <span class="math display">\[\ket{((1 3) 2) j_{1 2 3} m_{1 2 3} j_{1 3} j_1 j_2 j_3} = \sum_{m_1 m_3 m_{1 3} m_2} \ket{j_1 m_1 j_2 m_2 j_3 m_3} \bkt{1, 3 | 13} \bkt{13, 2 | 123}\]</span> These choices lead to very different sets of eigenstates that are related by nontrivial coefficients. There are also several other ways to couple, such as ((21)3), (1(32)), (2(13)), etc, but they are equivalent to one of the above three up to a phase factor akin to Eq. <a href="print.html#eq:cg-flip-phase">32</a>.</p>
<p>To convert from, say, ((12)3) to (1(23)), we would require the following <span class="math inline">\(m\)</span>-independent recoupling coefficient: <span class="math display">\[\bkt{((12)3) j_{1 2 3}&#39; j_{1 2} j_1&#39; j_2&#39; j_3&#39; | (1(23)) j_{1 2 3} j_{2 3} j_1 j_2 j_3}\]</span> The selection rules tell us that the primed quantities have to match the unprimed quantities. So the only nontrivial elements are: <span class="math display">\[\begin{gather*}
  \bkt{((12)3) j_{1 2 3} j_{1 2} j_1 j_2 j_3 | (1(23)) j_{1 2 3} j_{2 3} j_1 j_2 j_3} \\
  = \frac{1}{\jweight{j}_{1 2 3}^2} \sum_{m_1 m_2 m_3 m_{1 2} m_{2 3} m_{1 2 3}} \bkt{12, 3 | 123} \bkt{1, 2 | 12} \bkt{2, 3 | 23} \bkt{1, 23 | 123}
\end{gather*}\]</span> Hence, the coupling of states is also not associative, even though the addition of angular momenta operators is.</p>
<figure>
<img src="fig-6j" alt="Figure 16: 6-j symbol: \{1 2 3 4 5 6\} = (1 2 3) (1 \check{5} 6) (2 \check{6} 4) (3 \check{4} 5) in Eq. 33" id="fig:6j" /><figcaption>Figure 16: 6-j symbol: <span class="math inline">\(\{1 2 3 4 5 6\} = (1 2 3) (1 \check{5} 6) (2 \check{6} 4) (3 \check{4} 5)\)</span> in Eq. <a href="print.html#eq:6j">33</a></figcaption>
</figure>
<p>The recoupling coefficient <span class="math inline">\(\bkt{((12)3) j_{1 2 3} j_{1 2} j_1 j_2 j_3 | (1(23)) j_{1 2 3} j_{2 3} j_1 j_2 j_3}\)</span> can be expressed in terms of a quantity called the <strong>6-j symbol</strong>, defined as <span id="eq:6j"><span class="math display">\[\begin{aligned}
  \begin{Bmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    j_4 &amp; j_5 &amp; j_6 \\
  \end{Bmatrix}
  &amp;= \sum_{m_1 m_2 m_3 m_4 m_5 m_6}
  (-)^{j_4 - m_4 + j_5 - m_5 + j_6 - m_6}
  \begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    m_1 &amp; m_2 &amp; m_3 \\
  \end{pmatrix} \\
  &amp;\quad
  \begin{pmatrix}
    j_1 &amp; j_5 &amp; j_6 \\
    m_1 &amp; -m_5 &amp; m_6 \\
  \end{pmatrix}
  \begin{pmatrix}
    j_2 &amp; j_6 &amp; j_4 \\
    m_2 &amp; -m_6 &amp; m_4 \\
  \end{pmatrix}
  \begin{pmatrix}
    j_3 &amp; j_4 &amp; j_5 \\
    m_3 &amp; -m_4 &amp; m_5 \\
  \end{pmatrix}
\end{aligned}\qquad(33)\]</span></span> Fig. <a href="print.html#fig:6j">16</a> shows the diagram for a 6-j symbol, which corresponds to the following diagrammatic shorthand: <span class="math display">\[\{1 2 3 4 5 6\} = (1 2 3) (1 \check{5} 6) (2 \check{6} 4) (3 \check{4} 5)\]</span></p>
<p>We may now write the aforementioned recoupling coefficient as: <span class="math display">\[\begin{gather*}
  \bkt{((12)3) j_{1 2 3} j_{1 2} j_1 j_2 j_3 | (1(23)) j_{1 2 3} j_{2 3} j_1 j_2 j_3}
  = (-)^{j_1 + j_2 + j_3 + j_{1 2 3}} \jweight{j}_{1 2} \jweight{j}_{2 3} \begin{Bmatrix}
    j_1 &amp; j_2 &amp; j_{1 2} \\
    j_3 &amp; j_{1 2 3} &amp; j_{2 3} \\
  \end{Bmatrix}
\end{gather*}\]</span></p>
<p>The 6-j symbol has the nonlocal selection rules corresponding to those of its 3-jm nodes, which are simply the following triangle conditions: <span class="math display">\[\begin{align*}
  &amp;\tridelta{j_1}{j_2}{j_3} &amp;
  &amp;\tridelta{j_1}{j_5}{j_6} &amp;
  &amp;\tridelta{j_2}{j_6}{j_4} &amp;
  &amp;\tridelta{j_3}{j_4}{j_5} &amp;
\end{align*}\]</span></p>
<p>Note that Fig. <a href="print.html#fig:6j">16</a> is only one out of several ways to draw a 6-j symbol. It has in fact several interesting symmetries that are not immediately obvious. For example, the columns of the 6-j symbol can be permuted <em>arbitrarily</em> (both odd and even permutations): <span class="math display">\[\begin{align*}
  \begin{Bmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    j_4 &amp; j_5 &amp; j_6 \\
  \end{Bmatrix}
  =
  \begin{Bmatrix}
    j_2 &amp; j_1 &amp; j_3 \\
    j_5 &amp; j_4 &amp; j_6 \\
  \end{Bmatrix}
  =
  \begin{Bmatrix}
    j_2 &amp; j_3 &amp; j_1 \\
    j_5 &amp; j_6 &amp; j_4 \\
  \end{Bmatrix}
  = \cdots
\end{align*}\]</span> It also has the following tetrahedral symmetries: <span class="math display">\[\begin{align*}
  \begin{Bmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    j_4 &amp; j_5 &amp; j_6 \\
  \end{Bmatrix}
  =
  \begin{Bmatrix}
    j_4 &amp; j_5 &amp; j_3 \\
    j_1 &amp; j_2 &amp; j_6 \\
  \end{Bmatrix}
  =
  \begin{Bmatrix}
    j_4 &amp; j_2 &amp; j_6 \\
    j_1 &amp; j_5 &amp; j_3 \\
  \end{Bmatrix}
  =
  \begin{Bmatrix}
    j_1 &amp; j_5 &amp; j_6 \\
    j_4 &amp; j_2 &amp; j_3 \\
  \end{Bmatrix}
\end{align*}\]</span></p>
<h3 id="sec:9j"><span class="header-section-number">8.8.3</span> 9-j symbol</h3>
<figure>
<img src="fig-9j" alt="Figure 17: 9-j symbol: \{1 2 3 4 5 6 7 8 9\} = (1 2 3) (4 5 6) (7 8 9) (1 4 7) (2 5 8) (3 6 9) in Eq. 34" id="fig:9j" /><figcaption>Figure 17: 9-j symbol: <span class="math inline">\(\{1 2 3 4 5 6 7 8 9\} = (1 2 3) (4 5 6) (7 8 9) (1 4 7) (2 5 8) (3 6 9)\)</span> in Eq. <a href="print.html#eq:9j">34</a></figcaption>
</figure>
<p>Certain recouplings four or more angular momenta can lead to another type of irreducible diagram known as the <strong>9-j symbol</strong>, defined as: <span id="eq:9j"><span class="math display">\[\begin{aligned}
  \begin{Bmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    j_4 &amp; j_5 &amp; j_6 \\
    j_7 &amp; j_8 &amp; j_9 \\
  \end{Bmatrix}
  &amp;= \sum_{m_1 m_2 m_3 m_4 m_5 m_6 m_7 m_8 m_9} \\
  &amp;\quad
  \begin{pmatrix}
    j_1 &amp; j_2 &amp; j_3 \\
    m_1 &amp; m_2 &amp; m_3 \\
  \end{pmatrix}
  \begin{pmatrix}
    j_4 &amp; j_5 &amp; j_6 \\
    m_4 &amp; m_5 &amp; m_6 \\
  \end{pmatrix}
  \begin{pmatrix}
    j_7 &amp; j_8 &amp; j_9 \\
    m_7 &amp; m_8 &amp; m_9 \\
  \end{pmatrix} \\
  &amp;\quad
  \begin{pmatrix}
    j_1 &amp; j_4 &amp; j_7 \\
    m_1 &amp; m_4 &amp; m_7 \\
  \end{pmatrix}
  \begin{pmatrix}
    j_2 &amp; j_5 &amp; j_8 \\
    m_2 &amp; m_5 &amp; m_8 \\
  \end{pmatrix}
  \begin{pmatrix}
    j_3 &amp; j_6 &amp; j_9 \\
    m_3 &amp; m_6 &amp; m_9 \\
  \end{pmatrix}
\end{aligned}\qquad(34)\]</span></span> This is shown diagrammatically in Fig. <a href="print.html#fig:9j">17</a>, which can be expressed as the following shorthand: <span class="math display">\[\{1 2 3 4 5 6 7 8 9\} = (1 2 3) (4 5 6) (7 8 9) (1 4 7) (2 5 8) (3 6 9)\]</span></p>
<p>The nonlocal selection rules of 9-j symbols are simply triangle conditions on all row and column triplets. They are invariant under reflections about either diagonal, and also invariant under even permutations of rows or columns. An odd permutation would introduce a phase factor of <span class="math inline">\((-)^{\sum_{i = 0}^9 j_i}\)</span>.</p>
<h2 id="calculation-of-angular-momentum-coefficients"><span class="header-section-number">8.9</span> Calculation of angular momentum coefficients</h2>
<p>Numerical values of the coupling and recoupling coefficients (i.e. 3-jm, 6-j, and 9-j symbols) can be calculated readily using the formulas as given in this chapter. Due to the presence of large alternating sums, use of arbitrary-precision arithmetic is highly recommended to avoid catastrophic loss of precision.</p>
<p>Optimized variants of the formulas for 3-jm, 6-j, and 9-j symbols have been described in detail in <span class="citation" data-cites="WEI1999222 doi:10.1063/1.168745">(Wei 1999, 1998)</span>. These have been implemented in the <code>wigner-symbols</code> software packages in Rust <span class="citation" data-cites="WSR">(“Wigner-Symbols” 2017)</span> and Haskell <span class="citation" data-cites="WSH">(“Wigner-Symbols” 2015)</span>, which leverage the GNU Multi Precision (GMP) Arithmetic Library <span class="citation" data-cites="Granlund12">(Granlund and the GMP development team 2016)</span> for its highly optimized arbitrary-precision integer and rational arithmetic.</p>
<p>Even with the fastest algorithms, it is often more performant to reuse (re)coupling coefficients that have been previously computed and cached in memory than to recompute them again. For this, the storage scheme devised in <span class="citation" data-cites="doi:10.1137/S1064827503422932">(Rasch and Yu 2004)</span> based on Regge symmetries can help reduce the total memory usage. The storage scheme consists of two main parts:</p>
<ul>
<li>A canonicalization scheme that uses the symmetries of the coupling coefficients to link ones that differ by a trivial phase factor.</li>
<li>An indexing scheme that translates canonicalized angular momenta into an array index, allowing rapid lookup of elements.</li>
</ul>
<p>In practice, we found the canonicalization scheme most useful for calculations as it provides a guaranteed 1-2 orders of magnitude reduction in memory usage. In contrast, the indexing scheme is not substantially faster than a plain hash-table lookup and comes with the disadvantage of requiring all coefficients to be precomputed up to some limit. This makes it somewhat difficult to use in practice and can result in wasted memory if the limit is overestimated.</p>
<h2 id="sec:jucys"><span class="header-section-number">8.10</span> Graphical tool for angular momentum diagrams</h2>
<p>We have developed a graphical tool <span class="citation" data-cites="Jucys">(“Jucys,” n.d.)</span> that can be used to perform graphical manipulation of angular momentum coefficients with the diagrammatic technique explained in this chapter, with a few slight modifications. Specifically, non-diagrammatic objects such as phases, <span class="math inline">\(\jweight{j}\)</span>-like factors, Kronecker deltas, or summations over <span class="math inline">\(j\)</span>-type variables are all tracked separately in a <strong>tableau</strong> that is displayed beside the diagram.</p>
<p>The primary motivation of the tool is to eliminate human errors that commonly occur in angular momentum algebra and improve the speed of such derivations. To achieve this, the diagram offers a special <em>reduction mode</em> that, when activated, <em>ensures that all of the user’s diagrammatic manipulations preserve equality</em>. The user modifies the diagram through various gestures and clicks of the mouse cursor. The program is responsible for enforcing the diagrammatic rules, including orthogonal relations, separation rules, various phase rules, etc.</p>
<p>The program comes with a separate <em>input tool</em> for writing angular momentum expressions, without which the user would have to manually draw angular momentum diagrams node by node – a tedious and error-prone process. The input tool provides fast means of describing coupling coefficients in text, reducing the room for human error. As an example, the Pandya transformation coefficient for spherical scalars is described by the following input:</p>
<pre><code>rel (p + q) (r + s)
rec (p - s) (r - q)</code></pre>
<p>Here, <code>rel</code> equates the two angular momenta <code>p + q</code> and <code>r + s</code>. The <code>rec</code> equates the two angular momenta <code>p - s</code> and <code>r - q</code> but also includes an extra <span class="math inline">\(1 / \jweight{j}_{p s}^2\)</span> factor. The plus sign in <code>p + q</code> denotes the usual CG coupling <span class="math display">\[\bkt{p, q | pq} = \bkt{j_p m_p j_q m_q | j_{pq} m_{pq}}\]</span> whereas the minus sign in <code>p - s</code> denotes coupling with the second angular momentum time-reversed: <span id="eq:time-reversed-clebschgordan"><span class="math display">\[\bkt{p, \check{s} | ps} = (-)^{j_s - m_s} \bkt{j_p, m_p, j_s, -m_s | j_{ps}, m_{ps}}\qquad(35)\]</span></span> After providing this input to the tool, the corresponding 6-j diagram can be rapidly derived along with the associated phases and factors.</p>
<p>As another example, the Pandya transformation coefficient for a spherical tensor <span class="math inline">\(\hat{A}^{j_A}_{m_A}\)</span> is described by</p>
<pre><code>wet (p + q) A (r + s)
wet (p - s) A (r - q)</code></pre>
<p>Here, <code>wet</code> denotes the use of the Wigner–Eckart coupling and the central <code>A</code> variable is the rank <span class="math inline">\(j_A\)</span> of the spherical tensor. After providing this input, one can quickly derive the corresponding 9-j diagram with the associated phases and factors.</p>
<p>The tool is a web application written in a combination of JavaScript, HTML, and CSS. It can therefore run in any modern Internet browser and is accessible to users on most desktop platforms. An online version is available for immediate use, but the user can also run the application on their own machine with the appropriate setup. It utilizes SVG technology to display diagrams, making it straightforward to export diagrams as vector images, suitable for use in literature as we have done in this work.</p>
<p>We will not attempt to explain the usage of the program here, as that information will very likely become out of date as the program evolves. Interested users are advised to read the official documentation for usage information.</p>
<h2 id="sec:j-scheme"><span class="header-section-number">8.11</span> Fermionic states in J-scheme</h2>
<p><strong>J-scheme</strong> is a many-body formalism that takes advantage of angular momentum conservation to reduce the dimensionality of the problem (i.e. the computational cost and size of matrices). In this context, the usual formalism where we do not take advantage of angular momentum symmetries is dubbed <strong>M-scheme</strong> for contrast.</p>
<p>We use <span class="math inline">\(a, b, c, \ldots\)</span> to label single-particle states in this section. We assume each state has some definite angular-momentum-like quantum numbers: magnitude <span class="math inline">\(j\)</span> and projection <span class="math inline">\(m\)</span>, along with some other quantum number(s) <span class="math inline">\(\alpha\)</span> that are not relevant here.</p>
<h3 id="two-particle-states"><span class="header-section-number">8.11.1</span> Two-particle states</h3>
<p>A two-particle J-coupled product state is defined as <span class="math display">\[\begin{align*}
  \ket{\alpha_a j_a \otimes \alpha_b j_b; j_{a b} m_{a b}}
  &amp;= \sum_{m_a m_b} \ket{a \otimes b} \bkt{a, b | a b} \\
  &amp;= \sum_{m_a m_b} \ket{\alpha_a j_a m_a \otimes \alpha_b j_b m_b} \bkt{j_a m_a j_b m_b | j_{a b} m_{a b}}
\end{align*}\]</span> where <span class="math inline">\(\bkt{a, b | a b} = \bkt{j_a m_a j_b m_b | j_{a b} m_{a b}}\)</span> is the Clebsch–Gordan coefficient (Sec. <a href="print.html#sec:clebschgordan">8.2</a>) and <span class="math inline">\(\ket{a \otimes b} = \ket{\alpha_a j_a m_a \otimes \alpha_b j_b m_b}\)</span> denotes the (non-antisymmetrized) tensor product state (Sec. <a href="many-body-theory.html#sec:prod-state">6.1.1</a>) in M-scheme. To keep things concise, we will use the following shorthand for coupled product states: <span class="math display">\[\ket{(12) a \otimes b} = \ket{\alpha_a j_a \otimes \alpha_b j_b; j_{a b} m_{a b}}\]</span> Keep in mind that unlike M-scheme, the states in J-scheme do <em>not</em> depend on the individual projections <span class="math inline">\(m_a\)</span> and <span class="math inline">\(m_b\)</span>, only total <span class="math inline">\(m_{a b}\)</span>.</p>
<p>The coupled product states are eigenstates of the total <span class="math inline">\(\hat{J}^2\)</span> of all particles, <span class="math display">\[\hat{J}^2 |(12) a \otimes b \rangle = j_{a b} (j_{a b} + 1) |(12) a \otimes b \rangle\]</span> In contrast, uncoupled states are not eigenstates of <span class="math inline">\(\hat{J}^2\)</span>.</p>
<p>For fermionic problems, we can form an antisymmetrized state for J-scheme. The most straightforward way to do this is by coupling the antisymmetrized state, <span class="math display">\[| \alpha_a j_a \alpha_b j_b; j_{a b} m_{a b} \rangle = \frac{1}{\sqrt{N_{a b}}} \sum_{m_a m_b} | a b \rangle \langle j_a m_a j_b m_b | j_{a b} m_{a b} \rangle\]</span> where the normalization factor is given by <span id="eq:two-particle-j-normalization-factor"><span class="math display">\[N_{a b} = 1 - (-)^{2 j_a + j_{a b}} \delta_{\alpha_a \alpha_b} \delta_{j_a j_b}\qquad(36)\]</span></span> If the normalization factor is zero, then the antisymmetrized state does not exist.</p>
<p>Note that <span class="math inline">\(N_{a b}\)</span> depends on only the non-<span class="math inline">\(m\)</span> parts of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. If <span class="math inline">\(j_a\)</span> and <span class="math inline">\(j_b\)</span> are always half-odd, then the normalization factor can be further simplified to <span class="math inline">\(N_{a b} = 1 + (-)^{j_{a b}} \delta_{\alpha_a \alpha_b} \delta_{j_a j_b}\)</span>, which means if <span class="math inline">\(\alpha_a = \alpha_b\)</span> and <span class="math inline">\(j_a = j_b\)</span>, then states with odd <span class="math inline">\(j_{a b}\)</span> do not exist.</p>
<p>As before, we will also introduce a shorthand for the antisymmetrized states, <span class="math display">\[\ket{(12) a b} = \ket{\alpha_a j_a \alpha_b j_b; j_{a b} m_{a b}}\]</span> which depends on neither <span class="math inline">\(m_a\)</span> nor <span class="math inline">\(m_b\)</span>.</p>
<p>Alternatively, one can also obtain the same state from a J-coupled product state: <span class="math display">\[\begin{align*}
  \ket{(12) a b}
  &amp;= \sqrt{\frac{2}{N_{a b}}} \symm^{(1 + j_a + j_b - j_{a b})} \ket{(12) a \otimes b} \\
  &amp;= \frac{1}{\sqrt{2 N_{a b}}} \left(\ket{(12) a \otimes b} - (-)^{j_a + j_b - j_{a b}} \ket{(12) b \otimes a}\right)
\end{align*}\]</span> where <span class="math inline">\(\symm^{(1 + j_a + j_b - j_{a b})}\)</span> is the <span class="math inline">\(\pm\)</span>-symmetrization symbol introduced in Sec. <a href="many-body-theory.html#sec:symmetrization">6.1.2</a>, <span class="math display">\[\symm^{(1 + j_a + j_b - j_{a b})} X_{a b} = \frac{1}{2} \left(X_{a b} + (-)^{1 + j_a + j_b - j_{a b}} X_{b a}\right)\]</span></p>
<p>Note that the antisymmetrizer <span class="math inline">\(\hat{S}^-\)</span> (Sec. <a href="many-body-theory.html#sec:symmetrization">6.1.2</a>) operates differently in J-scheme compared to in M-scheme: matrix elements of the antisymmetrizer <span class="math inline">\(\hat{S}^-\)</span> are not always antisymmetric with respect to <span class="math inline">\((j, \alpha)\)</span> in J-scheme; instead they depend on the parity of <span class="math inline">\(j_a + j_b - j_{a b}\)</span>. This becomes even more complex for 3 or more particles as the matrix elements of the antisymmetrizer may contain 6-j or higher symbols.</p>
<p>Under particle exchange, the J-scheme antisymmetrized state has the following property: <span class="math display">\[|(12) a b \rangle = -(-)^{j_a + j_b - j_{a b}} |(12) b a \rangle\]</span></p>
<p>In J-scheme, the two-body antisymmetrized matrix elements are related to the product matrix elements by <span class="math display">\[\begin{align*}
  &amp;\bra{(12) a b} \hat{V} \ket{(12) c d} \\
  &amp;= \sqrt{\frac{2}{N_{a b}}} \bra{(12) a \otimes b} \hat{V} \ket{(12) c d} \\
  &amp;= \frac{1}{\sqrt{N_{a b} N_{c d}}} \left(\bra{(12) a \otimes b} \hat{V} \ket{(12) c \otimes d} - (-)^{j_c + j_d - j_{c d}} \bra{(12) a \otimes b} \hat{V} \ket{(12) d \otimes c}\right)
\end{align*}\]</span></p>
<h3 id="three-particle-states"><span class="header-section-number">8.11.2</span> Three-particle states</h3>
<p>Three-particle states have 3 nontrivially distinct ways of coupling. We will stick to the convention of coupling the first two, then the third, which we call the <strong>standard coupling order</strong>. In this case, the product state in J-scheme is given by <span class="math display">\[|((12)3) a \otimes b \otimes c \rangle = \sum_{m_a m_b m_c} | a \otimes b \otimes c \rangle \bkt{a, b | ab} \bkt{ab, c | abc}\]</span> As usual, the J-scheme antisymmetrized state is formed by coupling the M-scheme antisymmetrized state, <span class="math display">\[|((12)3) a b c \rangle
= \frac{1}{\sqrt{N_{(a b) c}}} \sum_{m_a m_b m_c}| a b c \rangle \bkt{a, b | ab} \bkt{ab, c | abc}\]</span> where the normalization constant <span class="math inline">\(N_{(a b) c}\)</span> is given by <span class="math display">\[\begin{align*}
  N_{(a b) c} &amp;= 1 - (-)^{2 j_a + j_{a b}} \delta_{\alpha_a \alpha_b} \delta_{j_a j_b}
  \\ &amp;\quad
  - (-)^{2 j_{a b c}} \jweight{j}_{a b} \begin{Bmatrix}
    j_a &amp; j_b &amp; j_{a b} \\
    j_{a b c} &amp; j_b &amp; j_{a b} \\
  \end{Bmatrix} \delta_{\alpha_b \alpha_c} \delta_{j_b j_c}
  \\ &amp;\quad
  - (-)^{2 j_{a b c}} \jweight{j}_{a b} \begin{Bmatrix}
    j_b &amp; j_a &amp; j_{a b} \\
    j_{a b c} &amp; j_a &amp; j_{a b} \\
  \end{Bmatrix} \delta_{\alpha_a \alpha_c} \delta_{j_a j_c}
  \\ &amp;\quad
  + 2 (-)^{j_{a b}} \jweight{j}_{a b} \begin{Bmatrix}
    j_a &amp; j_a &amp; j_{a b} \\
    j_{a b c} &amp; j_a &amp; j_{a b} \\
  \end{Bmatrix} \delta_{\alpha_a \alpha_b} \delta_{j_a j_b} \delta_{\alpha_a \alpha_c} \delta_{j_a j_c}
\end{align*}\]</span></p>
<h2 id="matrix-elements-in-j-scheme"><span class="header-section-number">8.12</span> Matrix elements in J-scheme</h2>
<p>In this work, we do not use normalized J-scheme states: equations tend to be simpler if we use <strong>unnormalized matrix elements</strong> in which the <span class="math inline">\(1 / \sqrt{N}\)</span> factor (see Eq. <a href="print.html#eq:two-particle-j-normalization-factor">36</a>) is omitted. This convention is used throughout.</p>
<h3 id="standard-coupled-matrix-elements"><span class="header-section-number">8.12.1</span> Standard-coupled matrix elements</h3>
<p>Given an M-scheme two-body matrix <span class="math inline">\(A^{m_p m_q m_r m_s}_{p q r s}\)</span>, we can couple <span class="math inline">\(p\)</span> to <span class="math inline">\(q\)</span> and <span class="math inline">\(r\)</span> to <span class="math inline">\(s\)</span>, <span class="math display">\[A^{j_{p q} m_{p q} j_{r s} m_{r s} (1 2; 3 4)}_{p q r s} = \sum_{m_p m_q m_r m_s} \bkt{p, q | pq} \bkt{r, s | rs} A^{m_p m_q m_r m_s}_{p q r s}\]</span> where <span class="math inline">\(\bkt{p, q | pq} = \bkt{j_p m_p j_q m_q | j_{p q} m_{p q}}\)</span> is the CG coefficient (Sec. <a href="print.html#sec:clebschgordan">8.2</a>). We call this the <strong>standard coupling</strong> for two-body matrix elements and denote it by schematically as <span class="math inline">\(1 2; 3 4\)</span>. We will often omit the <span class="math inline">\((1 2; 3 4)\)</span> superscript as we consider this the default coupling scheme.</p>
<p>If the matrix is a spherical scalar, then thanks to the Wigner–Eckart theorem we can omit many of the superscripts: <span class="math display">\[A^{j_{p q} m_{p q} j_{r s} m_{r s} (1 2; 3 4)}_{p q r s} = \delta_{j_{p q} j_{r s}} \delta_{m_{p q} m_{r s}} A^{j_{p q} (1 2; 3 4)}_{p q r s}\]</span> where <span class="math inline">\(A^{j_{p q} (1 2; 3 4)}_{p q r s}\)</span> denotes the reduced matrix element in the CG convention (Sec. <a href="print.html#sec:wigner-eckart">8.6</a>). Like any reduced matrix element, it is entirely independent of <span class="math inline">\(m\)</span>.</p>
<p>If <span class="math inline">\(\hat{A}\)</span> is a spherical tensor of rank <span class="math inline">\(j_A\)</span> and projection <span class="math inline">\(m_A\)</span>, then it is more convenient to use the reduced matrix element in the 3-jm convention <span class="math display">\[A^{j_A m_A j_{p q} m_{p q} j_{r s} m_{r s} (1 2; 3 4)}_{p q r s}
  = (-)^{j_{p q} - m_{p q}}
  \begin{pmatrix}
    j_{p s} &amp; j_A &amp; j_{r q} \\
    -m_{p s} &amp; m_A &amp; m_{r q}
  \end{pmatrix}
  A^{j_A j_{p q} j_{r s} (1 2; 3 4)}_{p q r s}\]</span></p>
<p>The standard coupling can be extended for higher-body operators: one simply couples the bra and ket indices in the order as written. For example, a three-body matrix in standard coupling would be <span class="math display">\[\begin{gather*}
  A^{j_{p q r} m_{p q r} j_{p q} j_{s t u} m_{s t u} j_{s t} ((1 2) 3; (4 5) 6)}_{p q r s t u} \\
  = \sum_{m_p m_q m_r m_s m_t m_u} \bkt{p, q | pq} \bkt{pq, r | pqr} \bkt{s, t | st} \bkt{st, u | stu} A^{m_p m_q m_r m_s m_t m_u}_{p q r s t u}
\end{gather*}\]</span> This is denoted schematically by <span class="math inline">\((1 2) 3; (4 5) 6\)</span>. In the case of spherical scalars, we have the following reduced matrix elements in the CG convention: <span class="math display">\[A^{j_{p q r} m_{p q r} j_{p q} j_{s t u} m_{s t u} j_{s t} ((1 2) 3; (4 5) 6)}_{p q r s t u} = \delta_{j_{p q r} j_{s t u}} \delta_{m_{p q r} m_{s t u}} A^{j_{p q r} j_{p q} j_{s t} ((1 2) 3; (4 5) 6)}_{p q r s t u}\]</span></p>
<h3 id="sec:pandya"><span class="header-section-number">8.12.2</span> Pandya-coupled matrix elements</h3>
<p>Besides the standard coupling, two-body operators can be coupled in several other ways. Some are equivalent to <span class="math inline">\(1 2; 3 4\)</span> up to a phase factor. A nontrivial combination is the <strong>Pandya coupling</strong> <span class="citation" data-cites="PhysRev.103.956 Suhonen2007">(Pandya 1956; Suhonen 2007)</span> <span class="math inline">\(1 \check{4}; 3 \check{2}\)</span>: <span class="math display">\[A^{j_{p s} m_{p s} j_{r q} m_{r q} (1 \check{4}; 3 \check{2})}_{p s r q} = -\sum_{m_p m_s m_r m_q} \bkt{p, \check{s} | ps} \bkt{r, \check{q} | rq} A^{m_p m_q m_r m_s}_{p q r s}\]</span> where the <span class="math inline">\(\bkt{p, \check{s} | ps}\)</span> uses the time-reversed CG notation introduced in Eq. <a href="print.html#eq:time-reversed-clebschgordan">35</a>.</p>
<p>The extraneous minus sign in front of the summation is conventional: if we treat this a recoupling of field operators, we would obtain a minus sign due to antisymmetry since the permutation <span class="math inline">\(1 2 3 4 \to 1 4 3 2\)</span> is odd. If instead we omit the extraneous minus sign, the coupling is often referred to as <strong>cross-coupling</strong> <span class="citation" data-cites="KUO1981237">(Kuo et al. 1981)</span> rather than Pandya-coupling.</p>
<p>For spherical scalars, we have the following reduced matrix elements in the CG convention. <span class="math display">\[A^{j_{p s} m_{p s} j_{r q} m_{r q} (1 \check{4}; 3 \check{2})}_{p s r q} = \delta_{j_{p s} j_{r q}} \delta_{m_{p s} m_{r q}} A^{j_{p s} (1 \check{4}; 3 \check{2})}_{p s r q}\]</span> They are related to the standard-coupled reduced matrix elements the <strong>Pandya transformation</strong>: <span class="math display">\[A^{j_{p s} (1 \check{4}; 3 \check{2})}_{p s r q} =
  -\sum_{j_{p q}}
  (-)^{2 j_{p q}}
  \jweight{j}_{p q}^2
  \begin{Bmatrix}
    j_p &amp; j_q &amp; j_{p q} \\
    j_r &amp; j_s &amp; j_{p s} \\
  \end{Bmatrix}
  A^{j_{p q} (1 2; 3 4)}_{p q r s}
\]</span></p>
<p>The inverse Pandya transformation is nearly the same: <span class="math display">\[A^{j_{p s} (1 2; 3 4)}_{p q r s} =
  -(-)^{2 j_{p q}}
  \sum_{j_{p s}}
  \jweight{j}_{p s}^2
  \begin{Bmatrix}
    j_p &amp; j_q &amp; j_{p q} \\
    j_r &amp; j_s &amp; j_{p s} \\
  \end{Bmatrix}
  A^{j_{p s} (1 \check{4}; 3 \check{2})}_{p s r q}
\]</span></p>
<p>However, typically when Pandya-coupled matrices are involved, the fermionic antisymmetry is temporarily broken. As a result, in our implementation, Pandya-coupled matrices are not antisymmetrized even though standard-coupled matrices are. To restore the antisymmetry when performing the inverse transformation, we must perform an explicit antisymmetrization during the inverse transformation: <span class="math display">\[A_{p q r s}^{1 2; 3 4} =
  -(-)^{2 j_{p q}}
  \symm^{(1 + j_p + j_q - j_{p q})}_{p q}
  \symm^{(1 + j_r + j_s - j_{r s})}_{r s}
  \sum_{j_{p s}}
  \jweight{j}_{p s}^2
  \begin{Bmatrix}
    j_p &amp; j_q &amp; j_{p q} \\
    j_r &amp; j_s &amp; j_{p s} \\
  \end{Bmatrix}
  \tilde{A}^{1 \check{4}; 3 \check{2}}_{p s r q}\]</span> where the tilde symbol (<span class="math inline">\(\tilde{A}\)</span>) indicates that the matrix element is not antisymmetrized and <span class="math inline">\(\symm^{(i)}\)</span> is the <span class="math inline">\((-)^i\)</span>-symmetrization symbol in Sec. <a href="many-body-theory.html#sec:symmetrization">6.1.2</a>.</p>
<p>For completeness, we also include the Pandya transformation for spherical tensor operators, <span class="math display">\[A^{j_A j_{p s} j_{r q} (1 \check{4}; 3 \check{2})}_{p s r q} =
-\sum_{j_{p q} j_{r s}}
\jweight{j}_{p q}
\jweight{j}_{r s}
\jweight{j}_{p s}
\jweight{j}_{r q}
(-)^{j_q + j_s - j_{r s} + j_{r q}}
\begin{Bmatrix}
j_p &amp; j_q &amp; j_{p q} \\
j_s &amp; j_r &amp; j_{r s} \\
j_{p s} &amp; j_{r q} &amp; j_A
\end{Bmatrix}
A^{j_A j_{p q} j_{r s} (1 2; 3 4)}_{p q r s}\]</span> where we use reduced matrix elements in the 3-jm convention, <span class="math display">\[A^{j_A m_A j_{p s} m_{p s} j_{r q} m_{r q} (1 \check{4}; 3 \check{2})}_{p s r q}
  = (-)^{j_{p s} - m_{p s}}
  \begin{pmatrix}
    j_{p s} &amp; j_A &amp; j_{r q} \\
    -m_{p s} &amp; m_A &amp; m_{r q}
  \end{pmatrix}
  A^{j_A j_{p s} j_{r q} (1 \check{4}; 3 \check{2})}_{p s r q}\]</span> The inverse transformation is identical except the summation is over <span class="math inline">\(j_{p s}\)</span> and <span class="math inline">\(j_{r q}\)</span>.</p>
<h3 id="sec:implicit-j"><span class="header-section-number">8.12.3</span> Implicit-J convention</h3>
<p>To keep J-scheme of scalar operators concise, we will omit explicit mention of composite angular momenta within the matrix elements: <span class="math display">\[A^{j_{p q}}_{p q r s} \rightsquigarrow A_{p q r s}\]</span> <span class="math display">\[A^{j_{p q r} j_{p q} j_{r s}}_{p q r s t u} \rightsquigarrow A_{p q r s t u}\]</span> We will also omit mentions of Kronecker deltas between angular momenta as well as triangular deltas. We call this the <strong>implicit-J convention</strong>.</p>
<p>As an example, consider the following scalar equation written in our implicit-J convention: <span class="math display">\[C_{p q} = \frac{1}{2} \sum_{j_{i p}} \sum_{i \backslash a b} \frac{\jweight{j}_{i p}^2}{\jweight{j}_p^2} A_{i p a b} B_{a b i q} \]</span> To decode this, we follow these steps:</p>
<ol type="1">
<li><p>We first determine the set of <em>composite</em> angular momentum variables. This comes from a combination of (a) the composite angular momenta from the left-hand side (there are none, since <span class="math inline">\(C_{p q}\)</span> is only one-body), (b) the composite angular momenta that are being explicitly summed over (namely <span class="math inline">\(j_{i p}\)</span>). <span class="math display">\[C_{p q} = \frac{1}{2} \sum_{j_{i p}} \sum_{i \backslash a b} \frac{\jweight{j}_{i p}^2}{\jweight{j}_p^2} A^{j_{i p}}_{i p a b} B^?_{a b i q}\]</span></p></li>
<li><p>Next, we fill in the remaining slots for composite angular momenta using conservation laws. Since <span class="math inline">\(j_{i p} = j_{a b}\)</span>, the missing angular momentum on <span class="math inline">\(B\)</span> is simply <span class="math inline">\(j_{i p}\)</span>: <span class="math display">\[C_{p q} = \frac{1}{2} \sum_{j_{i p}} \sum_{i \backslash a b} \frac{\jweight{j}_{i p}^2}{\jweight{j}_p^2} A^{j_{i p}}_{i p a b} B^{j_{i p}}_{a b i q}\]</span></p></li>
<li><p>We may use the conservation laws to determine the Kronecker deltas for the <em>elementary</em> angular momenta: <span class="math display">\[C_{p q} = \frac{1}{2} \delta_{j_p j_q} \sum_{j_{i p}} \sum_{i \backslash a b} \frac{\jweight{j}_{i p}^2}{\jweight{j}_p^2} A^{j_{i p}}_{i p a b} B^{j_{i p}}_{a b i q}\]</span></p></li>
<li><p>Finally, we use selection rules to restrict the composite angular momenta via triangular deltas: <span class="math display">\[C_{p q} = \frac{1}{2} \delta_{j_p j_q} \sum_{j_{i p}} \sum_{i \backslash a b} \frac{\jweight{j}_{i p}^2}{\jweight{j}_p^2} \tridelta{j_i}{j_p}{j_{i p}} \tridelta{j_a}{j_b}{j_{i p}} A^{j_{i p}}_{i p a b} B^{j_{i p}}_{a b i q}\]</span></p></li>
</ol>
<p>This can be generalized to spherical tensors by omitting the tensor ranks: <span class="math display">\[A^{j_A j_{p q} j_{r s}}_{p q r s} \rightsquigarrow A_{p q r s}\]</span> <span class="math display">\[A^{j_A j_{p q r} j_{p q} j_{r s t} j_{r s}}_{p q r s t u} \rightsquigarrow A_{p q r s t u}\]</span> The procedure to decode these is analogous: tensor ranks should be treated like composite angular momenta.</p>
<h1 id="many-body-methods"><span class="header-section-number">9</span> Many-body methods</h1>
<p>We now discuss the many-body methods that form the core of our many-body code. In Sec. <a href="many-body-theory.html#sec:symmetrization">6.1.2</a>, we have noted that antisymmetrized states (Slater determinants) provide solutions for any non-interacting fermionic system. We have not yet discussed how to solve <em>interacting</em> systems however, which is the principal focus of many-body theory.</p>
<p>In general, while solutions of the non-interacting Hamiltonian <span class="math inline">\(\hat{H}^\circ\)</span> are often not solutions of any interacting Hamiltonian <span class="math inline">\(\hat{H}\)</span>, they do nonetheless provide a useful basis for the Fock space. We expect from basic linear algebra that, if the degrees of freedom (including boundary conditions) are the same between <span class="math inline">\(\hat{H}^{\mathrm{NI}}\)</span> and <span class="math inline">\(\hat{H}\)</span>, then any exact <span class="math inline">\(N\)</span>-particle solution <span class="math inline">\(\ket{\Psi}\)</span> can be expanded as a linear combination of antisymmetrized states, <span class="math display">\[\ket{\Psi} = \frac{1}{N!} \sum_{p_1 \ldots p_N} \Psi_{p_1 \ldots p_N} \hat{a}_{p_1}^\dagger \cdots \hat{a}_{p_N}^\dagger \ket{\varnothing}\]</span> Solving a quantum system in this manner is the central theme of <strong>exact diagonalization</strong> methods, such as <strong>full configuration interaction</strong> (FCI) <span class="citation" data-cites="doi:10.1063/1.455063 KNOWLES1984315">(Olsen et al. 1988; Knowles and Handy 1984)</span> and <strong>no-core shell model</strong> (NCSM) <span class="citation" data-cites="PhysRevC.62.054311 0954-3899-36-8-083101">(Navrátil, Vary, and Barrett 2000; Navrátil et al. 2009)</span>.</p>
<p>The key advantage of exact diagonalization is the ability to obtain exact numeric results within the basis (up to machine precision), capturing all the details of the quantum system. However, such methods are very costly as the number of <span class="math inline">\(N\)</span>-particle basis states <span class="math inline">\(n_{\mathrm{B}}\)</span> increases rapidly with the number of particles <span class="math inline">\(N\)</span> and the number of single-particle states <span class="math inline">\(n_{\mathrm{b}}\)</span>, specifically <span class="math display">\[n_{\mathrm{B}} = \binom{n_{\mathrm{b}}}{N}\]</span> where <span class="math inline">\(\binom{n}{k}\)</span> denotes the binomial coefficient. The combinatorial explosion quickly renders such methods unfeasible in systems with even a moderate number of particles, beyond the computational power that exists in the observable universe.</p>
<p>Alternative many-body methods strive to avoid this problem by limiting the <span class="math inline">\(N\)</span>-particle Hilbert space under consideration. It can be particularly beneficial if the non-interacting Hamiltonian <span class="math inline">\(\hat{H}^\circ\)</span> that generates the basis states is to some extent similar to the interacting Hamiltonian <span class="math inline">\(\hat{H}\)</span>. That is, one decomposes <span class="math inline">\(\hat{H}\)</span> into <span class="math display">\[\hat{H} = \hat{H}^\circ + \hat{V}\]</span> where the contributions of the <strong>perturbation</strong> <span class="math inline">\(\hat{V}\)</span> are expected to be small in some sense. In this case, one or a few antisymmetrized states may serve as a good zeroth order approximation to the system.</p>
<p>For now, we will only consider using a single antisymmetrized state as the initial approximation. This limits our consideration to closed-shell systems in which the number of particles coincides with a magic number. This distinguished antisymmetrized state will serve as our <em>reference state</em> (Fermi vacuum).</p>
<h1 id="hartree-fock-method"><span class="header-section-number">10</span> Hartree-Fock method</h1>
<p>The reference state formed by basis states of the non-interacting Hamiltonian may not offer a good approximation of the true ground state (i.e. of the interacting Hamiltonian). The Hartree–Fock (HF) method <span class="citation" data-cites="hartree_1928 Fock1930">(Hartree 1928; Fock 1930)</span> provides a way to optimize the basis states such that the reference state provides the best variational estimate of the ground state energy.</p>
<h2 id="hartreefock-equations"><span class="header-section-number">10.1</span> Hartree–Fock equations</h2>
<p>Using the variational principle, one can compute an approximate ground state <span class="math inline">\(\ket{\Phi}\)</span> by minimizing the energy expectation value (<strong>Hartree–Fock energy</strong>) <span id="eq:hfexpectation"><span class="math display">\[E_\Phi = \bra{\Phi} \hat H \ket{\Phi}\qquad(37)\]</span></span> with respect to a reference state <span class="math inline">\(\ket{\Phi}\)</span>, subject to the restriction that <span class="math inline">\(\ket{\Phi}\)</span> remains a single Slater determinant constructed from an unknown single-particle basis <span class="math inline">\(\ket{p&#39;},\)</span><a href="print.html#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a> <span class="math display">\[\ket{\Phi} = \ket{i_1&#39; \ldots i_N&#39;}\]</span> where <span class="math inline">\(\{i_1&#39;, \ldots, i_N\}\)</span> are an unknown set of occupied state labels drawn from the unknown single-particle basis. The restriction of <span class="math inline">\(\ket{\Phi}\)</span> to a single Slater determinant is what enables the simplicity and efficiency of this method.</p>
<p>To perform numerical calculations, we further assume that each unknown state <span class="math inline">\(\ket{p&#39;}\)</span> is built from a linear combination of known states <span class="math inline">\(\ket{p}\)</span>, with an unknown matrix of coefficients <span class="math inline">\(\bm{C}\)</span> defined via the transformation equation <span class="math display">\[\ket{p&#39;} = \sum_p \ket{p} C_{p p&#39;}\]</span> This allows the problem to be reduced from an abstract minimization problem Eq. <a href="print.html#eq:hfexpectation">37</a> to a concrete numerical problem. The caveat is that the set of known functions must be large enough to capture the relevant behavior of the system.</p>
<p>To ensure orthonormality of the states, we require there to be as many unknown states <span class="math inline">\(\ket{p&#39;}\)</span> as known states <span class="math inline">\(\ket{p}\)</span>, and the coefficient matrix <span class="math inline">\(\bm{C}\)</span> must be unitary, <span class="math display">\[\bm{C}^\dagger \bm{C} = \bm{1}\]</span> These conditions are more strict than needed, but they greatly simplify the calculations and allow the states <span class="math inline">\(\ket{p&#39;}\)</span> to act as <em>optimized</em> inputs for methods beyond HF (<strong>post-HF</strong> methods). At the end of the calculation, of the set of states <span class="math inline">\(\ket{p&#39;}\)</span> there would be exactly <span class="math inline">\(N\)</span> occupied states that participate in the optimized Slater determinant <span class="math inline">\(\ket{\Phi}\)</span>. The remaining unoccupied states serve as the complementary space into which particles can be excited by the interaction <span class="math inline">\(\hat{V}\)</span> during post-HF calculations.</p>
<p>Consider a Hamiltonian <span class="math inline">\(\hat{H}\)</span> that can be decomposed into a set of <span class="math inline">\((1, 2, 3)\)</span>-body operators relative to the physical vacuum, <span class="math display">\[\hat{H} = \hat{H}^\varnothing_1 + \hat{H}^\varnothing_2 + \hat{H}^\varnothing_3\]</span> where <span class="math inline">\(\hat{H}^\varnothing_k\)</span> is its <span class="math inline">\(k\)</span>-body component relative to the physical vacuum. (We will omit the <span class="math inline">\(\varnothing\)</span> suffix in this section.) The goal is to find the coefficients <span class="math inline">\(\bm{C}\)</span> that minimize the Hartree–Fock energy <span class="math inline">\(E_\Phi\)</span>, <span id="eq:hfenergy"><span class="math display">\[E_\Phi = \sum_{i&#39; \backslash} \bra{i&#39;} \hat{H}_1 \ket{i&#39;} + \frac{1}{2} \sum_{i&#39; j&#39; \backslash} \bra{i&#39; j&#39;} \hat{H}_2 \ket{i&#39; j&#39;}\qquad(38)\]</span></span> where <span id="eq:hftransform"><span class="math display">\[\begin{aligned}
  &amp;\bra{p&#39;} \hat{H}_1 \ket{q&#39;} = \sum_{p q} C_{p p&#39;}^* \bra{p} \hat{H}_1 \ket{q} C_{q q&#39;} \\
  &amp;\bra{p&#39; q&#39;} \hat{H}_2 \ket{r&#39; s&#39;} = \sum_{p q r s} C_{p p&#39;}^* C_{q q&#39;}^* \bra{p q} \hat{H}_2 \ket{r s} C_{r r&#39;} C_{s s&#39;}
\end{aligned}\qquad(39)\]</span></span> and <span class="math inline">\(\sum_{i&#39; \backslash}\)</span> denotes a summation over all hole states <span class="math inline">\(\ket{i&#39;}\)</span> in the unknown basis (see Eq. <a href="many-body-theory.html#eq:ph-summation">3</a>).</p>
<p>With the method of Lagrange multipliers, the minimization problem can be reduced to the solving of a nonlinear equation – the self-consistent <strong>Hartree–Fock equations</strong>: <span id="eq:hartreefock"><span class="math display">\[\bm{F} \bm{C} = \bm{C} \bm{\varepsilon}\qquad(40)\]</span></span> where the <strong>Fock matrix</strong> <span class="math inline">\(\bm F\)</span> is defined as <span id="eq:fock"><span class="math display">\[F_{p q} = \bra{p} \hat{H}_1 \ket{q} + \sum_{r s} \sum_{i&#39; \backslash} C_{r i&#39;}^* \bra{p r} \hat{H}_2 \ket{q s} C_{s i&#39;}\qquad(41)\]</span></span> with <span class="math inline">\(i&#39;\)</span> ranging over occupied states only, and <span class="math inline">\(\bm{\varepsilon}\)</span> is a vector of Lagrange multipliers, which serve to constrain the orthonormality of the single-particle basis. Each multiplier <span class="math inline">\(\varepsilon_{p&#39;}\)</span> is associated with a specific single-particle state <span class="math inline">\(\ket{p&#39;}\)</span>. Observe that the Fock matrix <span class="math inline">\(\bm{F}\)</span> contains precisely the matrix elements of the one-body Hamiltonian <span class="math inline">\(\hat{H}^\Phi_1\)</span> relative to the Fermi vacuum <span class="math inline">\(\ket{\Phi}\)</span> in the original basis <span class="math inline">\(\ket{p}\)</span> Eq. <a href="many-body-theory.html#eq:normord-ph">4</a>, and the HF energy <span class="math inline">\(E_\Phi\)</span> is exactly the zero-body component in Eq. <a href="many-body-theory.html#eq:normord-ph">4</a>.</p>
<h2 id="hf-equations-in-j-scheme"><span class="header-section-number">10.2</span> HF equations in J-scheme</h2>
<p>In this work, we use the implicit-J convention of Sec. <a href="angular-momentum-coupling.html#sec:implicit-j">8.12.3</a> to describe J-scheme equations.</p>
<p>In J-scheme, the HF energy of Eq. <a href="print.html#eq:hfenergy">38</a> is given by <span id="eq:hfenergy-j"><span class="math display">\[E_\Phi = \sum_{i&#39; \backslash} \jweight{j}_{i&#39;}^2 \bra{i&#39;} \hat{H}_1 \ket{i&#39;} + \frac{1}{2} \sum_{j_{i&#39; j&#39;}} \sum_{i&#39; j&#39; \backslash} \jweight{j}_{i&#39; j&#39;}^2 \bra{i&#39; j&#39;} \hat{H}_2 \ket{i&#39; j&#39;}\qquad(42)\]</span></span> and the Fock matrix of Eq. <a href="print.html#eq:fock">41</a> is given by <span id="eq:fock-j"><span class="math display">\[F_{p q} = \bra{p} \hat{H}_1 \ket{q} + \sum_{j_{p r} r s} \sum_{i&#39; \backslash} \frac{\jweight{j}_{p r}^2}{\jweight{j}_p^2} C_{r i&#39;}^* \bra{p r} \hat{H}_2 \ket{q s} C_{s i&#39;}\qquad(43)\]</span></span></p>
<p>The transformation equations of Eq. <a href="print.html#eq:hftransform">39</a> remain superficially identical to M-scheme.</p>
<h2 id="solving-hf-equations"><span class="header-section-number">10.3</span> Solving HF equations</h2>
<p>Aside from trivial cases that are analytically solvable, the HF equation is generally solved numerically using an iterative algorithm. We begin with an initial guess <span class="math inline">\(\bm{C}^{(k)}\)</span> on the <span class="math inline">\(k\)</span>-th iteration, which is fed into Eq. <a href="print.html#eq:fock">41</a> to produce the Fock matrix. This is then used in Eq. <a href="print.html#eq:hartreefock">40</a>, which leads to a standard eigenvalue problem from which <span class="math inline">\(\bm{C}^{(k + 1)}\)</span> arises as the matrix of eigenvectors and <span class="math inline">\(\bm{\varepsilon}^{(k + 1)}\)</span> as the vector of eigenvalues. This process can be repeated indefinitely until <span class="math inline">\(\bm{C}\)</span> approaches a fixed point (self-consistency). While in theory it is possible for the solution to never reach a fixed point, or that it may require an unfeasibly large number of iterations, in practice this naive approach can adequately provide solutions for many cases. In other cases where it is insufficient, methods such as direct inversion of the iterative subspace (DIIS) <span class="citation" data-cites="PULAY1980393 JCC:JCC540030413">(Pulay 1980, 1982)</span>, Broyden’s method <span class="citation" data-cites="broyden1965class">(Broyden 1965)</span>, or even <em>ad hoc</em> linear mixing can improve and accelerate convergence greatly. Therefore, the possibility of slow or non-convergence is generally not a concern in practice.</p>
<p>For the initial guess, we simply use the ground state of our noninteracting Hamiltonian, thus <span class="math inline">\(\bm{C}^{(0)} = \bm{1}\)</span>, the identity matrix. At each iteration, we calculate the sum of the Lagrange multipliers <span class="math inline">\(\bm{\varepsilon}\)</span> as a diagnostic for convergence: as the iteration approaches convergence, the change in the sum per iteration should decrease rapidly.</p>
<h2 id="post-hf-methods"><span class="header-section-number">10.4</span> Post-HF methods</h2>
<p>Since HF restricts the ground state to merely a single Slater determinant of single-particle states, it cannot provide an exact solution to a problem where multi-particle correlations are present even if the single-particle basis is not truncated (infinite in size). The discrepancy between the HF energy and the exact ground state energy is often referred to as the <strong>correlation energy</strong>, by definition. The focus of post-HF methods such as IM-SRG or CC is to add corrections beyond mean-field approximations such as HF.</p>
<p>To make use of the HF solution as the reference state for post-HF calculations, we transform the matrix elements via Eq. <a href="print.html#eq:hftransform">39</a>. In effect, this means we are no longer operating within the harmonic oscillator single-particle basis, but rather a HF-optimized single-particle basis. However, we will omit the prime symbols as the post-HF methods are generic and can be used in any basis, whether optimized by HF or not.</p>
<p>A commonly used post-HF method is the <strong>Møller–Plesset perturbation theory at second order</strong> (MP2) <span class="citation" data-cites="MoellerPlesset1934">(Møller and Plesset 1934)</span>, which adds an energy correction to the Hartree–Fock result: <span id="eq:mp2"><span class="math display">\[\Delta E = \frac{1}{4} \sum_{i j \backslash a b} \frac{V_{i j a b} V_{a b i j}}{\Delta_{i j a b}}\qquad(44)\]</span></span> where <span class="math inline">\(V_{i j a b}\)</span> are two-body matrix elements of the HF-transformed Hamiltonian, <span class="math inline">\(\Delta\)</span> denotes the <strong>Møller–Plesset energy denominators</strong> <span class="citation" data-cites="MoellerPlesset1934">(Møller and Plesset 1934)</span>, <span id="eq:moellerplessetdenominator"><span class="math display">\[\Delta_{q_1 \ldots q_k p_1 \ldots p_k} = \sum_{i = 1}^k (\varepsilon_{q_i} -  \varepsilon_{p_i})\qquad(45)\]</span></span> and <span class="math inline">\(\varepsilon_p\)</span> are HF orbital energies. In J-scheme, the MP2 correction is given by: <span id="eq:mp2-j"><span class="math display">\[\Delta E = \frac{1}{4} \sum_{j_{i j}} \sum_{i j \backslash a b} \jweight{j}_{i j}^2 \frac{V_{i j a b} V_{a b i j}}{\Delta_{i j a b}}\qquad(46)\]</span></span> The MP2 calculation is extremely simple and cheap, thus it is often used as a diagnostic for estimating the strength of correlations that remain unaccounted for.</p>
<p>A more sophisticated post-HF method is the <em>coupled-cluster</em> (CC) method <span class="citation" data-cites="shavitt2009many">(Shavitt and Bartlett 2009)</span>, in which the <span class="math inline">\(N\)</span>-particle correlated wave function <span class="math inline">\(\ket{\Psi}\)</span> is expressed as the exponential ansatz, <span class="math display">\[\ket{\Psi} = \E^{\hat{T}} \ket{\Phi}\]</span> Here, <span class="math inline">\(\ket{\Phi}\)</span> is a Slater determinant reference state such as the one from HF and <span class="math inline">\(\hat{T}\)</span> is the <em>cluster operator</em>, which is a sum of <span class="math inline">\(k\)</span>-particle-<span class="math inline">\(k\)</span>-hole excitation operators of various <span class="math inline">\(k\)</span>. The Schrödinger equation with this ansatz becomes a set of non-linear algebraic equations (<em>coupled-cluster equations</em>) with which one can solve for the matrix elements of <span class="math inline">\(\hat{T}\)</span> and thereby obtain information about <span class="math inline">\(\ket{\Psi}\)</span>.</p>
<p>The focus of this work is not on the coupled-cluster method, however, although we will present benchmarks of it for comparison. Our focus is on the in-medium similarity renormalization group (IM-SRG) method.</p>
<h1 id="similarity-renormalization-group-methods"><span class="header-section-number">11</span> Similarity renormalization group methods</h1>
<h2 id="sec:srgmethods"><span class="header-section-number">11.1</span> Free space SRG</h2>
<p>The central theme of similarity renormalization group (SRG) methods is the application of a continuous sequence of unitary transformations on the Hamiltonian to evolve it into a band- or block-diagonal form. This allows the decoupling of a small, designated <strong>model space</strong> from its larger complementary space. The problem can thus be truncated to the small model space while preserving a large amount of information about the system. See for examples <span class="citation" data-cites="kehrein2006flow Hergert2016165 lnp936">(Kehrein 2006; Hergert et al. 2016; Hjorth-Jensen, Lombardo, and Kolck 2017)</span> for derivations and calculational details.</p>
<p>The sequence of transformations is parameterized by a continuous variable <span class="math inline">\(s\)</span> known as the <strong>flow parameter</strong>. Without loss of generality, we can define <span class="math inline">\(s = 0\)</span> to be the beginning of this sequence, thus <span class="math inline">\(\hat{H}(0)\)</span> is simply the original Hamiltonian. At any value of <span class="math inline">\(s\)</span>, the evolving Hamiltonian <span class="math inline">\(\hat{H}(s)\)</span> is related to the original Hamiltonian by <span class="math display">\[\hat{H}(s) = \hat{U}(s) \hat{H}(0) \hat{U}^\dagger(s)\]</span> where <span class="math inline">\(U(s)\)</span> is a unitary operator that describes the product of all such transformations since <span class="math inline">\(s = 0\)</span>. Taking the derivative with respect to <span class="math inline">\(s\)</span>, we obtain: <span class="math display">\[\frac{\D}{\D s} \hat{H}(s) = \frac{\D \hat{U}(s)}{\D s} \hat{H}(0) \hat{U}^\dagger(s) + \hat{U}(s) \hat{H}(0) \frac{\D \hat{U}^\dagger (s)}{\D s}\]</span> If we define the <strong>generator</strong> <span class="math inline">\(\hat{\eta}(s)\)</span> as <span id="eq:etadefinition"><span class="math display">\[\hat{\eta}(s) = \frac{\D \hat{U}(s)}{\D s} \hat{U}^\dagger(s)\qquad(47)\]</span></span> we find that it is antihermitian as a result of the unitarity of <span class="math inline">\(\hat{U}(s)\)</span>: <span class="math display">\[\hat{\eta}(s) + \hat{\eta}^\dagger(s) = \frac{\D}{\D s} \left(\hat{U}(s) \hat{U}^\dagger(s)\right) = 0\]</span> From this property we can derive a differential equation known as the <strong>SRG flow equation</strong>: <span id="eq:imsrgode"><span class="math display">\[\frac{\D \hat{H}(s)}{\D s} = [\hat{\eta}(s), \hat{H}(s)]\qquad(48)\]</span></span> This equation allows <span class="math inline">\(\hat{H}(s)\)</span> to be evaluated without explicitly constructing the full transformation <span class="math inline">\(\hat{U}(s)\)</span>. The focus is instead shifted to the operator <span class="math inline">\(\hat{\eta}(s)\)</span>, the generator of the transformation. When <span class="math inline">\(\hat{\eta}(s)\)</span> is <em>multiplicatively</em> integrated (<strong>product integral</strong>), the full unitary transformation <span class="math inline">\(\hat{U}(s)\)</span> is recovered: <span id="eq:etaintegral"><span class="math display">\[\hat{U}(s&#39;) = \lim_{\Delta s \to 0} \prod_{i = 1}^{\to n} \mathrm{e}^{\hat{\eta}(s_i) \Delta s}\qquad(49)\]</span></span> where <span class="math inline">\(s_i = i \Delta s\)</span>, <span class="math inline">\(n = \lfloor s&#39; / \Delta s \rfloor\)</span>, <span class="math inline">\(\lfloor x \rfloor\)</span> denotes the floor of <span class="math inline">\(x\)</span>, and the product is ordered from left (<span class="math inline">\(i = 1\)</span>) to right (<span class="math inline">\(i = n\)</span>). This is the formal solution to the linear differential equation Eq. <a href="print.html#eq:etadefinition">47</a>. The product integral in Eq. <a href="print.html#eq:etaintegral">49</a> may also be reinterpreted as “<span class="math inline">\(s\)</span>-ordering” <span class="citation" data-cites="reimann2013quantum">(Reimann 2013)</span> in analogy to time-ordering from quantum field theory.</p>
<p>The power of SRG methods lies in the flexibility of the generator <span class="math inline">\(\hat{\eta}\)</span>, which is usually chosen in an <span class="math inline">\(s\)</span>-dependent manner. In particular, it is often dependent on the evolving Hamiltonian <span class="math inline">\(\hat{H}(s)\)</span>. The operator <span class="math inline">\(\hat{\eta}\)</span> determines which parts of the Hamiltonian matrix would become suppressed by the evolution, which are usually considered “off-diagonal” in an abstract sense. The “off-diagonal” parts could be elements far away from the matrix diagonal, in which case the evolution drives the matrix towards a band-diagonal form. Or, the “off-diagonal” parts could be elements that couple the ground state from the excited state, in which case the evolution drives the matrix towards a block-diagonal form that isolates the ground state. Or, the “off-diagonal” could be literally the elements that do not lie on the diagonal, in which case the evolution would simply diagonalize the Hamiltonian. Through different choices of <span class="math inline">\(\hat{\eta}\)</span>, the SRG evolution can be controlled and adapted to the features of a particular problem.</p>
<h2 id="in-medium-srg"><span class="header-section-number">11.2</span> In-medium SRG</h2>
<p>The SRG flow equation Eq. <a href="print.html#eq:imsrgode">48</a> can be solved in the second quantization formalism described in Sec. <a href="many-body-theory.html#sec:second-quantization">6.2</a>, where field operators are defined with respect to the physical vacuum state. However, since the basis of a many-body problem grows factorially with the number of particles and the size of the model space, the applicability of the naive (free-space) SRG method is restricted to comparatively small systems. A more practical approach is to perform the evolution <em>in medium</em> <span class="citation" data-cites="kehrein2006flow">(Kehrein 2006)</span>, i.e. using a many-body Slater determinant as a reference state, which is assumed to be a fair approximation to the true ground state. This gives rise to the in-medium similarity renormalization group (IM-SRG) method <span class="citation" data-cites="PhysRevC.85.061304 Hergert2016165 lnp936">(Tsukiyama, Bogner, and Schwenk 2012; Hergert et al. 2016; Hjorth-Jensen, Lombardo, and Kolck 2017)</span>.</p>
<p>We begin by decomposing the Hamiltonian <span class="math inline">\(\hat{H}\)</span> into normal-ordered components relative to an appropriately chosen reference state (Fermi vacuum) <span class="math inline">\(\ket{\Phi}\)</span>: <span id="eq:normordhamiltonian"><span class="math display">\[\hat{H} = E_\Phi + \sum_{p q} H^\Phi_{p q} \normord{\hat{a}_p^\dagger \hat{a}_q^{}} + \frac{1}{4} \sum_{p q r s} H^\Phi_{p q r s} \normord{\hat{a}_p^\dagger \hat{a}_q^\dagger \hat{a}_s^{} \hat{a}_r^{}} + \cdots\qquad(50)\]</span></span> where <span class="math inline">\(E_\Phi\)</span> is the energy of the reference state and <span class="math inline">\(H^\Phi_{p_1 \ldots p_k q_1 \ldots q_k}\)</span> are matrix elements of the <span class="math inline">\(k\)</span>-body component <span class="math inline">\(\hat{H}^\Phi_k\)</span>. In IM-SRG we work exclusively with matrix elements relative to <span class="math inline">\(\ket{\Phi}\)</span>, thus we will omit the <span class="math inline">\(\Phi\)</span> suffix in this section.</p>
<p>The use of a Hamiltonian with components relative to the Fermi vacuum may seem like a triviality – it is still the same <span class="math inline">\(\hat{H}\)</span> after all. However, this makes a critical difference when the operator expressions are <em>truncated</em>, i.e. higher-body components discarded from the computation for efficiency reasons. By normal-ordering the components relative to a reference state <span class="math inline">\(\ket{\Phi}\)</span>, we preserve a portion of the higher-body contributions within the lower-body operators, significantly decreasing the importance of higher-body operators.</p>
<p>Higher-body operators arise from integrating the flow equations of Eq. <a href="print.html#eq:imsrgode">48</a>, which is one of the main challenges of the SRG method. With each evaluation of the commutator, the Hamiltonian gains terms of increasingly higher order, and these induced contributions will in subsequent integration steps feed back into terms of lower order. Thus, the higher-body contributions are not irrelevant to the final solution even if only the ground state energy (zero-body component) is desired.</p>
<p>Computationally, higher-body terms rapidly become unfeasible to handle: naive storage of the matrix elements of <span class="math inline">\(k\)</span>-body operator requires an exponentially increasing amount of memory, <span class="math display">\[\bigo(n_{\mathrm{b}}^{2 k})\]</span> where <span class="math inline">\(n_{\mathrm{b}}\)</span> is the number of single-particle basis states. Moreover, the flow equations are capable of generating an infinite number of higher-body terms as the Hamiltonian evolves. To make the method tractable, the IM-SRG flow equations must be closed by truncating the equations to a finite order. We call this <strong>operator truncation</strong>.</p>
<p>In this work, we truncate both <span class="math inline">\(\hat{H}\)</span> and <span class="math inline">\(\hat{\eta}\)</span> at the two-body level, leading to an approach known as <strong>IM-SRG(2)</strong>. This normal-ordered two-body approximation appears to be sufficient in many cases and has yielded excellent results for several nuclei <span class="citation" data-cites="PhysRevLett.106.222502 PhysRevLett.109.052501 Hergert2016165">(Tsukiyama, Bogner, and Schwenk 2011; Roth et al. 2012; Hergert et al. 2016)</span>.</p>
<p>Operator truncation is but one out of the two primary sources of error in this method. The other source of error comes from <strong>basis truncation</strong>: the size of the single-particle is finite and therefore does not encompass the full infinite-dimensional Hilbert space. This is a concern for any finite-basis approach, including HF, IM-SRG, CC, and many others. This source of error can be reduced by increasing the size of the basis at the expense of greater computational effort, albeit the cost increases much less rapidly in this direction. The CPU cost of IM-SRG methods is polynomial with respect to the number of states in the single-particle basis <span class="math inline">\(n_{\mathrm{b}}\)</span>. For IM-SRG(2) in particular, the CPU cost scales roughly as <span class="math display">\[\mathcal{O}(n_{\mathrm{b}}^6)\]</span> This is comparable to coupled cluster singles-and-doubles (CCSD), which also scales as <span class="math inline">\(\mathcal{O}(n_{\mathrm{b}}^6)\)</span>.</p>
<p>The commutator in the flow equations Eq. <a href="print.html#eq:imsrgode">48</a> ensures that the evolved state <span class="math inline">\(\hat U(s) \ket{\Phi}\)</span> consists of <em>linked diagrams</em> only <span class="citation" data-cites="shavitt2009many">(Shavitt and Bartlett 2009)</span>. This indicates that IM-SRG is a size-extensive <span class="citation" data-cites="ISI:A1981MN73700014">(Bartlett 1981)</span> method by construction, even if the operators are truncated.</p>
<p>An accurate and robust solver is required to solve ordinary differential equation (ODE) in Eq. <a href="print.html#eq:imsrgode">48</a>. In particular, the solver must be capable of handling the stiffness that often arises in such problems. For our numerical experiments, we used a high-order ODE solver algorithm by L. F. Shampine and M. K. Gordon <span class="citation" data-cites="shampine1975computer">(Shampine and Gordon 1975)</span>, which is a multistep method based on the implicit Adams predictor-corrector formulas. Its source code is freely available <span class="citation" data-cites="odesolver sgode">(L. Shampine and Gordon, n.d.; L. Shampine, Gordon, and Yuan, n.d.)</span>.</p>
<p>IM-SRG has relations to several other well-known methods of quantum chemistry such as coupled cluster theory <span class="citation" data-cites="shavitt2009many">(Shavitt and Bartlett 2009)</span>, canonical transformation theory <span class="citation" data-cites="White:cond-mat0201346 CTreview">(White 2002; Neuscamman, Yanai, and Chan 2010)</span>, the irreducible/anti-Hermitian contracted Schrödinger equation approach <span class="citation" data-cites="Mazziotti1 Mazziotti2">(Mazziotti 2007b, 2007a)</span>, and the driven similarity renormalization group method <span class="citation" data-cites="Evangelista">(Evangelista 2014)</span>. These connections are explored in more detail in <span class="citation" data-cites="HeikoReview">(Hergert 2017)</span>.</p>
<h2 id="im-srg-generators"><span class="header-section-number">11.3</span> IM-SRG generators</h2>
<p>With an appropriate choice of the generator <span class="math inline">\(\hat{\eta}\)</span>, the evolved state <span class="math inline">\(\hat U(s) \ket{\Phi}\)</span> will gradually approach a more “diagonal” form. If the “diagonal” form decouples the ground state from the excited states, then <span class="math inline">\(\hat{U}(\infty) \ket{\Phi}\)</span> would yield the exact ground state solution of the problem if no operator or basis truncations are made. In particular, <span class="math inline">\(E_\Phi(\infty)\)</span> would be the exact ground state energy.</p>
<p>The traditional <strong>Wegner generator</strong> <span class="citation" data-cites="Wegner200177">(Wegner 2001)</span> is defined as <span class="math display">\[\hat{\eta}^{\text{Wg}} = [\hat{H}^{\text{d}}, \hat{H} - \hat{H}^{\text{d}}] = [\hat{H}^{\text{d}}, \hat{H}]\]</span> where <span class="math inline">\(\hat{H}^{\text{d}}\)</span> denotes the “diagonal” part of the Hamiltonian and <span class="math inline">\(\hat{H} - \hat{H}^{\text{d}}\)</span> denotes the “off-diagonal” part. This is in the abstract sense described at the end of Section Sec. <a href="print.html#sec:srgmethods">11.1</a>. Since <span class="math inline">\(\hat{H}\)</span> depends on the flow parameter <span class="math inline">\(s\)</span>, so does <span class="math inline">\(\hat{\eta}\)</span> in general.</p>
<p>Since <span class="math inline">\(\hat{\eta}^{\text{Wg}}\)</span> is a commutator between two Hermitian operators, it is antihermitian as required for a generator. Additionally, it can be shown that the commutator has the property of suppressing off-diagonal matrix elements as the state evolves via the flow equation <span class="citation" data-cites="kehrein2006flow">(Kehrein 2006)</span>, as we would like. Matrix elements “far” from the diagonal – i.e. where the Hamiltonian couples states with large energy differences – are suppressed much faster than those “close” to the diagonal.</p>
<p>There exist several other generators in literature. One choice, proposed by White <span class="citation" data-cites="White:cond-mat0201346">(White 2002)</span>, makes numerical approaches much more efficient. The problem with the Wegner generator is the widely varying decaying speeds of the Hamiltonian matrix elements. Terms with large energy separations from the ground state are suppressed initially, followed by those with smaller energy separations. This leads to stiffness in the flow equation, which in turn causes numerical difficulties when solving the set of coupled differential equations.</p>
<p>The <strong>White generator</strong> takes an alternative approach, which is well suited for problems where one is mainly interested in the ground state of a system. Firstly, instead of driving all off-diagonal elements of the Hamiltonian to zero, the generator focuses exclusively on those that are coupled to the reference state <span class="math inline">\(\ket{\Phi}\)</span> so as to decouple the reference state from the remaining Hamiltonian. This reduces the amount of change done to the Hamiltonian, reducing the accuracy lost from the operator truncation. Secondly, the rate of decay in Hamiltonian matrix elements are approximately normalized by dividing the generator matrix elements by an appropriate factor. This ensures that the affected elements decay at approximately the same rate, reducing the stiffness of the flow equations.</p>
<p>The White generator is explicitly constructed in the following way <span class="citation" data-cites="PhysRevLett.106.222502 White:cond-mat0201346">(Tsukiyama, Bogner, and Schwenk 2011; White 2002)</span>: <span id="eq:white-generator"><span class="math display">\[\hat{\eta}^{\text{Wh}} = \hat{\eta}&#39; - \hat{\eta}&#39;{}^\dagger\qquad(51)\]</span></span> where <span class="math inline">\(\hat{\eta}&#39;\)</span> is defined as <span class="math display">\[\hat{\eta}&#39; = \sum_{i \backslash a} \frac{H_{a i}}{\tilde{\Delta}_{a i}} \normord{\hat{a}^\dagger_a \hat{a}_i} + \frac{1}{4} \sum_{i j \backslash a b} \frac{H_{a b i j}}{\tilde{\Delta}_{a b i j}} \normord{\hat{a}^\dagger_a \hat{a}^\dagger_b \hat{a}_j \hat{a}_i} + \cdots\]</span> The symbol <span class="math inline">\(\tilde{\Delta}\)</span> denotes the <strong>Epstein–Nesbet energy denominators</strong> <span class="citation" data-cites="PhysRev.28.695 Nesbet312 shavitt2009many">(Epstein 1926; Nesbet 1955; Shavitt and Bartlett 2009)</span>, defined as <span class="math display">\[\begin{align*}
  \tilde{\Delta}_{a i} &amp;= E_{\Phi_{a i}} - E_\Phi \\
  &amp;= \Delta_{a i} - H_{a i a i} \\
  \tilde{\Delta}_{a b i j} &amp;= E_{\Phi_{a b i j}} - E_\Phi \\
  &amp;= \Delta_{a b i j} + H_{a b a b} - H_{a i a i} - H_{b i b i} + H_{i j i j} - H_{a j a j} - H_{b j b j} \\
  \tilde{\Delta}_{a_1 \ldots a_k i_1 \ldots i_k} &amp;= E_{\Phi_{a_1 \ldots a_k i_1 \ldots i_k}} - E_\Phi
\end{align*}\]</span> whereas <span class="math inline">\(\Delta\)</span> denotes the Møller–Plesset energy denominators <span class="citation" data-cites="MoellerPlesset1934">(Møller and Plesset 1934)</span> defined in Eq. <a href="hartree-fock.html#eq:moellerplessetdenominator">45</a>. White generators can also use Møller–Plesset energy denominators directly in lieu of Epstein–Nesbet energy denominators <span class="citation" data-cites="Hergert2016165">(Hergert et al. 2016)</span>, which leads to a slightly different variant of the White generator. In our calculations, we use exclusively Epstein–Nesbet denominators.</p>
<p>Compared to the Wegner generator, where the derivatives of the final flow equations contain cubes of the Hamiltonian matrix elements (i.e. each term contains a product of 3 one-body and/or two-body matrix elements), the elements in White generators contribute only linearly. This reduces the stiffness in the differential equation, providing a net increase in computational efficiency as stiff ODE solvers tend to be slower and consume more memory.</p>
<h2 id="sec:imsrg-eqs"><span class="header-section-number">11.4</span> IM-SRG(2) equations</h2>
<p>In the 2-body operator truncation scheme, the generator <span class="math inline">\(\hat{\eta}\)</span> can be written as a generic 2-body operator: <span class="math display">\[\hat{\eta} = \sum_{p q} \eta_{p q} \normord{\hat{a}_p^\dagger \hat{a}_q} + \frac{1}{4} \sum_{p q r s} \eta_{p q r s} \normord{\hat{a}_p^\dagger \hat{a}_q^\dagger \hat{a}_s \hat{a}_r}\]</span> where <span class="math inline">\(\eta_{p q}\)</span> and <span class="math inline">\(\eta_{p q r s}\)</span> respectively are its one- and two-body matrix elements normal ordered relative to <span class="math inline">\(\ket{\Phi}\)</span> and subject to the antihermittivity constraint.</p>
<p>The main complication of the IM-SRG flow equation Eq. <a href="print.html#eq:imsrgode">48</a> lies in the commutator, <span class="math display">\[[\hat{\eta}, \hat{H}] = \hat{\eta} \hat{H} - \hat{H} \hat{\eta}\]</span> By expanding the commutator diagrammatically, we find that all terms where <span class="math inline">\(\hat{\eta}\)</span> and <span class="math inline">\(\hat{H}\)</span> are connected (disconnected diagrams) vanish because they commute. The remaining terms are simply the linked products between the two operators, which we denote <span class="math inline">\(\hat{C}(\hat{\eta}, \hat{H})\)</span>, in either order: <span class="math display">\[[\hat{\eta}, \hat{H}] = \hat{C}(\hat{\eta}, \hat{H}) - \hat{C}(\hat{H}, \hat{\eta})\]</span></p>
<p>Consider a generic linked product <span class="math inline">\(\hat{C}(\hat{A}, \hat{B})\)</span> where <span class="math inline">\(\hat{C}\)</span> is a (0, 1, 2, 3)-operator given by <span class="math display">\[\begin{gather*}
  \hat{C} = C_\Phi + \sum_{p q} C_{p q} \normord{\hat{a}_p^\dagger \hat{a}_q} + \frac{1}{4} \sum_{p q r s} C_{p q r s} \normord{\hat{a}_p^\dagger \hat{a}_q^\dagger \hat{a}_s \hat{a}_r} \\
  \quad + \frac{1}{36} \sum_{p q r s t u} C_{p q r s t u} \normord{\hat{a}_p^\dagger \hat{a}_q^\dagger \hat{a}_r^\dagger \hat{a}_u \hat{a}_t \hat{a}_s}
\end{gather*}\]</span> To write out the linked product, we start considering all possible Hugenholtz skeletons<a href="print.html#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a> <span class="math inline">\(\hat{C}^{c a b}\)</span> where <span class="math inline">\(a\)</span> is the rank of the first operator from <span class="math inline">\(\hat{A}\)</span>, <span class="math inline">\(b\)</span> is the rank of the second operator from <span class="math inline">\(\hat{B}\)</span>, and <span class="math inline">\(c\)</span> is the rank of the product diagram. This leads to the following terms: <span class="math display">\[\begin{align*}
  \hat{C}^{0} &amp;= \hat{C}^{011} + \hat{C}^{022} &amp;
  \hat{C}^{1} &amp;= \hat{C}^{111} + \hat{C}^{112} + \hat{C}^{121} + \hat{C}^{122} \\
  \hat{C}^{2} &amp;= \hat{C}^{212} + \hat{C}^{221} + \hat{C}^{222} &amp;
  \hat{C}^{3} &amp;= \hat{C}^{322}
\end{align*}\]</span> We can then elaborate on this by considering all possible assignments of the arrows. We classify these diagrams as <span class="math inline">\(\hat{C}^{c a b d}\)</span> where <span class="math inline">\(d\)</span> is the number of arrows going from <span class="math inline">\(\hat{B}\)</span> toward <span class="math inline">\(\hat{A}\)</span>, which is also the number of particle lines. <span class="math display">\[\begin{align*}
  \hat{C}^{011} &amp;= \hat{C}^{0110} &amp;
  \hat{C}^{022} &amp;= \hat{C}^{0220} \\
  \hat{C}^{111} &amp;= \hat{C}^{1110} + \hat{C}^{1111} &amp;
  \hat{C}^{112} &amp;= \hat{C}^{1120} \\
  \hat{C}^{121} &amp;= \hat{C}^{1210} &amp;
  \hat{C}^{122} &amp;= \hat{C}^{1220} + \hat{C}^{1221} \\
  \hat{C}^{212} &amp;= \hat{C}^{2120} + \hat{C}^{2121} &amp;
  \hat{C}^{221} &amp;= \hat{C}^{2210} + \hat{C}^{2211} \\
  \hat{C}^{222} &amp;= \hat{C}^{2220} + \hat{C}^{2221} + \hat{C}^{2222} &amp;
  \hat{C}^{322} &amp;= \hat{C}^{3220} + \hat{C}^{3221}
\end{align*}\]</span> Finally, we write out the diagrams as, <span class="math display">\[\begin{align*}
  C^{0110}_\Phi &amp;= +\sum_{i \backslash a} A_{i a} B_{a i} &amp;
  C^{0220}_\Phi &amp;= +\frac{1}{4} \sum_{i j \backslash a b} A_{i j a b} B_{a b i j} \\
  C^{1110}_{p q} &amp;= -\sum_{i \backslash} A_{i q} B_{p i} &amp;
  C^{1111}_{p q} &amp;= +\sum_{\backslash a} A_{p a} B_{a q} \\
  C^{1120}_{p q} &amp;= +\sum_{i \backslash a} A_{i a} B_{a p i q} &amp;
  C^{1210}_{p q} &amp;= +\sum_{i \backslash a} A_{i p a q} B_{a i} \\
  C^{1220}_{p q} &amp;= -\frac{1}{2} \sum_{i j \backslash a} A_{i j a q} B_{a p i j} &amp;
  C^{1221}_{p q} &amp;= +\frac{1}{2} \sum_{i \backslash a b} A_{i p a b} B_{a b i q} \\
  C^{2120}_{p q r s} &amp;= -2 \mathcal{A}_{r s} \sum_{i \backslash} A_{i r} B_{p q i s} &amp;
  C^{2121}_{p q r s} &amp;= +2 \mathcal{A}_{p q} \sum_{\backslash a} A_{p a} B_{a q r s} \\
  C^{2210}_{p q r s} &amp;= -2 \mathcal{A}_{p q} \sum_{i \backslash} A_{i q r s} B_{p i} &amp;
  C^{2211}_{p q r s} &amp;= +2 \mathcal{A}_{r s} \sum_{\backslash a} A_{p q a s} B_{a r} \\
  C^{2220}_{p q r s} &amp;= +\frac{1}{2} \sum_{i j \backslash} A_{i j r s} B_{p q i j} &amp;
  C^{2221}_{p q r s} &amp;= -4 \mathcal{A}_{p q} \mathcal{A}_{r s} \sum_{i \backslash a} A_{i q a r} B_{a p i s} \\
  C^{2222}_{p q r s} &amp;= +\frac{1}{2} \sum_{\backslash a b} A_{p q a b} B_{a b r s} \\
  C^{3220}_{p q r s t u} &amp;= -9 \mathcal{A}_{p q r} \mathcal{A}_{s t u} \sum_{i \backslash} A_{i q s t} B_{p r i u} &amp;
  C^{3221}_{p q r s t u} &amp;= +9 \mathcal{A}_{p q r} \mathcal{A}_{s t u} \sum_{\backslash a} A_{p q a t} B_{a r s u}
\end{align*}\]</span> Fig. <a href="print.html#fig:diagrams-imsrg">18</a> shows these diagrams in diagrammatic form.</p>
<figure>
<img src="fig-diagrams-imsrg" alt="Figure 18: Hugenholtz diagrams representing the linked product \hat{C}(\circ, \bullet) in the IM-SRG flow equation, with open circles representing \hat{A} and filled circles representing \hat{B}. We omit diagrams that are related by permutations among the external bra lines or among the external ket lines." id="fig:diagrams-imsrg" /><figcaption>Figure 18: Hugenholtz diagrams representing the linked product <span class="math inline">\(\hat{C}(\circ, \bullet)\)</span> in the IM-SRG flow equation, with open circles representing <span class="math inline">\(\hat{A}\)</span> and filled circles representing <span class="math inline">\(\hat{B}\)</span>. We omit diagrams that are related by permutations among the external bra lines or among the external ket lines.</figcaption>
</figure>
<h2 id="sec:imsrg-j-eqs"><span class="header-section-number">11.5</span> IM-SRG(2) equations in J-scheme</h2>
<p>Once again, we use the implicit-J convention (Sec. <a href="angular-momentum-coupling.html#sec:implicit-j">8.12.3</a>) to write J-scheme equations. Although some equations in J-scheme appear superficially identical to those in M-scheme, they are not interpreted in the same way due to the lack of <span class="math inline">\(m\)</span>-type variables in J-scheme.</p>
<p>The Epstein–Nesbet energy denominators that arise in White generators contain two-body terms that cannot be expressed in J-scheme. As a practical workaround, one could replace occurrences of <span class="math inline">\(H_{p q r s}\)</span> in the denominator with the monopole matrix element <span class="math display">\[H_{p q r s}^{\mathrm{mono}} = \frac{\sum_{j_{p q}} \jweight{j}_{p q}^2 H_{p q r s}}{\sum_{j_{p q}} \jweight{j}_{p q}^2 \tridelta{j_p}{j_q}{j_{p q}}}\]</span> Unlike the usual matrix element <span class="math inline">\(H_{p q r s}\)</span>, the monopole matrix element <span class="math inline">\(H_{p q r s}^{\mathrm{mono}}\)</span> does not depend on <span class="math inline">\(j_{p q}\)</span>.</p>
<p>The replacement by monopole matrix elements leads to the following Epstein–Nesbet energy denominators: <span class="math display">\[\begin{align*}
  \tilde{\Delta}_{a i}^{\mathrm{mono}} &amp;= \Delta_{a i} - H_{a i a i}^{\mathrm{mono}} \\
  \tilde{\Delta}_{a b i j}^{\mathrm{mono}} &amp;= \Delta_{a b i j} + H_{a b a b}^{\mathrm{mono}} - H_{a i a i}^{\mathrm{mono}} - H_{b i b i}^{\mathrm{mono}} + H_{i j i j}^{\mathrm{mono}} - H_{a j a j}^{\mathrm{mono}} - H_{b j b j}^{\mathrm{mono}}
\end{align*}\]</span> These do result in a different White generator, however. The generator in M-scheme is no longer equivalent to that in J-scheme if monopole matrix elements are used.</p>
<p>Finally, here are the J-scheme IM-SRG(2) equations using the implicit-J convention (Sec. <a href="angular-momentum-coupling.html#sec:implicit-j">8.12.3</a>): <span class="math display">\[\begin{align*}
  C^{0110}_\Phi &amp;= +\sum_{i \backslash a} \jweight{j}_i^2 A_{i a} B_{a i} &amp;
  C^{0220}_\Phi &amp;= +\frac{1}{4} \sum_{j_{i j}} \sum_{i j \backslash a b} \jweight{j}_{i j}^2 A_{i j a b} B_{a b i j} \\
  C^{1110}_{p q} &amp;= -\sum_{i \backslash} A_{i q} B_{p i} &amp;
  C^{1111}_{p q} &amp;= +\sum_{\backslash a} A_{p a} B_{a q} \\
  C^{1120}_{p q} &amp;= +\sum_{j_{a p}} \sum_{i \backslash a} \frac{\jweight{j}_{a p}^2}{\jweight{j}_p^2} A_{i a} B_{a p i q} &amp;
  C^{1210}_{p q} &amp;= +\sum_{j_{i p}} \sum_{i \backslash a} \frac{\jweight{j}_{i p}^2}{\jweight{j}_p^2} A_{i p a q} B_{a i} \\
  C^{1220}_{p q} &amp;= -\frac{1}{2} \sum_{j_{a p}} \sum_{i j \backslash a} \frac{\jweight{j}_{a p}^2}{\jweight{j}_p^2} A_{i j a q} B_{a p i j} &amp;
  C^{1221}_{p q} &amp;= +\frac{1}{2} \sum_{j_{i p}} \sum_{i \backslash a b} \frac{\jweight{j}_{i p}^2}{\jweight{j}_p^2} A_{i p a b} B_{a b i q} \\
  C^{2120}_{p q r s} &amp;= -2 \mathcal{A}_{r s} \sum_{i \backslash} A_{i r} B_{p q i s} &amp;
  C^{2121}_{p q r s} &amp;= +2 \mathcal{A}_{p q} \sum_{\backslash a} A_{p a} B_{a q r s} \\
  C^{2210}_{p q r s} &amp;= -2 \mathcal{A}_{p q} \sum_{i \backslash} A_{i q r s} B_{p i} &amp;
  C^{2211}_{p q r s} &amp;= +2 \mathcal{A}_{r s} \sum_{\backslash a} A_{p q a s} B_{a r} \\
  C^{2220}_{p q r s} &amp;= +\frac{1}{2} \sum_{i j \backslash} A_{i j r s} B_{p q i j} &amp;
  \tilde{C}^{2221}_{p s r q} &amp;= +4 \sum_{i \backslash a} \tilde{A}_{i a r q} \tilde{B}_{p s i a} \\
  C^{2222}_{p q r s} &amp;= +\frac{1}{2} \sum_{\backslash a b} A_{p q a b} B_{a b r s}
\end{align*}\]</span> where the tilde symbol (<span class="math inline">\(\tilde{C}\)</span>) denotes non-antisymmetrized Pandya-coupled matrix elements (Sec. <a href="angular-momentum-coupling.html#sec:pandya">8.12.2</a>).</p>
<h1 id="quasidegenerate-perturbation-theory"><span class="header-section-number">12</span> Quasidegenerate perturbation theory</h1>
<p>The IM-SRG method provides a means to calculate the ground state energy of any system that is reasonably approximated by a single Slater determinant. This works well for closed-shell systems, but it does not provide a direct means to obtain the ground state energy of open-shell systems. While there exist more complicated multi-reference approaches to IM-SRG that seek to tackle the general problem <span class="citation" data-cites="Hergert2016165">(Hergert et al. 2016)</span>, we opted to use a perturbative approach, which is simple, inexpensive, and as we shall see from the results, quite effective for many problems.</p>
<p>Quasidegenerate perturbation theory (QDPT) <span class="citation" data-cites="0022-3700-7-18-010 Kvasnicka1974">(Lindgren 1974; Kvasnička 1974)</span> is an extension to the usual perturbation theory framework to support multiple reference states instead of just one. This is useful for solving <em>open-shell</em> systems in which there are multiple reference states sharing similar (quasidegenerate) or equal (degenerate) energies. It is particularly useful if the open-shell system is only a few particles away from a closed-shell system. We will focus primarily on states that are one particle different from a closed-shell system. Specifically, we wish to calculate <strong>addition energies</strong> <span class="math inline">\(\varepsilon_a\)</span> and <strong>removal energies</strong> <span class="math inline">\(\varepsilon_i\)</span> of such systems, defined as <span class="math display">\[\begin{align*}
  \varepsilon_a &amp;= E_{\Phi_a} - E_{\Phi} &amp;
  \varepsilon_i &amp;= E_{\Phi} - E_{\Phi_i}
\end{align*}\]</span> respectively.</p>
<p>As usual in perturbation theory, we start by splitting the Hamiltonian <span class="math inline">\(\hat{H}\)</span> into two components, <span class="math display">\[\hat{H} = \hat{H}^\circ + \hat{V}\]</span> Here <span class="math inline">\(\hat{H}^\circ\)</span> is the zeroth-order <strong>model Hamiltonian</strong> that is easy to solve (typically a non-interacting Hamiltonian) and <span class="math inline">\(\hat{V}\)</span> is the perturbation that makes the problem difficult. We choose <em>a few</em> of the eigenstates of the model Hamiltonian as our set of model states <span class="math inline">\(\ket{u^{\prime\circ}}\)</span>, <span class="math display">\[\hat{H}^\circ \ket{u^{\prime\circ}} = E^\circ_{u&#39;} \ket{u^{\prime\circ}}\]</span> and we want to solve for the corresponding unknown eigenstates <span class="math inline">\(\ket{u}\)</span> of the full Hamiltonian, <span class="math display">\[\hat{H} \ket{u} = E_u \ket{u}\]</span></p>
<p>We define a <strong>wave operator</strong> <span class="math inline">\(\hat{\Omega}\)</span> that projects some set of states <span class="math inline">\(\ket{u^\circ}\)</span> from the model space to the true ground state <span class="math inline">\(\ket{u}\)</span> (i.e. of the full Hamiltonian): <span id="eq:omega-condition1"><span class="math display">\[\ket{u} = \hat{\Omega} \ket{u^\circ}\qquad(52)\]</span></span> where <span class="math inline">\(\ket{u^\circ}\)</span> is taken to be a linear combination of our selection of model states <span class="math inline">\(\ket{u^{\prime\circ}}\)</span>, <span class="math display">\[\ket{u^\circ} = \sum_{u&#39;} \ket{u^{\prime\circ}} C_{u&#39; u}\]</span> with <span class="math inline">\(C_{u&#39; u}\)</span> being some coefficient matrix.</p>
<p>There is some freedom in the choice of the wave operator <span class="math inline">\(\hat{\Omega}\)</span>. We assume it has the following form: <span id="eq:omega-condition2"><span class="math display">\[\hat{\Omega} = \hat{P} + \hat{Q} \hat{\Omega} \hat{P}\qquad(53)\]</span></span> where</p>
<ul>
<li><span class="math inline">\(\hat{P}\)</span> is a projection operator for the model space, <span class="math display">\[\hat{P} = \sum_u \hat{P}_u\]</span></li>
<li><span class="math inline">\(\hat{P}_u\)</span> is the projection operator for <span class="math inline">\(\ket{u^\circ}\)</span>, <span class="math display">\[\hat{P}_u = \ket{u^\circ} \bra{u^\circ}\]</span></li>
<li><span class="math inline">\(\hat{Q}\)</span> is the complement of <span class="math inline">\(\hat{P}\)</span>, <span class="math display">\[\hat{Q} = 1 - \hat{P}\]</span></li>
</ul>
<p>This definition of <span class="math inline">\(\hat{\Omega}\)</span> entails that the exact states <span class="math inline">\(\ket{u}\)</span> are no longer normalized but instead satisfy the so-called <strong>intermediate normalization</strong>, <span class="math display">\[\bkt{u | u^\circ} = 1\]</span></p>
<p>From Eqns. <a href="print.html#eq:omega-condition1">52</a>, <a href="print.html#eq:omega-condition2">53</a> we observe that <span class="math display">\[\hat{\Omega} \hat{H}^\circ = \hat{\Omega} \hat{P} \hat{H}^\circ \hat{P} \hat{\Omega} = \hat{\Omega} \hat{H}^\circ \hat{\Omega}\]</span> <span class="math display">\[\hat{H} \hat{\Omega} = \sum_u \hat{\Omega} E_u \hat{\Omega} \hat{P}_u = \hat{\Omega} \hat{H} \hat{\Omega}\]</span> These equations can be used to simplify the commutator <span class="math inline">\([\hat{\Omega}, \hat{H}^\circ]\)</span>, leading to the <strong>generalized Bloch equation</strong> <span class="citation" data-cites="LindgrenMorrison1986">(Lindgren and Morrison 1986)</span> that defines QDPT: <span class="math display">\[[\hat{\Omega}, \hat{H}^\circ] = (1 - \hat{\Omega}) \hat{V} \hat{\Omega}\]</span> The commutator on the left may be “inverted” using the resolvent approach <span class="citation" data-cites="shavitt2009many">(Shavitt and Bartlett 2009, 50)</span>, resulting in the relation: <span class="math display">\[\hat{Q} \hat{\Omega} \hat{P}_u = \hat{R}_u (1 - \hat{\Omega}) \hat{V} \hat{\Omega} \hat{P}_u\]</span> where <span class="math inline">\(\hat{R}_u\)</span> is the resolvent,<a href="print.html#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a> <span class="math display">\[\hat{R}_u = \hat{Q} (E^\circ_u - \hat{Q} \hat{H}^\circ \hat{Q})^{-1} \hat{Q}\]</span> Now define <span class="math inline">\(\hat{\Omega}\)</span> as a series of terms of increasing order, quantified by the exponent (degree) of the perturbation <span class="math inline">\(\hat{V}\)</span>, <span class="math display">\[\hat{\Omega} = \sum_{n = 0}^\infty \hat{\Omega}^{(n)}\]</span> We can then derive a recursion relation that allows <span class="math inline">\(\hat{\Omega}\)</span> to be calculated to any order <span class="math display">\[\hat{\Omega}^{(n)} = \begin{cases}
  \hat{P} &amp; \text{if } n = 0 \\
  \sum_u \hat{R}_u \left(\hat{V} \hat{\Omega}^{(n - 1)} + \sum_{k = 1}^{n - 1} \hat{\Omega}^{(k)} \hat{V} \hat{\Omega}^{(n - k - 1)}\right) \hat{P}_u &amp; \text{if } n &gt; 0 \\
\end{cases}\]</span> Up to third order, we have <span class="math display">\[\begin{align*}
  \hat{\Omega}^{(1)} \hat{P}_u &amp;= \hat{R}_u \hat{V} \hat{P}_u \\
  \hat{\Omega}^{(2)} \hat{P}_u &amp;=
    \hat{R}_u \biggl(
    \hat{V} \hat{R}_u
    - \sum_v \hat{R}_v \hat{V} \hat{P}_v
    \biggr) \hat{V} \hat{P}_u \\
  \hat \Omega^{(3)} \hat{P}_u &amp;=
    \hat{R}_u \biggl(
    \hat{V} \hat{R}_u \hat{V} \hat{R}_u
    - \hat{V} \hat{R}_u \sum_v \hat{R}_v \hat{V} \hat{P}_v
    - \sum_v \hat{R}_v \hat{V} \hat{P}_v \hat{V} \hat{R}_u \\
  &amp;\qquad
    - \sum_v \hat{R}_v \hat{V} \hat{R}_v \hat{V} \hat{P}_v
    + \sum_v \hat{R}_v \sum_w \hat{R}_w \hat{V} \hat{P}_w \hat{V} \hat{P}_v
    \biggr) \hat{V} \hat{P}_u
\end{align*}\]</span></p>
<p>We can define an <strong>effective Hamiltonian</strong> <span class="math display">\[\hat{H}^{\mathrm{eff}} = \hat{P} \hat{H} \hat{\Omega}\]</span> which acts only in the model space but yields the correct eigenvalues of the full space, <span class="math display">\[\hat{H}^{\mathrm{eff}} \ket{u^\circ} = E_u \ket{u^\circ}\]</span> Thus, the energy corrections are given by: <span class="math display">\[E_u^{(n)} = \begin{cases}
  \bra{u^\circ} \hat{H}^\circ \ket{u^\circ} &amp; \text{if } n = 0 \\
  \bra{u^\circ} \hat{V} \hat{\Omega}^{(n - 1)} \ket{u^\circ} &amp; \text{if } n &gt; 0
\end{cases}\]</span> The coefficients <span class="math inline">\(C_{u&#39; u}\)</span> are obtained by diagonalizing the effective Hamiltonian through the eigenvalue problem, <span id="eq:qdpt-diagonalization"><span class="math display">\[\sum_{v&#39;} \bra{u^{\prime\circ}} \hat{H}^{\mathrm{eff}} \ket{v^{\prime\circ}} C_{v&#39; u} = C_{u&#39; u} E_u\qquad(54)\]</span></span></p>
<h2 id="sec:qdpt-eqs"><span class="header-section-number">12.1</span> QDPT equations</h2>
<p>We now consider the application of QDPT to the treatment of addition and removal energies via the particle-hole formalism. Take each reference state to be a Slater determinant constructed by adding or removing a single particle <span class="math inline">\(u\)</span> to an existing closed-shell Fermi vacuum <span class="math inline">\(\ket{\Phi}\)</span>, <span class="math display">\[\ket{u^\circ} = \ket{\Phi_u}\]</span> Take note that in QDPT <em>Fermi vacuum</em> and <em>reference state</em> are no longer synonymous.</p>
<p>We choose <span class="math inline">\(u\)</span> to be close to the Fermi level: it should be a single-particle state within an adjacent shell (<strong>valence shell</strong>). Therefore, the number of reference states in the model space of QDPT is equal to the number of particles in either the lowest unoccupied shell or the highest occupied shell of <span class="math inline">\(\ket{\Phi}\)</span>, depending on whether we are considering addition or removal energies, respectively.</p>
<p>We can then express the perturbation expansion in terms of summations over matrix elements as we did for the IM-SRG flow equation. We will restrict ourselves to the case where the perturbation <span class="math inline">\(\hat{V}\)</span> is a two-body operator.</p>
<p>The second-order QDPT corrections of the <strong>left-shift operator</strong> (or <strong>reaction operator</strong>) <span class="math inline">\(\hat{W} = \hat{H}^{\mathrm{eff}} - \hat{H}^\circ\)</span> are: <span class="math display">\[
  W^{(2)}_{p q} =+ \frac{1}{2} \sum_{i \backslash a b} \frac{V_{i p a b} V_{a b i q}}{\Delta_{i q a b}} - \frac{1}{2} \sum_{i j \backslash a} \frac{V_{i j a q} V_{a p i j}}{\Delta_{i j a p}}
\]</span> Here, <span class="math inline">\(V_{a b i q}\)</span> are matrix elements of the two-body operator <span class="math inline">\(\hat{V}\)</span> and <span class="math inline">\(\Delta\)</span> denotes Møller–Plesset denominators as defined in Eq. <a href="hartree-fock.html#eq:moellerplessetdenominator">45</a>. These second-order corrections are depicted as perturbative diagrams (Sec. <a href="diagrams.html#sec:perturbative-diagrams">7.1</a>) in Fig. <a href="print.html#fig:diagrams-sfe">19</a>.</p>
<p>Third-order QDPT corrections are: <span class="math display">\[\begin{aligned}
  &amp;W^{(3)}_{p q} =
  \\ &amp;\quad
  + \frac{1}{4} \sum_{i \backslash a b c d} \frac{V_{i p a b} V_{a b c d} V_{c d i q}}{\Delta_{i q a b} \Delta_{i q c d}}
  - \frac{1}{4} \sum_{i j \backslash a b c} \frac{V_{i j a q} V_{a p b c} V_{b c i j}}{\Delta_{i j a p} \Delta_{i j b c}}
  - \frac{1}{4} \sum_{i j \backslash a b c} \frac{V_{i j a b} V_{a b c q} V_{c p i j}}{\Delta_{i j q a b p} \Delta_{i j c p}}
  \\ &amp;\quad
  - \frac{1}{4} \sum_{i j k l \backslash a} \frac{V_{i j a q} V_{k l i j} V_{a p k l}}{\Delta_{i j a p} \Delta_{k l a p}}
  + \frac{1}{4} \sum_{i j k \backslash a b} \frac{V_{i p a b} V_{j k i q} V_{a b j k}}{\Delta_{i q a b} \Delta_{j k a b}}
  + \frac{1}{4} \sum_{i j k \backslash a b} \frac{V_{i j a b} V_{k p i j} V_{a b k q}}{\Delta_{i j q a b p} \Delta_{k q a b}}
  \\ &amp;\quad
  - \frac{1}{2} \sum_{i j k \backslash a b} \frac{V_{i j a b} V_{k p j q} V_{a b i k}}{\Delta_{i j q a b p} \Delta_{i k a b}}
  + \frac{1}{2} \sum_{i j \backslash a b c} \frac{V_{i j a b} V_{b p c q} V_{a c i j}}{\Delta_{i j q a b p} \Delta_{i j a c}}
  + \frac{1}{2} \sum_{i j \backslash a b c} \frac{V_{i p a q} V_{a j b c} V_{b c i j}}{\Delta_{i a} \Delta_{i j b c}}
  \\ &amp;\quad
  + \frac{1}{2} \sum_{i j \backslash a b c} \frac{V_{i j a b} V_{a b i c} V_{c p j q}}{\Delta_{i j q a b p} \Delta_{j q c p}}
  - \frac{1}{2} \sum_{i j k \backslash a b} \frac{V_{i p a q} V_{j k i b} V_{a b j k}}{\Delta_{i a} \Delta_{j k a b}}
  - \frac{1}{2} \sum_{i j k \backslash a b} \frac{V_{i j a b} V_{a k i j} V_{b p k q}}{\Delta_{i j q a b p} \Delta_{k q b p}}
  \\ &amp;\quad
  + \sum_{i j \backslash a b c} \frac{V_{i p a c} V_{j c b q} V_{a b i j}}{\Delta_{i q a c} \Delta_{i j a b}}
  + \sum_{i j \backslash a b c} \frac{V_{i j a b} V_{b p j c} V_{a c i q}}{\Delta_{i j q a b p} \Delta_{i q a c}}
  + \sum_{i j \backslash a b c} \frac{V_{i p a c} V_{j a b i} V_{b c j q}}{\Delta_{i q a c} \Delta_{j q b c}}
  \\ &amp;\quad
  - \sum_{i j k \backslash a b} \frac{V_{i k a q} V_{a j i b} V_{b p j k}}{\Delta_{i k a p} \Delta_{j k b p}}
  - \sum_{i j k \backslash a b} \frac{V_{i k a q} V_{j p b k} V_{a b i j}}{\Delta_{i k a p} \Delta_{i j a b}}
  - \sum_{i j k \backslash a b} \frac{V_{i j a b} V_{b k j q} V_{a p i k}}{\Delta_{i j q a b p} \Delta_{i k a p}}
\end{aligned}\]</span> Perturbative diagrams (Sec. <a href="diagrams.html#sec:perturbative-diagrams">7.1</a>) of third-order corrections are also shown in Fig. <a href="print.html#fig:diagrams-sfe">19</a>.</p>
<figure>
<img src="fig-diagrams-sfe" alt="Figure 19: Perturbative Hugenholtz diagrams (Sec. 7.1) of the second- and third-order QDPT corrections. Denominator lines have been elided. When QDPT is performed on IM-SRG-evolved Hamiltonians, many of the diagrams vanish. The remaining nonvanishing diagrams for addition energy are highlighted in blue and for removal energy are highlighted in red." id="fig:diagrams-sfe" /><figcaption>Figure 19: Perturbative Hugenholtz diagrams (Sec. <a href="print.html#sec:perturbative-diagrams">7.1</a>) of the second- and third-order QDPT corrections. Denominator lines have been elided. When QDPT is performed on IM-SRG-evolved Hamiltonians, many of the diagrams vanish. The remaining nonvanishing diagrams for addition energy are highlighted in blue and for removal energy are highlighted in red.</figcaption>
</figure>
<p>One of the benefits of applying QDPT to an IM-SRG-evolved Hamiltonian is that many of the QDPT terms vanish. In IM-SRG, a generator that decouples the ground state energy is required to drive certain classes of matrix elements to zero. Consider for example the White generator, which eliminates matrix elements of the form: <span class="math display">\[V_{i j a b} = V_{a b i j} = 0\]</span> This means certain kinds of vertices in the diagrams become forbidden, reducing the number of nonzero diagrams at third order from 18 to only four. Out of these four, two of them contribute only to the correction of hole states (removal energies), while the other two contribute only to the correction of the particle states (addition energies).</p>
<p>Note that the final step of diagonalizing the effective Hamiltonian (Eq. <a href="print.html#eq:qdpt-diagonalization">54</a>) is usually not needed for the calculation of single-particle energies with one valence shell as the matrix is often already diagonal due to conservation laws of the quantum system.</p>
<p>In J-scheme, the second-order corrections are: <span class="math display">\[
  W^{(2)}_{p q} =
    \frac{1}{2} \sum_{j_{i p}} \sum_{i \backslash a b}
    \frac{\jweight{j}_{i p}^2}{\jweight{j}_p^2}
    \frac{V_{i p a b} V_{a b i q}}{\Delta_{i q a b}}
  - \frac{1}{2} \sum_{j_{a p}} \sum_{i j \backslash a}
    \frac{\jweight{j}_{a p}^2}{\jweight{j}_p^2}
    \frac{V_{i j a q} V_{a p i j}}{\Delta_{i j a p}}
\]</span> As usual, these equations use the implicit-J convention (Sec. <a href="angular-momentum-coupling.html#sec:implicit-j">8.12.3</a>).</p>
<p>For efficiency, the third-order corrections in J-scheme make use of the non-antisymmetrized Pandya-transformed matrix elements of <span class="math inline">\(\hat{V}\)</span>, which are denoted <span class="math inline">\(\tilde{V}_{p s r q}\)</span> (Sec. <a href="angular-momentum-coupling.html#sec:pandya">8.12.2</a>). Using these matrix elements, we may write the third-order terms as: <span class="math display">\[\begin{aligned}
  &amp;W^{(3)}_{p q} =
  \\ &amp;\quad
  + \frac{1}{4} \sum_{j_{i p}} \sum_{i \backslash a b c d} \frac{\jweight{j}_{i p}^2}{\jweight{j}_p^2} \frac{V_{i p a b} V_{a b c d} V_{c d i q}}{\Delta_{i q a b} \Delta_{i q c d}}
  - \frac{1}{4} \sum_{j_{a p}} \sum_{i j \backslash a b c} \frac{\jweight{j}_{a p}^2}{\jweight{j}_p^2} \frac{V_{i j a q} V_{a p b c} V_{b c i j}}{\Delta_{i j a p} \Delta_{i j b c}}
  \\ &amp;\quad
  - \frac{1}{4} \sum_{j_{c p}} \sum_{i j \backslash a b c} \frac{\jweight{j}_{c p}^2}{\jweight{j}_p^2} \frac{V_{i j a b} V_{a b c q} V_{c p i j}}{\Delta_{i j q a b p} \Delta_{i j c p}}
  - \frac{1}{4} \sum_{j_{a p}} \sum_{i j k l \backslash a} \frac{\jweight{j}_{a p}^2}{\jweight{j}_p^2} \frac{V_{i j a q} V_{k l i j} V_{a p k l}}{\Delta_{i j a p} \Delta_{k l a p}}
  \\ &amp;\quad
  + \frac{1}{4} \sum_{j_{i p}} \sum_{i j k \backslash a b} \frac{\jweight{j}_{i p}^2}{\jweight{j}_p^2} \frac{V_{i p a b} V_{j k i q} V_{a b j k}}{\Delta_{i q a b} \Delta_{j k a b}}
  + \frac{1}{4} \sum_{j_{k p}} \sum_{i j k \backslash a b} \frac{\jweight{j}_{k p}^2}{\jweight{j}_p^2} \frac{V_{i j a b} V_{k p i j} V_{a b k q}}{\Delta_{i j q a b p} \Delta_{k q a b}}
  \\ &amp;\quad
  - \frac{1}{2} \sum_{j_{k p} j_{i j}} \sum_{i j k \backslash a b} \frac{\jweight{j}_{k p}^2 \jweight{j}_{i j}^2}{\jweight{j}_p^2 \jweight{j}_j^2} \frac{V_{i j a b} V_{k p j q} V_{a b i k}}{\Delta_{i j q a b p} \Delta_{i k a b}}
  + \frac{1}{2} \sum_{j_{b p} j_{a b}} \sum_{i j \backslash a b c} \frac{\jweight{j}_{b p}^2 \jweight{j}_{a b}^2}{\jweight{j}_p^2 \jweight{j}_b^2} \frac{V_{i j a b} V_{b p c q} V_{a c i j}}{\Delta_{i j q a b p} \Delta_{i j a c}}
  \\ &amp;\quad
  + \frac{1}{2} \sum_{j_{i p} j_{i j}} \sum_{i j \backslash a b c} \frac{\jweight{j}_{i p}^2 \jweight{j}_{i j}^2}{\jweight{j}_p^2 \jweight{j}_i^2} \frac{V_{i p a q} V_{a j b c} V_{b c i j}}{\Delta_{i a} \Delta_{i j b c}}
  + \frac{1}{2} \sum_{j_{c p} j_{i j}} \sum_{i j \backslash a b c} \frac{\jweight{j}_{c p}^2 \jweight{j}_{i j}^2}{\jweight{j}_p^2 \jweight{j}_j^2} \frac{V_{i j a b} V_{a b i c} V_{c p j q}}{\Delta_{i j q a b p} \Delta_{j q c p}}
  \\ &amp;\quad
  - \frac{1}{2} \sum_{j_{i p} j_{a b}} \sum_{i j k \backslash a b} \frac{\jweight{j}_{i p}^2 \jweight{j}_{a b}^2}{\jweight{j}_p^2 \jweight{j}_a^2} \frac{V_{i p a q} V_{j k i b} V_{a b j k}}{\Delta_{i a} \Delta_{j k a b}}
  - \frac{1}{2} \sum_{j_{b p} j_{a b}} \sum_{i j k \backslash a b} \frac{\jweight{j}_{b p}^2 \jweight{j}_{a b}^2}{\jweight{j}_p^2 \jweight{j}_b^2} \frac{V_{i j a b} V_{a k i j} V_{b p k q}}{\Delta_{i j q a b p} \Delta_{k q b p}}
  \\ &amp;\quad
  + \sum_{j_{c p}} \sum_{i j \backslash a b c} \frac{\jweight{j}_{c p}^2}{\jweight{j}_p^2} \frac{\tilde{V}_{i a c p} \tilde{V}_{c q b j} \tilde{V}_{b j i a}}{\Delta_{i q a c} \Delta_{i j a b}}
  + \sum_{j_{c p}} \sum_{i j \backslash a b c} \frac{\jweight{j}_{c p}^2}{\jweight{j}_p^2} \frac{\tilde{V}_{i a b j} \tilde{V}_{b j c p} \tilde{V}_{c q i a}}{\Delta_{i j q a b p} \Delta_{i q a c}}
  \\ &amp;\quad
  + \sum_{j_{c p}} \sum_{i j \backslash a b c} \frac{\jweight{j}_{c p}^2}{\jweight{j}_p^2} \frac{\tilde{V}_{i a c p} \tilde{V}_{j b i a} \tilde{V}_{c q j b}}{\Delta_{i q a c} \Delta_{j q b c}}
  - \sum_{j_{p k}} \sum_{i j k \backslash a b} \frac{\jweight{j}_{p k}^2}{\jweight{j}_p^2} \frac{\tilde{V}_{i a q k} \tilde{V}_{j b i a} \tilde{V}_{p k j b}}{\Delta_{i k a p} \Delta_{j k b p}}
  \\ &amp;\quad
  - \sum_{j_{p k}} \sum_{i j k \backslash a b} \frac{\jweight{j}_{p k}^2}{\jweight{j}_p^2} \frac{\tilde{V}_{i a q k} \tilde{V}_{p k b j} \tilde{V}_{b j i a}}{\Delta_{i k a p} \Delta_{i j a b}}
  - \sum_{j_{p k}} \sum_{i j k \backslash a b} \frac{\jweight{j}_{p k}^2}{\jweight{j}_p^2} \frac{\tilde{V}_{i a b j} \tilde{V}_{b j q k} \tilde{V}_{p k i a}}{\Delta_{i j q a b p} \Delta_{i k a p}}
\end{aligned}\]</span></p>
<h1 id="application-to-quantum-systems"><span class="header-section-number">13</span> Application to quantum systems</h1>
<p>The two main systems that we study in this work are quantum dots and nuclei. Quantum dots are a remarkably simple system for studying quantum phenomena and provide a testbed for both theoretical calculations and experimental measurements as the strength of its correlations can be easily tuned by adjusting the width of the external trap. In contrast, nuclei are natural, self-bound systems with a nuclear force that is both complicated and uncertain.</p>
<p>For simplicity, we begin with quantum dots and use it to test the effectiveness of our many-body methods. Ultimately, nuclei are the more challenging and intriguing system to study, and they tend to be more practically relevant.</p>
<h1 id="quantum-dots"><span class="header-section-number">14</span> Quantum dots</h1>
<p>Quantum dots, also known as “artificial atoms”, are prototypical quantum systems consisting of electrons confined by an external potential.</p>
<h2 id="quantum-dot-hamiltonian"><span class="header-section-number">14.1</span> Quantum dot Hamiltonian</h2>
<p>We will devote our focus on <em>circular</em> quantum dots, consisting of a collection of nonrelativistic electrons trapped in a two-dimensional harmonic oscillator potential, interacting through the standard Coulomb interaction. The parameters of the system are:</p>
<ul>
<li><span class="math inline">\(N\)</span>: the number of electrons,</li>
<li><span class="math inline">\(m\)</span>: the mass of each electron,</li>
<li><span class="math inline">\(e\)</span>: the charge of each electron,</li>
<li><span class="math inline">\(\epsilon\)</span>: the permittivity of the medium, and</li>
<li><span class="math inline">\(\omega\)</span>: the angular frequency of the harmonic oscillator potential.</li>
</ul>
<p>The three basic components of the Hamiltonian are the kinetic energy <span class="math inline">\(t(\bm{p})\)</span>, the potential energy <span class="math inline">\(u(\bm{r})\)</span>, and the Coulomb interaction <span class="math inline">\(v(R)\)</span>: <span class="math display">\[\begin{align*}
t(\bm{p}) &amp;= \frac{\bm{p}^2}{2 m} &amp;
u(\bm{r}) &amp;= \frac{m \omega^2 \bm{r}^2}{2} &amp;
v(R) &amp;= \frac{e^2}{4 \pi \epsilon |R|}
\end{align*}\]</span> where <span class="math inline">\(\bm{r}\)</span> is the position of an electron relative to the center of the trap, <span class="math inline">\(\bm{p}\)</span> is its linear momentum, and <span class="math inline">\(R\)</span> is the distance between two electrons. The kinetic and potential energies combine to form the standard harmonic oscillator Hamiltonian <span class="math inline">\(h(\bm{r}, \bm{p})\)</span>: <span class="math display">\[h(\bm{r}, \bm{p}) = t(\bm{p}) + u(\bm{r})\]</span></p>
<p>The quantum many-body problem is described by the Hamiltonian <span class="math display">\[\hat{H} = \hat{H}_1 + \hat{H}_2\]</span> where <span class="math inline">\(\hat{H}_1\)</span> and <span class="math inline">\(\hat{H}_2\)</span> are respectively its one- and two-body components,<a href="print.html#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a> namely <span id="eq:onetwobodyhamiltonian"><span class="math display">\[\begin{aligned}
  \hat{H}_1 &amp;= \sum_{\alpha = 1}^N h(\hat{\bm r}_\alpha, \hat{\bm p}_\alpha) \\
  \hat{H}_2 &amp;= \sum_{\alpha = 1}^N \sum_{\beta = 1}^{\alpha - 1} v(|\hat{\bm r}_\alpha - \hat{\bm r}_\beta|)
\end{aligned}\qquad(55)\]</span></span> The operator <span class="math inline">\(\hat{\bm r}_\alpha\)</span> is the position operator of the <span class="math inline">\(\alpha\)</span>-th particle, and <span class="math inline">\(\hat{\bm p}_\alpha = -\mathrm{i} \hat{\bm{\nabla}}_{\bm{r}_\alpha}\)</span> is its momentum operator.</p>
<p>Even though the model system contains five parameters, many of them are redundant. With an appropriate choice of units, the number of parameters in the system can be reduced to just two. For this system, it is convenient to choose <strong>atomic units</strong> where <span class="math display">\[\hbar = m = e = 4 \pi \epsilon = 1\]</span> Here, Hartree <span class="math inline">\(E_{\mathrm{h}}\)</span> is the unit of energy and Bohr radius <span class="math inline">\(a\)</span> is the unit of length: <span class="math display">\[\begin{align*}
  E_{\mathrm{h}} &amp;= m \left(\frac{e^2}{4 \pi \epsilon \hbar}\right)^2 &amp;
  a &amp;= \frac{4 \pi \epsilon \hbar^2}{m e^2}
\end{align*}\]</span> This leaves us with <span class="math inline">\((N, \omega)\)</span> as the only two parameters needed to specify the quantum dot system, with <span class="math inline">\(\omega\)</span> in units of <span class="math inline">\(E_{\mathrm{h}} / \hbar\)</span>.</p>
<h2 id="fockdarwin-basis"><span class="header-section-number">14.2</span> Fock–Darwin basis</h2>
<p>We will use the noninteracting part of the many-body Hamiltonian <span class="math inline">\(\hat{H}_1\)</span> to define the single-particle basis. The single-particle Hamiltonian is of the form: <span class="math display">\[\begin{align*}
  \hat{h} = \frac{1}{2} \hat{\bm{\nabla}}^2 + \frac{1}{2} \omega^2 \hat{\bm{r}}^2
\end{align*}\]</span> In Cartesian coordinates, the two-dimensional harmonic oscillator is trivially reducible to the well-known one-dimensional problem. However, to exploit the circular symmetry, we prefer to use <strong>Fock–Darwin states</strong> <span class="citation" data-cites="Fock1928 darwin_1931">(Fock 1928; Darwin 1931)</span>, which are written in polar coordinates <span class="math inline">\(\bm{r} = (r, \varphi)\)</span>. Such states have the computationally useful property of conserving orbital angular momentum, <span class="math display">\[\hat{L}_3 = -\mathrm{i} \frac{\hat{\partial}}{\partial \varphi}\]</span></p>
<p>The Fock–Darwin wave functions can be decomposed into radial and angular components,<span class="citation" data-cites="lohne2010coupled">(Lohne 2010)</span> <span id="eq:fockdarwin"><span class="math display">\[\begin{aligned}
  &amp;F_{n m_\ell}(r, \varphi) = \sqrt{\frac{m \omega}{\hbar}} R_{n |m_\ell|}\left(\sqrt{\frac{m \omega}{\hbar}} r\right) A_{m_\ell}(\varphi) \\
  &amp;R_{n \mu}(\rho) = \sqrt{2} \mathrm{e}^{-\rho^2 / 2} \rho^\mu \bar{L}_n^\mu(\varrho^2) \\
  &amp;A_{m_\ell}(\varphi) = \frac{1}{\sqrt{2 \pi}} \mathrm{e}^{\mathrm{i} m_\ell \varphi}
\end{aligned}\qquad(56)\]</span></span> in ordinary units. Here, <span class="math inline">\(\sqrt{\hbar / m \omega}\)</span> is the characteristic length of the harmonic oscillator, <span class="math inline">\(\Gamma(x)\)</span> is the gamma function, and <span class="math inline">\(\bar{L}_n^\alpha(x)\)</span> is the <em>normalized</em> variant of the associated Laguerre polynomial <span class="math inline">\(L_n^\alpha(x)\)</span> of degree <span class="math inline">\(n\)</span> and parameter <span class="math inline">\(\alpha\)</span> <span class="citation" data-cites="DLMF">(“NIST Digital Library of Mathematical Functions” 2016)</span>: <span id="eq:laguerre-polynomials"><span class="math display">\[\begin{aligned}
  &amp;\bar{L}^\alpha_n(x) = \sqrt{\frac{n!}{\Gamma(n + \alpha + 1)}} L^\alpha_n(x) \\
  &amp;L_n^\alpha(x) = \frac{1}{n!} x^{-\alpha} \mathrm{e}^x \frac{\mathrm{d}^n}{\mathrm{d} x^n} (\mathrm{e}^{-x} x^{\alpha + n})
\end{aligned}\qquad(57)\]</span></span> The normalized Laguerre polynomials satisfy the following orthogonality relation: <span class="math display">\[\int_0^\infty u^\alpha \E^{-u} \bar{L}_m^{(\alpha)}(u) \bar{L}_n^{(\alpha)}(u) \D u = \delta_{m n}\]</span></p>
<p>The states are labeled by two quantum numbers: the principal quantum number <span class="math inline">\(n \in \{0, 1, 2, \ldots\}\)</span> and orbital angular momentum projection <span class="math inline">\(m_\ell \in \mathbb \{\ldots, -2, -1, 0, +1, +2, \ldots\}\)</span>. For a wave function, <span class="math inline">\(n\)</span> indicates the degree of the Laguerre polynomial, whereas <span class="math inline">\(m_\ell\)</span> is the eigenvalue of <span class="math inline">\(\hat{L}_3\)</span>.</p>
<p>Since electrons are spin-<span class="math inline">\(\frac{1}{2}\)</span> fermions, they can occupy either of the two possible spin states <span class="math inline">\(\chi_{-\frac{1}{2}}\)</span> or <span class="math inline">\(\chi_{+\frac{1}{2}}\)</span>. Thus, every single-particle basis state <span class="math inline">\(|n m_\ell m_s\rangle\)</span> contains both a spatial component  and a spin component, <span id="eq:singleparticlestate"><span class="math display">\[\langle r \varphi m_s&#39; |n m_\ell m_s\rangle = F_{n m_\ell}(r, \varphi) \delta_{m_s^{} m_s&#39;}\qquad(58)\]</span></span> Here we have introduced spin projection <span class="math inline">\(m_s \in \bigl\{-\frac{1}{2}, +\frac{1}{2}\bigr\}\)</span> as the third quantum number, which is the eigenvalue of the spin projection operator <span class="math inline">\(\hat{S}_3\)</span>.</p>
<figure>
<img src="fig-shell-structure" alt="Figure 20: The 42 lowest single-particle states (the first 5 shells) in the 2D harmonic oscillator basis. Each box represents a single-particle state arranged by m_\ell, m_s, and energy, and the up/down arrows indicate the spin of the states. Within each column, the principal quantum number n increases as one traverses upward." id="fig:shell-structure" /><figcaption>Figure 20: The 42 lowest single-particle states (the first 5 shells) in the 2D harmonic oscillator basis. Each box represents a single-particle state arranged by <span class="math inline">\(m_\ell\)</span>, <span class="math inline">\(m_s\)</span>, and energy, and the up/down arrows indicate the spin of the states. Within each column, the principal quantum number <span class="math inline">\(n\)</span> increases as one traverses upward.</figcaption>
</figure>
<p>The energy of the single-particle state <span class="math inline">\(|n m_\ell m_s\rangle\)</span> is given by <span id="eq:energysingleparticlestate"><span class="math display">\[\varepsilon_{n m_\ell m_s} = (2 n + |m_\ell| + 1) \hbar \omega\qquad(59)\]</span></span> in ordinary units. These energies are degenerate with respect to the spin projection <span class="math inline">\(m_s\)</span> as our Hamiltonian <span class="math inline">\(\hat{h}\)</span> does not distinguish between them. Additionally, they are degenerate with respect to the number of quanta <span class="math inline">\(k\)</span>, defined as <span id="eq:shell_index"><span class="math display">\[k = 2 n + |m_\ell|\qquad(60)\]</span></span> We also call <span class="math inline">\(k\)</span> the <strong>shell index of the two-dimensional harmonic oscillator</strong> as this nonnegative integer labels each shell starting from zero. The shells are equidistant with an energy spacing of <span class="math inline">\(\hbar \omega\)</span>. This is depicted graphically in Fig. <a href="print.html#fig:shell-structure">20</a>.</p>
<p>When the number of particles <span class="math inline">\(N\)</span> satisfies <span class="math inline">\(N = K_{\mathrm{F}} (K_{\mathrm{F}} + 1)\)</span> for some nonnegative integer <span class="math inline">\(K_{\mathrm{F}}\)</span>, there would be just enough particles to form a closed-shell Slater determinant, leading to a unique, well-isolated ground state. These specific values of <span class="math inline">\(N\)</span> form the <strong>magic numbers</strong> of this system. We call <span class="math inline">\(K_{\mathrm{F}}\)</span> the <strong>number of filled shells</strong> (or “Fermi level”). In particular, a single-particle state is occupied in the ground state Slater determinant if and only if <span class="math inline">\(k &lt; K_{\mathrm{F}}\)</span>, where <span class="math inline">\(k\)</span> is the shell index of the single-particle state as defined in Eq. <a href="print.html#eq:shell_index">60</a>.</p>
<h2 id="coulomb-interaction-in-the-fockdarwin-basis"><span class="header-section-number">14.3</span> Coulomb interaction in the Fock–Darwin basis</h2>
<p>For many-body calculations, we will need matrix elements of the Coulomb interaction in the Fock–Darwin basis that we chose. The antisymmetrized matrix elements, needed for Eq. <a href="many-body-theory.html#eq:two-body-operator">2</a>, are given by <span class="math display">\[\begin{aligned}
  &amp;\bra{(n m s)_1 (n m s)_2} \hat{H}_2 \ket{(n m s)_3 (n m s)_4} \\
  &amp;= \bra{(n m)_1 (n m)_2} \hat{H}_2 \ket{(n m)_3 (n m)_4} \delta_{s_1 s_3} \delta_{s_2 s_4} \\
  &amp;\quad - \bra{(n m)_1 (n m)_2} \hat{H}_2 \ket{(n m)_4 (n m)_3} \delta_{s_1 s_4} \delta_{s_2 s_3}
\end{aligned}\]</span> where for brevity we have relabeled the quantum numbers with <span class="math inline">\(m = m_\ell\)</span> and <span class="math inline">\(s = m_s\)</span>, and <span id="eq:qdots-integral"><span class="math display">\[\begin{aligned}
  &amp;\bra{(n m)_1 (n m)_2} \hat{H}_2 \ket{(n m)_3 (n m)_4} \\
  &amp;= \frac{e^2}{4 \PI \epsilon} \iint \frac{F_{(n m)_1}(\bm{r}) F_{(n m)_2}(\bm{r}&#39;) F_{(n m)_3}(\bm{r}) F_{(n m)_4}(\bm{r}&#39;)}{|\bm{r} - \bm{r}&#39;|} \D^2 r \D^2 r&#39;
\end{aligned}\qquad(61)\]</span></span> denotes the <em>non-antisymmetrized</em> matrix element in ordinary units, and <span class="math inline">\(F_{n m}(\bm{r})\)</span> denotes a Fock–Darwin wave function.</p>
<p>Analytically, the integral may be evaluated <span class="citation" data-cites="0953-8984-10-3-013">(Anisimovas and Matulis 1998)</span> as <span class="math display">\[\begin{aligned}
  &amp;\frac{\bra{(n m)_1 (n m)_2} \hat{H}_2 \ket{(n m)_3 (n m)_4}}{\sqrt{\hbar \omega E_{\mathrm{h}}}} \\
  &amp;= \delta_{m_1 + m_2, m_3 + m_4} \sqrt{\prod_{i = 1}^4 \frac{n_i!}{(n_i + |m_i|)!}} \sum_{j_1 = 0}^{n_1} \sum_{j_2 = 0}^{n_2} \sum_{j_3 = 0}^{n_3} \sum_{j_4 = 0}^{n_4} \\
  &amp;\qquad \left(\prod_{i = 1}^4  \frac{(-)^{j_i}}{j_i!} \binom{n_i + |m_i|}{n_i - j_i}\right) \frac{1}{2^{(G + 1) / 2}} \sum_{l_1 = 0}^{\gamma_1} \sum_{l_2 = 0}^{\gamma_2} \sum_{l_3 = 0}^{\gamma_3} \sum_{l_4 = 0}^{\gamma_4} \\
  &amp;\qquad\quad \delta_{l_1 + l_2, l_3 + l_4} (-)^{\gamma_2 + \gamma_4 - l_2 - l_4} \Gamma\left(1 + \frac{\Lambda}{2}\right) \Gamma\left(\frac{G - \Lambda + 1}{2}\right) \prod_{i = 1}^4 \binom{\gamma_i}{l_i} \\
  &amp;G = \sum_{i = 1}^4 \gamma_1 \\
  &amp;\Lambda = \sum_{i = 1}^4 l_1 \\
  &amp;\gamma_1 = j_1 + j_3 + \frac{|m_1| + m_1}{2} + \frac{|m_3| - m_3}{2} \\
  &amp;\gamma_2 = j_2 + j_4 + \frac{|m_2| + m_2}{2} + \frac{|m_4| - m_4}{2} \\
  &amp;\gamma_3 = j_3 + j_1 + \frac{|m_3| + m_3}{2} + \frac{|m_1| - m_1}{2} \\
  &amp;\gamma_4 = j_4 + j_2 + \frac{|m_4| + m_4}{2} + \frac{|m_2| - m_2}{2}
\end{aligned}\]</span></p>
<p>However, the analytic approach is rather inefficient: it has effectively 7 nested summations, which means the computational cost of <em>each</em> matrix element grows as <span class="math inline">\(\bigo(k^7)\)</span> where <span class="math inline">\(k\)</span> is the number of shells. It is also prone to precision losses due to the highly oscillatory terms.</p>
<p>A more effective way to compute the integral is through the technique described in <span class="citation" data-cites="2008arXiv0810.2644K">(Kvaal 2008)</span> as implemented in the OpenFCI package. By transforming product states <span class="math inline">\(\ket{(n m)_1 \otimes (n m)_2}\)</span> into their center-of-mass frame, one arrives at a radial integral <span class="math display">\[C^\mu_{n n&#39;} = 2 (-)^{n + n&#39;} \int_0^\infty R^{2 \mu} \bar{L}^\mu_n(R^2) \bar{L}^\mu_{n&#39;}(R^2) v(\sqrt{2} R) \E^{-R^2} R \D R \]</span> where <span class="math inline">\(\bar{L}^\alpha_n(x)\)</span> is the normalized associated Laguerre polynomial defined in Eq. <a href="print.html#eq:laguerre-polynomials">57</a> and <span class="math inline">\(v(R)\)</span> is our central interaction, although this technique generalizes to many kinds of central interactions. The radial integral may be calculated <em>exactly</em> using Gauss–Hermite quadrature of sufficiently high order. The results are transformed back into the laboratory frame using Talmi–Brody–Moshinsky transformation brackets <span class="citation" data-cites="Talmi1952 brody1967tables MOSHINSKY1959104">(Talmi 1952; Brody and Moshinsky 1967; Moshinsky 1959)</span>.</p>
<h1 id="nuclei"><span class="header-section-number">15</span> Nuclei</h1>
<p>The nuclear many-body problem is challenging problem due to the strength of as well as the uncertainty in the interaction.</p>
<h2 id="the-nuclear-hamiltonian"><span class="header-section-number">15.1</span> The nuclear Hamiltonian</h2>
<p>A nucleus is a self-bound system of nucleons: neutrons and protons. The nucleons interact with each other through the nuclear interaction. The parameters of the system are:</p>
<ul>
<li><span class="math inline">\(A\)</span>: the number of nucleons,</li>
<li><span class="math inline">\(N\)</span>: the number of neutrons,<a href="print.html#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a></li>
<li><span class="math inline">\(Z\)</span>: the number of protons,</li>
<li><span class="math inline">\(m\)</span>: the mass of each nucleon, and</li>
<li><span class="math inline">\(\hat{V}\)</span>: the nuclear interaction.</li>
</ul>
<p>Note that for simplicity we treat neutrons and protons as having the same mass, which is generally adequate given the current levels of accuracy.</p>
<p>The many-body Hamiltonian consists of two components, the relative kinetic energy <span class="math inline">\(\hat{T}^{\mathrm{rel}}\)</span> and the nuclear interaction <span class="math inline">\(\hat{V}\)</span>, <span class="math display">\[\hat{H} = \hat{T}^{\mathrm{rel}} + \hat{V}\]</span> The relative kinetic energy is given by: <span class="math display">\[\hat{T}^{\mathrm{rel}} = \sum_{\alpha = 1}^A \frac{\hat{\bm{p}}_\alpha^2}{2 m} - \frac{1}{2 m A} \left(\sum_{\alpha = 1}^A \hat{\bm{p}}_\alpha\right)^2 = \sum_{\alpha = 1}^A \sum_{\beta = 1}^{\alpha - 1} \frac{(\hat{\bm{p}}_\alpha - \hat{\bm{p}}_\beta)^2}{2 m}\]</span> In second quantization, this can be written as a combination of a one-body and a two-body operator: <span class="math display">\[\begin{align*}
  \hat{t}^{\mathrm{rel}}_1(\bm{p}) &amp;= \left(1 - \frac{1}{A}\right) \frac{\hat{\bm{p}}^2}{2 m} &amp;
  \hat{t}^{\mathrm{rel}}_2(\bm{p}, \bm{p}&#39;) &amp;= -\frac{\hat{\bm{p}} \cdot \hat{\bm{p}}&#39;}{m A} \\
  \hat{T}^{\mathrm{rel}}_1 &amp;= \sum_{\alpha = 1}^A \hat{t}^{\mathrm{rel}}_1(\bm{p}_\alpha) &amp;
  \hat{T}^{\mathrm{rel}}_2 &amp;= \sum_{\alpha = 1}^A \sum_{\beta = 1}^{\alpha - 1} \hat{t}^{\mathrm{rel}}_2(\bm{p}_\alpha, \bm{p}_\beta)
\end{align*}\]</span></p>
<p>The units we use in nuclear theory are <span class="math inline">\(\si{MeV}\)</span>, <span class="math inline">\(\si{fm}\)</span>, and combinations thereof. We set the constants <span class="math inline">\(\hbar = c = 1\)</span>.</p>
<h2 id="the-nuclear-interaction"><span class="header-section-number">15.2</span> The nuclear interaction</h2>
<p>The nuclear interaction <span class="math inline">\(\hat{V}\)</span> is generally quite complicated. Typically it is either a two-body operator, or a combination of two-body and three-body operators. In principle, this interaction could even have higher-body operators than three.</p>
<p>Unlike quantum dots, there are many possible choices for <span class="math inline">\(\hat{V}\)</span>, none of which could be considered canonical. This is due to current limitations in the understanding of the nuclear interaction.</p>
<p>So far, the state of the art in nuclear interactions lies in chiral effective field theory (chiral EFT or <span class="math inline">\(\chi\)</span>-EFT) <span class="citation" data-cites="MACHLEIDT20111 RevModPhys.81.1773">(Machleidt and Entem 2011; Epelbaum, Hammer, and Meißner 2009)</span>, which uses a power-counting scheme to build an effective Lagrangian with nucleons as the degrees of freedom. Most of the coupling constants of this Lagrangian are not known <em>a priori</em> and must be determined by fitting experimental data.</p>
<p>Chiral EFT interactions are characterized by the level of truncation in the power-counting scheme, as well as the cut-off momentum <span class="math inline">\(\Lambda\)</span> used for regularization. A commonly used choice in the literature is the nucleon-nucleon interaction of <span class="citation" data-cites="PhysRevC.68.041001">(Entem and Machleidt 2003)</span> computed to the next-to-next-to-next-to-leading order (N<sup>3</sup>LO) with a momentum cutoff at <span class="math inline">\(\Lambda = \SI{500}{MeV}\)</span>. This interaction has proven to be quite accurate in practice.</p>
<p>Many kinds of nuclear interactions, including chiral EFT ones, are typically <em>hard</em> in that they couple low-momentum states with high-momentum ones, caused by the presence of a strongly repulsive core <span class="citation" data-cites="BOGNER201094">(Bogner, Furnstahl, and Schwenk 2010)</span>. This can significantly hinder the convergence of many-body methods, necessitating the use of a large single-particle basis.</p>
<p>To mitigate this, free-space SRG may be used to renormalize the interaction, decoupling the low-momentum states from high-momentum states, thereby <em>softening</em> the interaction. This extra preprocessing step confers significant benefits to the convergence of many-body methods, reducing computational cost <span class="citation" data-cites="PhysRevC.75.061001">(Bogner, Furnstahl, and Perry 2007)</span>.</p>
<p>The SRG softening is characterized by the flow parameter <span class="math inline">\(s_{\mathrm{SRG}}\)</span>, or equivalently by the momentum <span class="math display">\[\lambda_{\mathrm{SRG}} = \frac{1}{s_{\mathrm{SRG}}^4}\]</span> which is not to be confused with the cutoff momentum <span class="math inline">\(\Lambda\)</span> in chiral EFT. In our calculations, we choose <span class="math inline">\(s_{\mathrm{SRG}} = \SI{0.0625}{fm^4}\)</span> or equivalently <span class="math inline">\(\lambda_{\mathrm{SRG}} = \SI{2}{fm^{-1}}\)</span>.</p>
<h2 id="spherical-harmonic-oscillator-basis"><span class="header-section-number">15.3</span> Spherical harmonic oscillator basis</h2>
<p>The standard basis used for nuclei is that of the three-dimensional harmonic oscillator, chosen for both its analytic properties and similarity to the nuclear problem. Note unlike quantum dots, the spherical oscillator basis are <em>not</em> the eigenstates of the one-body part of the nuclear Hamiltonian.</p>
<p>The frequency <span class="math inline">\(\omega\)</span> of the basis is not associated with the physical system, unlike in the case of quantum dots. Therefore, it adds an additional, arbitrary parameter for the nuclear many-body problem. The parameter can be used to evaluate the quality of the result: in a perfect calculation where the results are well converged, there should be no dependence on <span class="math inline">\(\omega\)</span> since it is not a physical parameter.</p>
<p>There are several kinds of bases for the three-dimensional harmonic oscillator. We choose the spherical version to take advantage of angular momentum symmetries. They are given by: <span class="math display">\[\psi_{n \ell m_\ell}(r, \theta, \varphi) = \sqrt{2 \left(\frac{m \omega}{\hbar}\right)^{\ell + 3/2}} r^\ell \E^{-m \omega r^2 / (2 \hbar)} \bar{L}_n^{(\ell + 1/2)}\left(\frac{m \omega r^2}{\hbar}\right) Y_{\ell m_\ell}(\theta, \varphi)\]</span> where <span class="math inline">\(n\)</span> is the principal quantum number, <span class="math inline">\(\ell\)</span> is the orbital angular momentum magnitude, <span class="math inline">\(m_\ell\)</span> is the orbital angular momentum projection, <span class="math inline">\(\bar{L}_n^\alpha\)</span> are normalized associated Laguerre polynomials defined in Eq. <a href="quantum-dots.html#eq:laguerre-polynomials">57</a>, and <span class="math inline">\(Y_{\ell m_\ell}\)</span> are spherical harmonics.</p>
<figure>
<img src="fig-shell-ho3d" alt="Figure 21: Shell structure of the spherical harmonic oscillator" id="fig:shell-ho3d" /><figcaption>Figure 21: Shell structure of the spherical harmonic oscillator</figcaption>
</figure>
<p>The energy is given by: <span class="math display">\[E_{n \ell m_\ell} = \hbar \omega \left(e + \frac{3}{2}\right)\]</span> where <span class="math inline">\(e\)</span> is the <strong>shell index of the three-dimensional harmonic oscillator</strong>: <span id="eq:ho3d-shell-index"><span class="math display">\[e = 2 n + \ell\qquad(62)\]</span></span> which counts shells starting at zero. Compare with Eq. <a href="quantum-dots.html#eq:shell_index">60</a>, which is for the two-dimensional harmonic oscillator. These shells are also equidistant with an energy spacing of <span class="math inline">\(\hbar \omega\)</span>.</p>
<p>Nucleons are associated with two additional non-spatial quantum numbers: spin projection <span class="math inline">\(m_s = \pm 1 / 2\)</span> and isospin projection <span class="math inline">\(m_t = \pm 1 / 2\)</span>. This means a proper nucleonic state should have 5 quantum numbers: <span class="math display">\[\ket{n \ell m_\ell m_s m_t}\]</span></p>
<p>In practice, however, it is more beneficial to use LS coupled states as the nuclear Hamiltonian conserves not <span class="math inline">\(\hat{\bm{L}}\)</span> but <span class="math inline">\(\hat{\bm{J}}\)</span>: <span class="math display">\[\ket{n \ell j m_j m_t} = \sum_{m_\ell m_s} \ket{n \ell m_\ell m_s m_t} \bkt{\ell m_\ell \frac{1}{2} m_s | j m_j}\]</span> The corresponding harmonic oscillator shell structure is shown in Fig. <a href="print.html#fig:shell-ho3d">21</a> using spectroscopic notation <span class="math inline">\(n \ell_j\)</span>, where s, p, d, f correspond to <span class="math inline">\(\ell = 0\)</span>, <span class="math inline">\(\ell = 1\)</span>, <span class="math inline">\(\ell = 2\)</span>, and <span class="math inline">\(\ell = 3\)</span>.</p>
<p>The nuclear Hamiltonian also conserves parity, thus it can be convenient to use the parity quantum number <span class="math inline">\(\pi = (-)^\ell\)</span> in lieu of <span class="math inline">\(\ell\)</span>, since from <span class="math inline">\(\pi\)</span> and <span class="math inline">\(j\)</span> one can recover <span class="math inline">\(\ell\)</span>: <span class="math display">\[\ket{n \pi j m_j m_t} \simeq \ket{n \ell j m_j m_t}\]</span></p>
<p>For calculations, it is necessary to truncate the single-particle harmonic oscillator basis. The simplest way is to impose a limit on the number of shells by the <strong>maximum shell index</strong> parameter <span class="math inline">\(e_{\mathrm{max}}\)</span>: <span id="eq:emax"><span class="math display">\[e \le e_{\mathrm{max}}\qquad(63)\]</span></span> We can analogously limit <span class="math inline">\(n\)</span> and/or <span class="math inline">\(\ell\)</span>: <span id="eq:nlmax"><span class="math display">\[n \le n_{\mathrm{max}} \qquad \qquad \ell \le \ell_{\mathrm{max}}\qquad(64)\]</span></span> On two-particle states constructed from the harmonic oscillator, we may also impose a limit through the <span class="math inline">\(E_{\mathrm{max}}\)</span> parameter (not to be confused with energy): <span id="eq:eemax"><span class="math display">\[e_1 + e_2 \le E_{\mathrm{max}}\qquad(65)\]</span></span> Currently, for our calculations we only use the <span class="math inline">\(e_{\mathrm{max}}\)</span> truncation. In future, we may require other forms of truncation in addition to <span class="math inline">\(e_{\mathrm{max}}\)</span> to keep the basis from growing too rapidly as we explore higher numbers of shells.</p>
<h2 id="matrix-elements-of-kinetic-energy"><span class="header-section-number">15.4</span> Matrix elements of kinetic energy</h2>
<p>For calculations in a harmonic oscillator basis, one often needs to compute matrix elements of the kinetic energy, <span class="math display">\[\langle n&#39; \ell&#39; m_\ell&#39; | \frac{\hat{\bm{p}}^2}{2 m} | n \ell m_\ell \rangle\]</span> Since linear momentum squared <span class="math inline">\(\hat{\bm{p}}^2\)</span> is a scalar, it commutes with angular momentum <span class="math inline">\(\hat{\bm{L}}\)</span> and therefore matrix elements with differing <span class="math inline">\(\ell\)</span> and <span class="math inline">\(m_\ell\)</span> must vanish.</p>
<p>For now, let us use natural units – we will return to ordinary units shortly. To simplify the calculation, observe that <span class="math display">\[\frac{\hat{\bm{p}}^2}{2} = \hat{H} - \frac{\hat{\bm{r}}^2}{2}\]</span> This way, instead of calculating an integral involving a Laplacian, we can get away with an integral involving just <span class="math inline">\(r^2\)</span>.</p>
<p>Using the recurrence relation of Laguerre polynomials, <span class="math display">\[\left(2 n + \ell + \frac{3}{2} - r^2\right) L_n^{(\ell + 1/2)}(r^2) = (n + 1) L_{n + 1}^{(\ell + 1/2)}(r^2) + \left(n + \ell + \frac{1}{2}\right) L_{n - 1}^{(\ell + 1/2)}(r^2)\]</span> we can expand <span class="math display">\[\begin{aligned}
\hat{\bm{r}}^2 | n \ell m_\ell \rangle &amp;= -\sqrt{n \left(n + \ell + \frac{1}{2}\right)} | (n - 1) \ell m_\ell \rangle \\
&amp;\quad + \left(2 n + \ell + \frac{3}{2}\right) | n \ell m_\ell \rangle \\
&amp;\quad - \sqrt{(n + 1) \left(n + \ell + \frac{3}{2}\right)} | (n + 1) \ell m_\ell \rangle
\end{aligned}\]</span> Hence, in ordinary units the matrix elements of potential energy are <span class="math display">\[\begin{align*}
&amp;\langle n&#39; \ell&#39; m_\ell&#39; | \frac{m \omega^2 \hat{\bm{r}}^2}{2} | n \ell m_\ell \rangle = \\
&amp;\quad \frac{\delta_{\ell&#39; \ell} \delta_{m_\ell&#39; m_\ell} \hbar \omega}{2} \left(\left(2 n + \ell + \frac{3}{2}\right) \delta_{n&#39; n} - \sqrt{\eta \left(\eta + \ell + \frac{1}{2}\right)} \delta_{|n&#39; - n| 1}\right)
\end{align*}\]</span> where <span class="math inline">\(\eta = \max\{n&#39;, n\}\)</span> is the larger of the two. From here it is straightforward to compute the matrix elements of kinetic energy, <span id="eq:ho3d-kinetic-energy"><span class="math display">\[\begin{aligned}
&amp;\langle n&#39; \ell&#39; m_\ell&#39; | \frac{\hat{\bm{p}}^2}{2 m} | n \ell m_\ell \rangle = \\
&amp;\quad \frac{\delta_{\ell&#39; \ell} \delta_{m_\ell&#39; m_\ell} \hbar \omega}{2} \left(\left(2 n + \ell + \frac{3}{2}\right) \delta_{n&#39; n} + \sqrt{\eta \left(\eta + \ell + \frac{1}{2}\right)} \delta_{|n&#39; - n| 1}\right)
\end{aligned}\qquad(66)\]</span></span> with the same <span class="math inline">\(\eta\)</span> as defined earlier.</p>
<h1 id="implementation"><span class="header-section-number">16</span> Implementation</h1>
<p>We now discuss the details of our specific implementation of the many-body methods that we have discussed. In our experience, we find a dearth of such documentation in scientific literature, potentially leading to the loss of valuable practical knowledge. We hope readers will find this information helpful for either developing their own codes, reproducing our results, or utilizing our code.</p>
<p>The many-body methods in this work are implemented as part of the Lutario project <span class="citation" data-cites="Lutario">(Yuan, n.d.)</span>, an open-source library written in Rust, dual licensed under the permissive MIT <span class="citation" data-cites="MIT">(“MIT License,” n.d.)</span> and Apache 2.0 licenses <span class="citation" data-cites="Apache2">(“Apache License, Version 2.0,” n.d.)</span>. Lutario implements a J-scheme framework for many-body calculations, upon which HF, Møller–Plesset perturbation theory to second order (MP2), IM-SRG(2), and QDPT3 are written. The code supports several systems, including quantum dots and nuclei, whose results we discuss in detail in the next chapter. The code also contains implementations of infinite matter and homogeneous electron gas, but we have not included any of those results in this work.</p>
<h2 id="programming-language"><span class="header-section-number">16.1</span> Programming language</h2>
<p>Rust is a systems programming language focused on memory safety and performance <span class="citation" data-cites="Rust RustBook">(“Rust,” n.d.; The Rust Project Developers 2017)</span>. It is intended to fulfill a niche similar to those of other close-to-metal languages such as C, C++, or Fortran. These languages are characterized by extremely low overhead on all operations and they offer a high degree of manual control over memory usage and layout. This contrasts with the higher level, garbage-collected languages such as C#, Java, Python, or R, where the manual memory management is eschewed in favor of an automatic memory management with the aid of a garbage collector (GC) that reclaims unused memory without the programmer’s assistance.</p>
<p>Rust differs from mainstream close-to-metal languages like C or C++ in a few critical ways:</p>
<ul>
<li><p>The Rust language is partitioned into <em>safe</em> and <em>unsafe</em> subsets. While the unsafe subset is as flexible and performant as C, the safe subset sacrifices a bit of flexibility or performance so as to prevent the dreaded <em>undefined behavior</em> that plagues similar languages. Use of the safe subset is heavily encouraged by design.</p></li>
<li><p>Among many ideas adopted from research in functional programming languages, it offers a novel <em>affine</em> type system augmented with <em>borrowing</em> semantics, allowing easy management of scarce resources such as memory and file handles.</p></li>
</ul>
<p>In a way, the design choices of Rust is a natural consequence of making safety a top priority and then making pragmatic trade-offs between flexibility and performance.</p>
<p>Nonetheless, our motivation for choosing Rust is not simply because of safety, which is certainly important but not the most important concern in numerical software. Instead, we chose Rust for a combination of reasons:</p>
<ul>
<li><p>Rust includes a subset of the features commonly found in functional programming languages, greatly enhancing productivity. These features include closures, algebraic data types, and traits. While they have also made their way to other languages such as C++, Java, or C#, which were originally object-oriented but have become increasingly multi-paradigm, Rust was originally designed with these features from the outset, and as a result they integrate better into the language’s design, whereas older languages have had to retrofit these features.</p></li>
<li><p>Rust comes with an official package manager Cargo <span class="citation" data-cites="Cargo">(“Cargo: The Rust Package Manager,” n.d.)</span> with high adoption among the community. It makes it extremely easy to build and install Rust <em>crates</em> (packages) from the Rust package registry [CratesIo], while encouraging sharing and reuse of code.</p></li>
<li><p>Rust has a flourishing and close-knit community from many diverse backgrounds, ranging from system programmers to high-performance computing specialists. This aids adoption of the young language and offers a helpful environment for learners.</p></li>
</ul>
<p>With that being said, there are also reasons to not choose Rust:</p>
<ul>
<li><p>Rust remains a very young language by any measure. While the language is officially stable, some portions remain under experimentation. Large parts of the library ecosystem are still in their infancy stages, so there is a high risk of immature, rapidly evolving libraries.</p></li>
<li><p>Rust puts safety above all else. As a result, highly performant but unsafe Rust code can be awkward and non-idiomatic to write. This can often be mitigated with the design of safer data abstractions, but these are also active areas of research.</p></li>
<li><p>The lack of a garbage collector requires significant compromises on abstractions in Rust. For example, closures in Rust are more complex (but also more performant) than those in languages with GC such as Python or JavaScript. One should consider whether these complications are a worthwhile trade-off.</p></li>
</ul>
<p>We will discuss the project with a perspective heavily influenced by Rust, but conceptually many of these apply to C and C++ just as well. We will use Rust snippets to illustrate concepts, but we expect any reader familiar with C++ should have little trouble adjusting to the slightly different notation.</p>
<p>In the next two subsections we will provide some motivations to the design of Rust, which can be safely skipped.</p>
<h3 id="undefined-behavior"><span class="header-section-number">16.1.1</span> Undefined behavior</h3>
<p><strong>Undefined behavior</strong> (UB) is any behavior that is not defined by the language. Compilers are not obliged to detect whether a program has UB. If a program does have UB, the compiled program is not guaranteed to function correctly at all. It should not be confused with <em>implementation-defined</em> behavior, in which the behavior is allowed to vary from platform to platform but must remain documented and predictable.</p>
<p>In C and C++, the list of potential UB is numerous <span class="citation" data-cites="C11">(“ISO International Standard Iso/Iec 9899:2011 – Programming Languages c” 2011, Annex J.2, p. 557 - 571)</span>. To name a few:</p>
<ul>
<li><em>buffer overflow</em>: use of memory beyond the range that was allocated;</li>
<li><em>null pointer dereference</em>: attempting to dereference an invalid (<em>null</em>) pointer;</li>
<li><em>use after free</em>: use of memory that has already been deallocated;</li>
<li><em>use of uninitialized data</em>: attempting to read uninitialized variables or arrays</li>
<li><em>data races</em>: use of the same memory location from multiple threads without proper synchronization, in which at least one of the them is performing a write; and</li>
<li><em>signed arithmetic overflow</em>: when the result of an arithmetic operation is too large or too negative to fit in the signed integer type.</li>
</ul>
<p>In software infrastructure, UB can be a bountiful source for security vulnerabilties. In high-performance computing (HPC), the concern of UB lies less so in security, but more in the risk of incorrect computations with possibly subtle and/or non-deterministic effects. This is especially pernicious as many optimizing compilers for C, C++, and Fortran <em>take for granted that UB never occur</em>, leading to miscompilations when they do inevitably occur as a result of programmer error. The following C program gives an example of miscompilation due to UB:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode c"><code class="sourceCode c"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="dt">int</span> main(<span class="dt">int</span> argc, <span class="dt">char</span> **argv)</a>
<a class="sourceLine" id="cb3-2" data-line-number="2">{</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">    <span class="cf">if</span> (argc == <span class="dv">1</span>) {</a>
<a class="sourceLine" id="cb3-4" data-line-number="4">        <span class="dt">int</span> *p;</a>
<a class="sourceLine" id="cb3-5" data-line-number="5">        <span class="cf">return</span> *p;</a>
<a class="sourceLine" id="cb3-6" data-line-number="6">    }</a>
<a class="sourceLine" id="cb3-7" data-line-number="7">    <span class="cf">return</span> <span class="dv">42</span>;</a>
<a class="sourceLine" id="cb3-8" data-line-number="8">}</a></code></pre></div>
<p>If the program is executed with no arguments, then <code>argc</code> is 1.<a href="print.html#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a> In that scenario, the program has UB: one is not permitted to dereference an uninitialized pointer <code>p</code>. Naively, one would expect an uninitialized variable to contain a random memory address, which is highly likely to be unallocated. Therefore, one would expect the program to crash with a segmentation fault (memory access violation) with high probability. Indeed this is what typically happens if the program is compiled without optimizations (the so-called <code>-O0</code> compiler flag).</p>
<p>However, when compiled <em>with</em> optimizations at level 1 (<code>-O1</code>) or higher under Clang or GNU C Compiler (GCC),<a href="print.html#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a> the program would simply exit silently with <code>42</code>, despite <code>argc</code> being 1. It is as if the compiler had entirely excised the <code>if</code> block from the code, treating <code>argc == 1</code> to be an unfulfillable condition because <code>return *p</code> has undefined behavior, which the compiler assumes is not supposed to ever happen.</p>
<p>In most languages, the programmer may reduce the risk of undefined behavior through appropriate discipline, defensive checks at run time, or the use of safer abstractions. A large fraction of these errors are avoided entirely through automatic memory management.</p>
<h3 id="sec:uniqueness-and-borrowing"><span class="header-section-number">16.1.2</span> Uniqueness and borrowing</h3>
<p>Rust tackles UB from a different angle than most languages: it tries to prevent such mistakes from happening through static analysis of the code (the type system, in particular). This is achieved through two unconventional features adapted from its predecessor Cyclone <span class="citation" data-cites="Jim2002CycloneAS">(Jim et al. 2002)</span>.</p>
<p>The first idea is that of <strong>uniqueness</strong>. Some forms of data are designated as unique, which means once they are consumed or given away they cannot be used again – the compiler assures this. With the guarantee that a piece of data is unique, one effectively has exclusive control over it. Specifically:</p>
<ul>
<li>We can modify its contents without the possibility that another agent might accidentally observe the changes. In particular, if we destroy the object, no-one – not us nor anyone else – can use it again, preventing use-after-free bugs.</li>
<li>We can be certain that its contents will stay the same unless we change it or relinquish control to another part of the program. This is extremely beneficial for not only optimization purposes, but also for readability.</li>
<li>No other thread has this data, so there is no possibility of data races.</li>
</ul>
<p>Uniqueness is a powerful guarantee, but it can also be very limiting. To overcome this Rust offers a complementary feature called <strong>borrowing</strong>, where a unique data is temporarily yielded to another agent for a limited amount of time. This duration of time is known as the <strong>lifetime</strong> of the borrow. Borrowing is classified into two kinds:</p>
<ul>
<li><p>When data is <em>mutably borrowed</em>, the borrower will be granted temporary but exclusive control over the data. The borrower is free to do anything it pleases with the data, but it must guarantee that under all circumstances the data remains valid when the lifetime ends.<a href="print.html#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a> During the lifetime of the borrow, the lender is denied all access to the data and cannot lend it again until the end of the lifetime.</p></li>
<li><p>Alternatively, one can grant a <em>shared borrow</em> of a data, which yields restricted access of the data to the borrower, which typically means the data becomes read-only. During the lifetime of the borrow, the lender can continue granting shared borrows of the data, or access the data directly under the same restrictions.</p></li>
</ul>
<p>This leads to a general programming principle referred to as <em>aliasing XOR mutability</em>: data should be modified only if it has exclusive control over the data. While this principle is not a hard and fast rule, it can aid both readability and compiler optimizations. With the idea of <em>exclusive control</em> encoded within the type system, Rust makes this principle enforceable by the compiler.</p>
<p>The downside of this approach lies in the complications that uniqueness and borrowing introduce to the language and data abstractions. Programming with uniqueness types and borrowing remains fairly novel and under-explored in practice.</p>
<h2 id="structure-of-the-program"><span class="header-section-number">16.2</span> Structure of the program</h2>
<p>Calculations in our many-body program follows a linear pipeline:</p>
<ol type="1">
<li>Basis: Set up data structures needed to organize matrix elements.</li>
<li>Input: Read and/or compute Hamiltonian matrix elements.</li>
<li>HF: Compute coefficient matrix and HF-transformed Hamiltonian.</li>
<li>Normal ordering: Obtain Hamiltonian relative to Fermi vacuum.</li>
<li>IM-SRG: Evolve Hamiltonian using IM-SRG.</li>
<li>QDPT: Compute perturbative corrections to addition and removal energies.</li>
</ol>
<p>The first two steps are highly dependent on the quantum system involved, whereas the remaining steps are designed to be independent of the details of any particular system.</p>
<p>We emphasize that the design of the program grew out of the needs of the program rather than some idealistic vision. From our experience, attempting to dictate an “intuitive” structure to programs generally leads to leaky abstractions and lackluster performance. It is more preferable to allow the program to evolve organically to meet its own computational demands, and develop abstractions and models around the natural flow of data to aid human comprehension.</p>
<h2 id="external-libraries"><span class="header-section-number">16.3</span> External libraries</h2>
<p>We utilize several external libraries in our program. Noteworthy ones include:</p>
<ul>
<li>BLAS (Basic Linear Algebra Subprograms <span class="citation" data-cites="Lawson:1979:BLA:355841.355847">(Lawson et al. 1979)</span>) is used for its vector and matrix operations, especially the GEMM (General Matrix-Matrix Multiplication) routine. Note that we do not use the <em>reference</em> implementation of BLAS from Netlib. We instead use highly optimized implementations such as OpenBLAS <span class="citation" data-cites="OpenBLAS Goto:2008:AHM:1356052.1356053 Wang:2013:AAG:2503210.2503219">(Xianyi, Qian, and Saar 2017; Goto and Geijn 2008; Wang et al. 2013)</span>.</li>
<li>LAPACK (Linear Algebra Package, <span class="citation" data-cites="laug">(Anderson et al. 1999)</span>) is used for solving the eigenvalue problem in the Hartree–Fock method.</li>
<li>The Shampine–Gordon ODE solver <span class="citation" data-cites="shampine1975computer odesolver sgode">(Shampine and Gordon 1975; L. Shampine and Gordon, n.d.; L. Shampine, Gordon, and Yuan, n.d.)</span> is used for solving the IM-SRG flow equation.</li>
<li>The <code>wigner-symbols</code> library <span class="citation" data-cites="WEI1999222 doi:10.1063/1.168745 WSR">(Wei 1999, 1998; “Wigner-Symbols” 2017)</span> is used to calculate of angular momentum (re)coupling coefficients needed for J-scheme.</li>
<li>The non-cryptographic Fowler–Noll–Vo (FNV) <span class="citation" data-cites="FNV">(Fowler et al. 2017)</span> hash algorithm is used for hash tables. Rust’s default choice is more secure, but slower.</li>
</ul>
<h2 id="basis-and-data-layout"><span class="header-section-number">16.4</span> Basis and data layout</h2>
<p>A critical question in computational many-body theory is how one should store the matrix elements, which can be numerous. Generally speaking, while there is no one-size-fits-all solution, there are a few distinct storage layouts that are of use to our three many-body methods. We must also be wary of introducing too many storage layouts, which would introduce bloat and redundancies to our code, reducing compilation speed, and hindering comprehension and maintenance.</p>
<p>One of the first choices lies in the scheme: M-scheme or J-scheme? Since we wish to study nuclei and similar systems, using J-scheme is necessary as the performance of M-scheme code is noticeably worse even for something as small as helium. The divergence in performance will only worsen as one adds more particles and/or shells. But there is also a trade-off: J-scheme code can be more difficult to understand and more difficult to verify. In fact, an easy way to verify J-scheme code would be to perform computations using both J- and M-scheme and compare their results.</p>
<p>One might be tempted to write code that performs both, but fortunately this is mostly unnecessary. J-scheme code can be used to perform <em>pseudo-M-scheme</em> calculations by associating each particle with a fictitious <code>j</code> quantum number that is always zero, which must not be confused with the physical <span class="math inline">\(j\)</span> quantum number. There are certain optimizations that can be done when <code>j</code> is always zero, but this suffices for verifying the correctness of the code.</p>
<p>For codes up to two-body interactions with real matrix elements, we use four separate kinds of operators:</p>
<ul>
<li>zero-body operator</li>
<li>standard-coupled one-body operator</li>
<li>standard-coupled two-body operator</li>
<li>Pandya-coupled two-body operator</li>
</ul>
<p>Zero-body operators are simply floating-point numbers. All other operators are stored as block-diagonal matrices to exploit the sparsity of the matrix. Specifically, because of conservation laws such as <span class="math display">\[[\hat{H}, \hat{J}_3] = 0\]</span> our Hamiltonian matrices are guaranteed to have a certain block diagonal form: <span class="math display">\[m_{\mathrm{j}} \ne m_{\mathrm{j}}&#39; \implies \bra{m_{\mathrm{j}} \alpha} \hat{H} \ket{m_{\mathrm{j}}&#39; \beta} = 0\]</span></p>
<h3 id="matrix-types"><span class="header-section-number">16.4.1</span> Matrix types</h3>
<p>The most basic data type is that of a matrix. A (dense) matrix containing entries of type <code>T</code>, denoted <code>Mat&lt;T&gt;</code>, is a combination of three items,<a href="print.html#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode rust"><code class="sourceCode rust"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw">struct</span> Mat&lt;T&gt; <span class="op">{</span></a>
<a class="sourceLine" id="cb4-2" data-line-number="2">    ptr: *<span class="kw">mut</span> T          <span class="co">// data pointer</span></a>
<a class="sourceLine" id="cb4-3" data-line-number="3">    num_rows: <span class="dt">usize</span>,     <span class="co">// number of rows</span></a>
<a class="sourceLine" id="cb4-4" data-line-number="4">    num_cols: <span class="dt">usize</span>,     <span class="co">// number of columns</span></a>
<a class="sourceLine" id="cb4-5" data-line-number="5"><span class="op">}</span></a></code></pre></div>
<ul>
<li><p>Here, <code>ptr</code> is declared to have type <code>*mut T</code>, namely a mutable pointer to <code>T</code>.<a href="print.html#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a> This is conventional but also somewhat deceptive, because we are actually storing a whole <em>array</em> of <code>T</code> objects at the location. The pointer simply provides the address to the first entry in this array, assuming the array is at least one element long.</p></li>
<li><p>The dimensions are declared to have type <code>usize</code>,<a href="print.html#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a> which is the pointer-sized unsigned integer type conventionally used to store lengths of data in memory.</p></li>
</ul>
<p>We use zero-based indices throughout the discussion.</p>
<p>There are two common matrix layout conventions: <strong>row-major</strong> (colloquially known as <strong>C order</strong>), where the matrix is laid out row by row, or <strong>col-major</strong> (<strong>Fortran order</strong>), where the matrix is laid out column by column. In both cases, the index <span class="math inline">\(f(i, j)\)</span> of an element within the array at <code>ptr</code> is given by the equation <span id="eq:mat-index"><span class="math display">\[f(i, j) = i n + j\qquad(67)\]</span></span> What differs is the interpretation of the variables:</p>
<ul>
<li><p>In the row-major convention, <span class="math inline">\(i\)</span> is the row index, <span class="math inline">\(n\)</span> is the number of columns, and <span class="math inline">\(j\)</span> is the column index.</p></li>
<li><p>In the column-major convention, <span class="math inline">\(i\)</span> is the column index, <span class="math inline">\(n\)</span> is the number of rows, and <span class="math inline">\(j\)</span> is the row index.</p></li>
</ul>
<p>In our code, we adhere to the row-major convention.</p>
<p>We use the <code>Mat&lt;T&gt;</code> data type to represent an <em>owning</em> matrix: it has exclusive ownership of its contents. When a <code>Mat&lt;T&gt;</code> object is destroyed, its associated memory is automatically deallocated by the destructor we implemented.</p>
<p>To share the matrix or submatrices of it, we introduce two separate types <code>MatRef&lt;'a, T&gt;</code> (shared matrix reference) and <code>MatMut&lt;'a, T&gt;</code> (mutable matrix reference). The reference types both have a <strong>lifetime parameter</strong> <code>'a</code> that determines the lifetime of the borrow. Unlike <code>Mat&lt;T&gt;</code>, we introduce an additional field to the contents of <code>MatRef&lt;T&gt;</code> and <code>MatMut&lt;T&gt;</code>:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode rust"><code class="sourceCode rust"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="kw">struct</span> MatRef&lt;T&gt; <span class="op">{</span>       <span class="co">// or MatMut&lt;T&gt;</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2">    ptr: *<span class="kw">const</span> T        <span class="co">// data pointer</span></a>
<a class="sourceLine" id="cb5-3" data-line-number="3">    num_rows: <span class="dt">usize</span>,     <span class="co">// number of rows</span></a>
<a class="sourceLine" id="cb5-4" data-line-number="4">    num_cols: <span class="dt">usize</span>,     <span class="co">// number of columns</span></a>
<a class="sourceLine" id="cb5-5" data-line-number="5">    stride: <span class="dt">usize</span>,       <span class="co">// gap between each row</span></a>
<a class="sourceLine" id="cb5-6" data-line-number="6"><span class="op">}</span></a></code></pre></div>
<p>The <code>stride</code> parameter allows us to extract references of submatrices (incomplete matrices). This is useful because in many situations we only want to operate on, say, the hole states but not the particle states, or vice versa. In this case, the indexing formula in Eq. <a href="print.html#eq:mat-index">67</a> is interpretedly differently: <span class="math inline">\(n\)</span> is now the <em>stride</em> of the matrix.</p>
<p>We also use a triangular matrix data type <code>TriMat&lt;T&gt;</code>, which can represent not just triangular matrices but also <span class="math inline">\(\pm\)</span>-symmetric and <span class="math inline">\(\pm\)</span>-Hermitian matrices. In a (non-strict) triangular matrix data type, we store the diagonal and all elements above it, or the diagonal and all elements below it. Because we chose row-major matrices, the latter convention turns out to be more convenient, as we can write the indexing formula as: <span class="math display">\[g(i, j) = \binom{i + 1}{2} + \binom{j}{1} = \frac{(i + 1) i}{2} + j\]</span> which is independent of the matrix’s dimensions. This formula readily generalizes to higher-rank simplex-shaped tensors.</p>
<p>A block-diagonal matrix is conceptually a matrix composed to square matrices arranged along the diagonal. In terms of data, a block-diagonal matrix is simply an array of matrices. In Rust, this can be represented by the nested type <code>Vec&lt;Mat&lt;T&gt;&gt;</code>, where <code>Vec&lt;M&gt;</code> denotes a growable array<a href="print.html#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a> of objects of type <code>M</code>.</p>
<p>Each block (or <strong>channel</strong> as we often call them in code) is indexed by <span class="math inline">\(l\)</span> (<strong>channel index</strong>) and each element is indexed by a triplet <span class="math inline">\((l, u, v)\)</span>, with <span class="math inline">\(u\)</span> being the row index within the block and <span class="math inline">\(v\)</span> being the column index within the block. The indices <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> are known as <strong>auxiliary indices</strong>. The size of blocks may vary within the matrix. Programmatically, block-diagonal matrices are represented by an array of matrices. In Rust, this would be <code>Vec&lt;Mat&lt;f64&gt;&gt;</code> where <code>Mat&lt;T&gt;</code> denotes our own custom matrix data type with entries of type <code>T</code>.</p>
<p>Effectively, all operations on block-diagonal matrices are performed block-wise. For example, matrix multiplication between two block matrices <span class="math inline">\(A^l_{u v}\)</span> and <span class="math inline">\(B^l_{u v}\)</span> can be written as: <span class="math display">\[C^l_{u w} = \sum_v A^l_{u v} B^l_{v w}\]</span> which is equivalent to <span class="math display">\[\bm{C}^l = \sum_v \bm{A}^l \bm{B}^l\]</span> This is a very convenient computational property. It provides an avenue for the parallelization of block-diagonal matrix multiplication, since the block operations are independent of each other.</p>
<p>We can generalize block-diagonal matrices such that the blocks are no longer required to be square nor do they have to lie on the diagonal. Instead, they simply need to be arranged so as to touch each other at their top-left/bottom-right corners. Implementation of operations on these generalized block-diagonal matrices remains identical.</p>
<p>There are additional optimizations one can apply to the layout of block-diagonal matrices. One can, for example, pack the contents of all matrices into a single contiguous array and store the matrix dimensions in a separate array along with offsets to each of these blocks. The array of offsets <span class="math inline">\(h(l)\)</span>, which we call <strong>block offsets</strong>, is given by the formula <span class="math display">\[h(l) = \sum_{l&#39; = 0}^{l - 1} e(l&#39;)\]</span> where <span class="math inline">\(e(l)\)</span> is the extent of the <span class="math inline">\(l\)</span>-th block, which for an ordinary rectangular block with dimensions <span class="math inline">\(m(l) \times n(l)\)</span> is simply <span class="math inline">\(e(l) = m(l) n(l)\)</span>. For convenience, we allow the indices of <span class="math inline">\(h(l)\)</span> to range from <span class="math inline">\(0\)</span> to <span class="math inline">\(l\)</span> rather than <span class="math inline">\(0\)</span> to <span class="math inline">\(l - 1\)</span> as would be typical with zero-based indexing. The value of <span class="math inline">\(h_l\)</span> is simply the length of the entire array. To save memory, the block offsets can be shared between matrices that have precisely the same layout of blocks.</p>
<h3 id="basis-charts"><span class="header-section-number">16.4.2</span> Basis charts</h3>
<p>A row index pair <span class="math inline">\((l, u)\)</span> can be considered an abstract label for a left basis vector in this matrix, whereas a column index pair <span class="math inline">\((l, v)\)</span> can be considered a label for a right basis vector.</p>
<p>For a one-body operators, each index pair corresponds to a one-particle state in J-scheme, <span class="math display">\[\ket{j \kappa \mu}\]</span> with <span class="math inline">\(j\)</span> being the angular momentum magnitude, <span class="math inline">\(\kappa\)</span> representing all remaining conserved quantum numbers, and <span class="math inline">\(\mu\)</span> representing all remaining non-conserved quantum numbers. Since J-scheme states are reduced states, the angular momentum projection <span class="math inline">\(m\)</span> is absent entirely. The combination of <span class="math inline">\((j, \kappa)\)</span> is conserved, thus we have the bijection <span class="math display">\[l \simeq (j, \kappa)\]</span> in the one-particle basis. In code, we can store this bijection using a special bidirectional lookup table that we call a <strong>chart</strong>, which is a pair of two data structures:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode rust"><code class="sourceCode rust"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="kw">struct</span> Chart&lt;T&gt; <span class="op">{</span></a>
<a class="sourceLine" id="cb6-2" data-line-number="2">    encoder: HashMap&lt;T, <span class="dt">usize</span>&gt;,</a>
<a class="sourceLine" id="cb6-3" data-line-number="3">    decoder: <span class="dt">Vec</span>&lt;T&gt;,</a>
<a class="sourceLine" id="cb6-4" data-line-number="4"><span class="op">}</span></a></code></pre></div>
<p>The encoder is a hash table that maps from a <code>T</code> object into an index, whereas the decoder is a vector that maps from an index to a <code>T</code> object. Here, <code>T</code> can be any hashable object with an equality relation. In this case, we choose <code>T = (Half&lt;i32&gt;, K)</code>, where <code>Half&lt;i32&gt;</code> is our custom data type for representing half-integers like <span class="math inline">\(j\)</span>, and <code>K</code> is the type of <span class="math inline">\(\kappa\)</span>.</p>
<p>In our code, we do not store <span class="math inline">\(\kappa\)</span> directly, but represent <span class="math inline">\(\kappa\)</span> using another abstract index <span class="math inline">\(k\)</span> isomorphic to <span class="math inline">\(\kappa\)</span>. This design allows the type of the <span class="math inline">\(l \simeq (j, k)\)</span> chart to be completely independent of the type of <span class="math inline">\(\kappa\)</span>, avoiding code bloat due to monomorphization. The rationale for this is that most operations in many-body theory only require knowledge of the total angular momentum magnitude <span class="math inline">\(j\)</span> and not of <span class="math inline">\(\kappa\)</span>.</p>
<p>There is also a bijection between <span class="math inline">\(\mu\)</span> and <span class="math inline">\(u\)</span> but it is <span class="math inline">\(l\)</span>-dependent, <span class="math display">\[(l, u) \simeq (l, \mu)\]</span> This bijection is needed to recover the non-conserved quantum numbers and is needed to interpret matrix elements (e.g. reading input matrix elements, displaying output), but is irrelevant within the core of the many-body methods.</p>
<p>For two-body operators, each index pair corresponds to an unnormalized two-particle state in J-scheme, <span class="math display">\[\ket{j_{1 2} \kappa_{1 2} j_1 \kappa_1 \mu_1 j_2 \kappa_2 \mu_2}\]</span> Since <span class="math inline">\(j_{1 2} \kappa_{1 2}\)</span> is conserved, we have the bijection, <span class="math display">\[l_{1 2} \simeq (j_{1 2}, \kappa_{1 2})\]</span> akin to one-particle states.</p>
<p>Notice that the two-particle state can be compressed to <span class="math display">\[\ket{j_{1 2} p_1 p_2}\]</span> where <span class="math inline">\(p\)</span> is some index isomorphic to <span class="math inline">\((j, \kappa, \mu)\)</span> that we call the <strong>orbital index</strong>, <span class="math display">\[p \simeq (j, \kappa, \mu)\]</span> The <span class="math inline">\(\kappa_{1 2}\)</span> disappears because it is determined uniquely by the relation <span id="eq:abelian-kappa"><span class="math display">\[\kappa_{1 2} = \begin{cases}
  \kappa_1 \dot{+} \kappa_2 &amp; \text{if operator standard-coupled} \\
  \kappa_1 \dot{-} \kappa_2 &amp; \text{if operator is Pandya-coupled} \\
\end{cases}\qquad(68)\]</span></span> where the dotted plus sign <span class="math inline">\((\dot{+})\)</span> denotes the Abelian operation used to combine the conserved quantum numbers and the dotted minus sign <span class="math inline">\((\dot{-})\)</span> denotes its inverse. Usually, this is simply addition, but for certain multiplicative quantum numbers like parity this would translate to multiplication.</p>
<p>We thus have the bijection <span class="math display">\[(l_{1 2}, u_{1 2}) \simeq (j_{1 2}, p_1, p_2)\]</span> which allows us to relate two-particle states to one-particle states (<em>orbitals</em>) entirely independent of the concrete quantum numbers. It is not necessary to relate the two-particle index pairs <span class="math inline">\((l_{1 2}, u_{1 2})\)</span> to the concrete quantum numbers directly.</p>
<p>For convenience, we use a specific choice of orbital index, defined as <span class="math display">\[p(l, u) = M(l) + u\]</span> where <span class="math inline">\(M(l)\)</span> is an array of <strong>channel offsets</strong>, defined as <span id="eq:channel-offset"><span class="math display">\[M(l) = \sum_{l&#39; = 0}^{l - 1} m(l&#39;)\qquad(69)\]</span></span> where <span class="math inline">\(m(l&#39;)\)</span> is the number of one-particle states in the one-particle channel <span class="math inline">\(l&#39;\)</span>.</p>
<p>For standard-coupled two-body operators, we impose an additional constraint to save memory: <span class="math display">\[p_1 \ge p_2\]</span> The antisymmetry of the states allows us to easily invert the order if this constraint is violated: <span class="math display">\[\ket{j_{1 2} p_2 p_1} = (-)^{j_1 + j_2 - j_{1 2}} \ket{j_{1 2} p_1 p_2}\]</span></p>
<p>In overall, we classify the bijections into two broad categories:</p>
<ul>
<li>Bijections that are dependent on the concrete quantum numbers <span class="math inline">\(\kappa\)</span> and <span class="math inline">\(\mu\)</span> are stored in a generic<a href="print.html#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a> data structure that we call the <strong>atlas</strong>, which necessarily depend on the types of <span class="math inline">\(\kappa\)</span> and <span class="math inline">\(\mu\)</span>.</li>
<li>Bijections that are independent of the concrete quantum numbers, as well as <strong>layout</strong> information (dimensions and offsets, as in Eqns. <a href="print.html#eq:channel-offset">69</a>, <a href="print.html#eq:part-offset">70</a>) are stored in a non-generic data structure that we call the <strong>scheme</strong>.</li>
</ul>
<p>The scheme is stored within the atlas for convenience, but most many-body methods do not require the atlas at all; they only need the scheme. The atlas is typically only needed during the input stage where matrix elements are read in, for conversion between J-scheme and pseudo-M-scheme, or for identification of basis states in debugging/display.</p>
<h3 id="access-of-matrix-elements"><span class="header-section-number">16.4.3</span> Access of matrix elements</h3>
<p>Within each block, we partition the states into several contiguous parts, indexed by a part label <span class="math inline">\(\chi\)</span>.</p>
<ul>
<li>For the one-body operator, states are divided into hole (<span class="math inline">\(\chi = 0\)</span>) and particle (<span class="math inline">\(\chi = 1\)</span>) parts.</li>
<li>For the standard-coupled two-body operator, states are divided into hole-hole (<span class="math inline">\(\chi = 0\)</span>), hole-particle/particle-hole (<span class="math inline">\(\chi = 1\)</span>), and particle-particle (<span class="math inline">\(\chi = 2\)</span>) parts.</li>
<li>For the Pandya-coupled two-body operator, states are divided into hole-hole (<span class="math inline">\(\chi = (0, 0)\)</span>), hole-particle (<span class="math inline">\(\chi = (0, 1)\)</span>), particle-hole (<span class="math inline">\(\chi = (1, 0)\)</span>), and particle-particle (<span class="math inline">\(\chi = (1, 1)\)</span>) parts.</li>
</ul>
<p>This partitioning scheme makes it possible to avoid unnecessary iteration over states that do not contribute to a many-body diagram.</p>
<p>Implementing this requires subdividing the channels according to <span class="math inline">\(\chi\)</span>, thus we will need analogous quantities to those in Eq. <a href="print.html#eq:channel-offset">69</a>, such as: <span id="eq:part-offset"><span class="math display">\[M(l, \chi) = \sum_{l&#39; = 0}^{l - 1} \sum_{\chi&#39; = 0}^{\chi - 1} m(l&#39;, \chi&#39;)\qquad(70)\]</span></span> which we call the <strong>part offset</strong>. Here, <span class="math inline">\(m(l&#39;, \chi&#39;)\)</span> is the number of one-particle states in the one-particle channel <span class="math inline">\(l&#39;\)</span> within part <span class="math inline">\(\chi&#39;\)</span>.</p>
<p>While the implicit antisymmetrization of standard-coupled two-particle states saves a significant amount of memory, they do complicate the translation of many-body equations into code. To reduce this cognitive load, we introduce an <strong>augmented</strong> two-particle state index triplet <span class="math inline">\((t_{1 2}, l_{1 2}, u_{1 2})\)</span> that includes an extra permutation parameter <span class="math inline">\(t_{1 2}\)</span>. The permutation <span class="math inline">\(t_{1 2}\)</span> can be either 0 or 1 if <span class="math inline">\(p_1 \ne p_2\)</span>, or it can only be 0 if <span class="math inline">\(p_1 = p_2\)</span>.</p>
<ul>
<li>If <span class="math inline">\(t_{1 2} = 0\)</span>, then we interpret <span class="math inline">\((t_{1 2}, l_{1 2}, u_{1 2})\)</span> as the usual state <span class="math inline">\(\ket{j_{1 2}; p_1 p_2}\)</span>.</li>
<li>However, if <span class="math inline">\(t_{1 2} = 1\)</span>, then we interpret <span class="math inline">\((t_{1 2}, l_{1 2}, u_{1 2})\)</span> as the permuted state <span class="math inline">\(\ket{j_{1 2}; p_2 p_1} = (-)^{j_1 + j_2 - j_{1 2}} \ket{j_{1 2}; p_1 p_2}\)</span>.</li>
</ul>
<p>The augmented state <span class="math inline">\((t_{1 2}, l_{1 2}, u_{1 2})\)</span> has the advantage of being in a one-to-one correspondence to our intuitive notion of a two-particle state on paper. Thus it offers a useful abstraction that hides the internal complications of implicit antisymmetrization.</p>
<p>When a matrix element is accessed using an augmented state index, we must perform a phase adjustment depending on the value of <span class="math inline">\(t\)</span>, <span class="math display">\[\begin{align*}
&amp;\mathbf{function}\ \mathrm{get}(V, (t_{1 2}, l_{1 2}, u_{1 2}), (t_{3 4}, l_{3 4}, u_{3 4})) \\
&amp;\quad \mathbf{if}\ l_{1 2} \ne l_{3 4} \\
&amp;\quad\quad 0 \\
&amp;\quad \mathbf{else} \\
&amp;\quad\quad \phi_{1 2} \phi_{3 4} V^{l_{1 2}}_{u_{1 2} u_{3 4}}
\end{align*}\]</span> where <span class="math display">\[\phi_{a b} = \begin{cases}
  0 &amp; \text{if } t_{a b} = 0 \\
  -(-1)^{j_a + j_b - j_{a b}} &amp; \text{if } t_{a b} = 1 \\
\end{cases}\]</span> When a matrix element is <em>set</em> using an augmented state index, we perform the same phase adjustment to the value being set, <span class="math display">\[\begin{align*}
&amp;\mathbf{function}\ \mathrm{set}(V, (t_{1 2}, l_{1 2}, u_{1 2}), (t_{3 4}, l_{3 4}, u_{3 4}), x) \\
&amp;\quad \mathrm{assert}(l_{1 2} = l_{3 4}) \\
&amp;\quad V^{l_{1 2}}_{u_{1 2} u_{3 4}} \leftarrow \phi_{1 2} \phi_{3 4} x
\end{align*}\]</span> where the left arrow <span class="math inline">\((\leftarrow)\)</span> denotes array element assignment. If <span class="math inline">\(l_{1 2} \ne l_{3 4}\)</span>, the operation aborts with an error. However, this setter is a rather leaky abstraction. Suppose we attempt to, say, increment every matrix element by one, <span class="math display">\[V_{p q r s} \leftarrow V_{p q r s} + 1\]</span> using the naive algorithm <span class="math display">\[\begin{align*}
&amp;\mathbf{for}\ \mathrm{pq}\ \mathbf{in}\ \mathrm{all\_augmented\_states} \\
&amp;\quad \mathbf{for}\ \mathrm{rs}\ \mathbf{in}\ \mathrm{all\_augmented\_states} \\
&amp;\quad\quad \mathrm{set}(V, \mathrm{pq}, \mathrm{rs}, \mathrm{get}(V, \mathrm{pq}, \mathrm{rs}) + 1)
\end{align*}\]</span> As it turns out, this will cause many of the matrix elements to be incremented <em>twice</em> instead of just once. This is because multiple augmented states map to the same unaugmented state. To remedy this, we introduce a separate abstraction for the addition-assignment operation defined as <span class="math display">\[\begin{align*}
&amp;\mathbf{function}\ \mathrm{add}(V, (t_{1 2}, l_{1 2}, u_{1 2}), (t_{3 4}, l_{3 4}, u_{3 4}), x) \\
&amp;\quad \mathrm{assert}(l_{1 2} = l_{3 4}) \\
&amp;\quad V^{l_{1 2}}_{u_{1 2} u_{3 4}} \leftarrow V^{l_{1 2}}_{u_{1 2} u_{3 4}} + \frac{\phi_{1 2} \phi_{3 4}}{N_{1 2} N_{3 4}} x
\end{align*}\]</span> where <span class="math inline">\(N_{a b}\)</span> is the normalization factor in Eq. <a href="angular-momentum-coupling.html#eq:two-particle-j-normalization-factor">36</a>, which simplifies to <span class="math inline">\(N_{a b} = 2 - \delta_{p_a p_b}\)</span> if non-existent states are excluded. The denominator helps compensate for the overcounting.</p>
<h3 id="initialization-of-the-basis"><span class="header-section-number">16.4.4</span> Initialization of the basis</h3>
<h4 id="sec:input-single-particle-basis"><span class="header-section-number">16.4.4.1</span> Input single-particle basis</h4>
<p>To set up all the necessary basis structures for many-body theory, we require the following data, all of which are specific to each quantum system:</p>
<ul>
<li><p>We need a list of all single-particle states (“orbitals”) in the quantum system.</p></li>
<li><p>For every single-particle state, we need to know its part label <span class="math inline">\(\chi\)</span>, which tells us whether it is a hole (occupied) state or a particle (unoccupied) state relative to the Fermi vacuum Slater determinant.</p></li>
<li><p>For every single-particle state, we need to know to its <span class="math inline">\(j\)</span>, <span class="math inline">\(\kappa\)</span>, and <span class="math inline">\(\mu\)</span> quantum numbers. We allow both <span class="math inline">\(\kappa\)</span> and <span class="math inline">\(\mu\)</span> to be of practically any type and leave them as generic type parameters.</p></li>
<li><p>We require <span class="math inline">\(\kappa\)</span>-type values (1) to be cloneable, (2) to have a total equality relation, (3) to be hashable, and (4) to form an abelian group (i.e. to support the <span class="math inline">\(\dot{+}\)</span> and <span class="math inline">\(\dot{-}\)</span> operations in Eq. <a href="print.html#eq:abelian-kappa">68</a>). The first three conditions are needed to set up efficient mappings between arbitrary <span class="math inline">\(\kappa\)</span> values and <span class="math inline">\(k\)</span> indices using hash tables.<a href="print.html#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a> The last condition is needed to compute conserved quantum numbers for multi-particle states.</p></li>
<li><p>We require <span class="math inline">\(\mu\)</span>-type values (1) to be cloneable, (2) to have a total equality relation, and (3) to be hashable. These conditions are needed to set up efficient mappings between arbitrary <span class="math inline">\(\mu\)</span> values and <span class="math inline">\(u\)</span> indices.</p></li>
</ul>
<p>Once we have this information, we can construct both the atlas and the scheme data structures for the system.</p>
<h4 id="sec:channelized-atlas-initialization"><span class="header-section-number">16.4.4.2</span> Channelized atlas initialization</h4>
<p>The general process for setting up any channelized basis is straightforward. The input is a sequence of <span class="math inline">\((\lambda, \chi, \mu)\)</span> states, where</p>
<ul>
<li><span class="math inline">\(\lambda\)</span> is the channel,</li>
<li><span class="math inline">\(\chi\)</span> is the part, and</li>
<li><span class="math inline">\(\mu\)</span> is any auxiliary information needed to uniquely identify it within all states of the same <span class="math inline">\(\lambda\)</span>.</li>
</ul>
<p>The output are various charts, including <span class="math inline">\(l \simeq \lambda\)</span> and <span class="math inline">\((l, u) \simeq (l, \mu)\)</span>, and layout information (arrays of dimensions and offsets, such as <span class="math inline">\(M(l)\)</span> in Eq. <a href="print.html#eq:channel-offset">69</a>). The process goes as follows:</p>
<ol type="1">
<li>Iterate over each state <span class="math inline">\((\lambda, \chi, \mu)\)</span> and incrementally build the single-particle chart for <span class="math inline">\(l \simeq \lambda\)</span>. Store each <span class="math inline">\((l, \chi, \mu)\)</span> to a temporary array.</li>
<li>Sort the temporary array in lexicographical order, grouping the states by <span class="math inline">\(l\)</span> and then by <span class="math inline">\(\chi\)</span>.</li>
<li>Iterate over the sorted array to derive the charts <span class="math inline">\(p \simeq (l, u) \simeq (l, \mu)\)</span> and layout information (see Eqns. <a href="print.html#eq:channel-offset">69</a>, <a href="print.html#eq:part-offset">70</a>).</li>
</ol>
<h4 id="many-body-atlas-initialization"><span class="header-section-number">16.4.4.3</span> Many-body atlas initialization</h4>
<p>The channelized atlas initialization procedure is then applied to one-particle, standard-coupled two-particle, and Pandya-coupled two-particle bases:</p>
<ol type="1">
<li><p>To build the one-particle basis for the one-body operator, iterate over the input single-particle basis (Sec. <a href="print.html#sec:input-single-particle-basis">16.4.4.1</a>) states <span class="math inline">\((\chi, j, \kappa, \mu)\)</span> and incrementally update the single-particle channel chart <span class="math inline">\(k \simeq \kappa\)</span>. The states <span class="math inline">\((\lambda = (j, k), \chi, \mu)\)</span> are then passed to the channelized atlas initialization procedure (Sec. <a href="print.html#sec:channelized-atlas-initialization">16.4.4.2</a>) to obtain the necessary charts and layouts.</p></li>
<li><p>To build the two-particle basis for the standard-coupled two-body operator, iterate over the Cartesian product of the single-particle states with itself, yielding <span class="math inline">\((l_1, u_1, l_2, u_2)\)</span> per iteration:</p>
<ol type="a">
<li>Use the single-particle chart to recover <span class="math inline">\(p_1\)</span>, <span class="math inline">\(p_2\)</span>, <span class="math inline">\(j_1\)</span>, <span class="math inline">\(j_2\)</span>, <span class="math inline">\(\kappa_1\)</span>, <span class="math inline">\(\kappa_2\)</span>, <span class="math inline">\(\chi_1\)</span>, and <span class="math inline">\(\chi_2\)</span>.</li>
<li>Skip the iteration if <span class="math inline">\(p_1 &lt; p_2\)</span>.</li>
<li>Compute <span class="math inline">\(\kappa_{12} = \kappa_1 \dot{+} \kappa_2\)</span> and <span class="math inline">\(\chi_{12} = \chi_1 + \chi_2\)</span> (<span class="math inline">\(\chi_1, \chi_2 \in \{0, 1\}\)</span> and <span class="math inline">\(\chi_{12} \in \{0, 1, 2\}\)</span>).</li>
<li>Update the two-particle channel chart <span class="math inline">\(k_{12} \simeq \kappa_{12}\)</span>.</li>
<li>For each <span class="math inline">\(j_{12}\)</span> compatible with <span class="math inline">\(\tridelta{j_1}{j_2}{j_{12}}\)</span>, push the state <span class="math inline">\((\lambda = (j_{12}, k_{12}), \chi = \chi_{12}, \mu = (p_1, p_2))\)</span> into a temporary array.</li>
</ol>
<p>Finally, pass the temporary array of states to the channelized atlas initialization procedure (Sec. <a href="print.html#sec:channelized-atlas-initialization">16.4.4.2</a>) to obtain the necessary charts and layouts.<a href="print.html#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a></p></li>
<li><p>To build the two-particle basis for the Pandya-coupled two-body operator, iterate over the Cartesian product of the single-particle states with itself, yielding <span class="math inline">\((l_1, u_1, l_4, u_4)\)</span> per iteration:</p>
<ol type="a">
<li>Use the single-particle chart to recover <span class="math inline">\(p_1\)</span>, <span class="math inline">\(p_4\)</span>, <span class="math inline">\(j_1\)</span>, <span class="math inline">\(j_4\)</span>, <span class="math inline">\(\kappa_1\)</span>, <span class="math inline">\(\kappa_4\)</span>, <span class="math inline">\(\chi_1\)</span>, and <span class="math inline">\(\chi_4\)</span>.</li>
<li>Compute <span class="math inline">\(\kappa_{14} = \kappa_1 \dot{-} \kappa_4\)</span> and <span class="math inline">\(\chi_{14} = \chi_1 + 2 \chi_4\)</span> (<span class="math inline">\(\chi_1, \chi_4 \in \{0, 1\}\)</span> and <span class="math inline">\(\chi_{14} \in \{0, 1, 2, 3\}\)</span>).</li>
<li>Update the two-particle channel chart <span class="math inline">\(k_{14} \simeq \kappa_{14}\)</span>.</li>
<li>For each <span class="math inline">\(j_{14}\)</span> compatible with <span class="math inline">\(\tridelta{j_1}{j_4}{j_{14}}\)</span>, push the state <span class="math inline">\((\lambda = (j_{14}, k_{14}), \chi = \chi_{14}, \mu = (p_1, p_4))\)</span> into a temporary array.</li>
</ol>
<p>Finally, pass the temporary array of states to the channelized atlas initialization procedure (Sec. <a href="print.html#sec:channelized-atlas-initialization">16.4.4.2</a>) to obtain the necessary charts and layouts.</p></li>
</ol>
<p>Note that step 2 and 3 differ in only two aspects: the abelian operation used for <span class="math inline">\(\kappa\)</span> (addition vs subtraction), and the presence or absence of the implicit antisymmetrization constraint <span class="math inline">\(p_1 \ge p_2\)</span>.</p>
<h4 id="basis-initialization-for-quantum-dots"><span class="header-section-number">16.4.4.4</span> Basis initialization for quantum dots</h4>
<p>The Fock–Darwin basis is used for quantum dot calculations.</p>
<p>In our implementation of the quantum dot system, <span class="math inline">\(j\)</span> is not used, so we can simply set it to zero throughout. The set of conserved quantum numbers are <span class="math inline">\(\kappa = (m_\ell, m_s)\)</span>, the projections of orbital angular momentum and spin. This leaves us with <span class="math inline">\(\mu = n\)</span>, the principal quantum number.</p>
<p>The abelian group on <span class="math inline">\(\kappa = (m_\ell, m_s)\)</span> is defined in a straightforward manner: <span class="math display">\[\begin{gather*}
  \dot{0} = (0, 0) \\
  (m_\ell, m_s) \dot{+} (m_\ell&#39;, m_s&#39;) = (m_\ell + m_\ell&#39;, m_s + m_s&#39;) \\
  (m_\ell, m_s) \dot{-} (m_\ell&#39;, m_s&#39;) = (m_\ell - m_\ell&#39;, m_s - m_s&#39;)
\end{gather*}\]</span></p>
<p>The occupied states for quantum dots are always selected in complete shells – a shell consists of all states that share the same single-particle energy in Eq. <a href="quantum-dots.html#eq:energysingleparticlestate">59</a>. Moreover, systems we study always contain complete shells filled from the bottom. These are the <span class="math inline">\(N\)</span>-particle electron configurations we use:</p>
<ul>
<li><span class="math inline">\(N = 2\)</span>: <span class="math inline">\(0\mathrm{s}^2\)</span></li>
<li><span class="math inline">\(N = 6\)</span>: <span class="math inline">\(0\mathrm{s}^2 0\mathrm{p}^4\)</span></li>
<li><span class="math inline">\(N = 12\)</span>: <span class="math inline">\(0\mathrm{s}^2 0\mathrm{p}^4 1\mathrm{s}^2 0\mathrm{d}^4\)</span></li>
<li><span class="math inline">\(N = 20\)</span>: <span class="math inline">\(0\mathrm{s}^2 0\mathrm{p}^4 1\mathrm{s}^2 0\mathrm{d}^4 1\mathrm{p}^4 0\mathrm{f}^4\)</span></li>
<li>etc.</li>
</ul>
<p>Here, the notation <span class="math inline">\(n \ell^i\)</span> means there are <span class="math inline">\(i\)</span> particles in states with <span class="math inline">\(n\)</span> and <span class="math inline">\(|m_\ell| = \ell\)</span> and <span class="math inline">\(\mathrm{s} \leftrightarrow 0\)</span>, <span class="math inline">\(\mathrm{p} \leftrightarrow 1\)</span>, <span class="math inline">\(\mathrm{d} \leftrightarrow 2\)</span>, <span class="math inline">\(\mathrm{f} \leftrightarrow 3\)</span>, as usual for spectroscopic notation.</p>
<h4 id="basis-initialization-for-nuclei"><span class="header-section-number">16.4.4.5</span> Basis initialization for nuclei</h4>
<p>The 3D harmonic oscillator basis is used for nuclei calculations.</p>
<p>In J-scheme nuclear calculations, the input <span class="math inline">\(j\)</span> quantum number is simply the total angular momentum magnitude <span class="math inline">\(j\)</span>. The set of conserved quantum numbers are <span class="math inline">\(\kappa = (\pi, m_t)\)</span>, parity and isospin projection. This leaves us with <span class="math inline">\(\mu = n\)</span>, the principal quantum number.</p>
<p>The abelian group on <span class="math inline">\(\kappa = (\pi, m_t)\)</span> is defined as: <span class="math display">\[\begin{gather*}
  \dot{0} = (+, 0) \\
  (\pi, m_t) \dot{+} (\pi&#39;, m_t&#39;) = (\pi \pi&#39;, m_t + m_t&#39;) \\
  (\pi, m_t) \dot{-} (\pi&#39;, m_t&#39;) = (\pi \pi&#39;, m_t - m_t&#39;) \\
\end{gather*}\]</span></p>
<p>In pseudo-M-scheme nuclear calculations, which we use mainly for testing purposes, the input <span class="math inline">\(j\)</span> quantum number<a href="print.html#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a> is artificially set to zero. The set of conserved quantum numbers are <span class="math inline">\(\kappa = (\pi, m_j, m_t)\)</span>, parity and the projections of total angular momentum and isospin. This leaves us with <span class="math inline">\(\mu = (n, j)\)</span>, the principal quantum number and total angular momentum magnitude. Note that <span class="math inline">\(j\)</span> cannot be put into <span class="math inline">\(\kappa\)</span> because we are using uncoupled two-particle states.</p>
<p>The abelian group on <span class="math inline">\(\kappa = (\pi, m_j, m_t)\)</span> is defined as: <span class="math display">\[\begin{gather*}
  \dot{0} = (+, 0, 0) \\
  (\pi, m_j, m_t) \dot{+} (\pi&#39;, m_j&#39;, m_t&#39;) = (\pi \pi&#39;, m_j + m_j&#39;, m_t + m_t&#39;) \\
  (\pi, m_j, m_t) \dot{-} (\pi&#39;, m_j&#39;, m_t&#39;) = (\pi \pi&#39;, m_j - m_j&#39;, m_t - m_t&#39;) \\
\end{gather*}\]</span></p>
<h2 id="input-matrix-elements"><span class="header-section-number">16.5</span> Input matrix elements</h2>
<p>The procurement of input matrix elements varies wildly from system to system and there is not much code that can be shared among them outside of I/O utilities.</p>
<h3 id="inputs-for-quantum-dots"><span class="header-section-number">16.5.1</span> Inputs for quantum dots</h3>
<p>The one-body matrix for quantum dots is diagonal and can be computed using Eq. <a href="quantum-dots.html#eq:energysingleparticlestate">59</a>.</p>
<p>Two-body matrix elements are more difficult to compute. We outsource the bulk of the work to the OpenFCI package <span class="citation" data-cites="2008arXiv0810.2644K">(Kvaal 2008)</span> and precompute the non-antisymmetrized matrix elements of Eq. <a href="quantum-dots.html#eq:qdots-integral">61</a> with the frequency-dependence factored out: <span class="math display">\[\frac{\bra{(n m)_1 (n m)_2} \hat{H}_2 \ket{(n m)_3 (n m)_4}}{\sqrt{\hbar \omega E_{\mathrm{h}}}}\]</span> (Recall that <span class="math inline">\(m\)</span> is a shorthand for <span class="math inline">\(m_\ell\)</span> for quantum dots.)</p>
<p>The elements are stored in a simple binary file format. In this format, the file is contiguous array of 16-byte entries, where the first 8 bytes of each entry contains the quantum numbers <span class="math inline">\(n_1, m_1, n_2, m_2, n_3, m_3, n_4, m_4\)</span> in that order. Each <span class="math inline">\(n\)</span> is an 8-bit unsigned integer and each <span class="math inline">\(m\)</span> is a 8-bit signed integer. The remaining 8 bytes contain the value of the matrix element as a little-endian 64-bit IEEE 754 double-precision floating-point number. Schematically, we can depict an entry as the following structure:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode rust"><code class="sourceCode rust"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="kw">struct</span> Entry <span class="op">{</span></a>
<a class="sourceLine" id="cb7-2" data-line-number="2">    n1:    <span class="dt">u8</span>,</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">    m1:    <span class="dt">i8</span>,</a>
<a class="sourceLine" id="cb7-4" data-line-number="4">    n2:    <span class="dt">u8</span>,</a>
<a class="sourceLine" id="cb7-5" data-line-number="5">    m2:    <span class="dt">i8</span>,</a>
<a class="sourceLine" id="cb7-6" data-line-number="6">    n3:    <span class="dt">u8</span>,</a>
<a class="sourceLine" id="cb7-7" data-line-number="7">    m3:    <span class="dt">i8</span>,</a>
<a class="sourceLine" id="cb7-8" data-line-number="8">    n4:    <span class="dt">u8</span>,</a>
<a class="sourceLine" id="cb7-9" data-line-number="9">    m4:    <span class="dt">i8</span>,</a>
<a class="sourceLine" id="cb7-10" data-line-number="10">    value: <span class="dt">f64</span>,</a>
<a class="sourceLine" id="cb7-11" data-line-number="11"><span class="op">}</span></a></code></pre></div>
<p>To save space, not all matrix elements are stored. We restrict matrix elements to those that satisfy both of the following canonicalization conditions: <span class="math display">\[\begin{align*}
  (p_1, p_2) &amp;\le \operatorname{sort}(p_3, p_4) &amp;
  (p_1, p_3) &amp;\le (p_2, p_4)
\end{align*}\]</span> where <span class="math display">\[\begin{gather*}
  \operatorname{sort}(p_3, p_4) = \begin{cases}
    (p_3, p_4) &amp; \text{if } p_3 \le p_4 \\
    (p_4, p_3) &amp; \text{otherwise} \\
  \end{cases} \\
  p_i = \frac{k_i (k_i + 2) + m_i}{2} \\
  k_i = 2 n_i + |m_i|
\end{gather*}\]</span> Note that comparisons such as <span class="math inline">\((a, b) \le (c, d)\)</span> use lexicographical ordering.</p>
<h3 id="inputs-for-nuclei"><span class="header-section-number">16.5.2</span> Inputs for nuclei</h3>
<p>The one-body matrix for nuclei is the kinetic energy operator, which is not diagonal but can still be easily computed using Eq. <a href="nuclei.html#eq:ho3d-kinetic-energy">66</a>. Note that the equation does <em>not</em> include the <span class="math inline">\((1 - 1/A)\)</span> factor that arises from the center-of-mass kinetic energy subtraction.</p>
<p>The two-body matrix elements consists of two parts. Firstly, there is a two-body component arising from the center-of-mass kinetic energy subtraction: <span class="math display">\[\bra{p q} \left(-\frac{\hat{\bm{p}}_1 \cdot \hat{\bm{p}}_2}{m A}\right) \ket{p q}\]</span> This quantity can be computed easily in the center-of-mass frame. The Talmi–Brody–Moshinsky transformation brackets <span class="citation" data-cites="Talmi1952 brody1967tables MOSHINSKY1959104">(Talmi 1952; Brody and Moshinsky 1967; Moshinsky 1959)</span> can be used to convert the result back into lab frame.</p>
<p>The second part is the actual nuclear interaction. There are many possible choices here, and they are often available precomputed in a variety of tabular formats.</p>
<p>A common format that used for nuclear matrix elements is the <strong>Darmstadt ME2J format</strong> <span class="citation" data-cites="tuprints3946 tuprints4069 tuprints3945">(Binder 2014; Calci 2014; Langhammer 2014)</span>. The chiral-EFT interactions, including <span class="citation" data-cites="PhysRevC.68.041001">(Entem and Machleidt 2003)</span>, are often distributed in this format. In this format, all matrix elements are stored in a predefined order without explicitly writing out the quantum numbers. The iteration order is parametrized by <span class="math inline">\((e_{\mathrm{max}}, n_{\mathrm{max}}, \ell_{\mathrm{max}}, E_{\mathrm{max}})\)</span> as defined in Eqns. <a href="nuclei.html#eq:emax">63</a>-<a href="nuclei.html#eq:eemax">65</a>. The first three parameters constrain the single-particle basis, which is constructed by the following algorithm: <span class="math display">\[\begin{gather*}
  \mathbf{for}\ e\ \mathbf{in}\ 0, \ldots, e_{\mathrm{max}} \\
  \quad \mathbf{for}\ \lambda\ \mathbf{in}\ 0, \ldots, \left\lfloor\frac{e}{2}\right\rfloor \\
  \quad \quad \mathbf{let}\ \ell = 2 \lambda + (e \bmod 2) \\
  \quad \quad \mathbf{let}\ n = \frac{e - \ell}{2} \\
  \quad \quad \mathbf{if}\ \ell &gt; \ell_{\mathrm{max}} \\
  \quad \quad \quad \mathbf{break} \\
  \quad \quad \mathbf{if}\ n &gt; n_{\mathrm{max}} \\
  \quad \quad \quad \mathbf{continue} \\
  \quad \quad \mathbf{for}\ \delta\ \mathbf{in}\ \left|\ell - \frac{1}{2}\right| - \frac{1}{2}, \ldots, \ell \\
  \quad \quad \quad \mathbf{let}\ j = \delta + \frac{1}{2} \\
  \quad \quad \quad \mathbf{yield}\ (e, n, \ell, j)
\end{gather*}\]</span> The algorithm establishes an <em>ordering</em> on the single-particle states, which we denote <span class="math display">\[(e_1, n_1, \ell_1, j_1), (e_2, n_2, \ell_2, j_2), \ldots, (e_{n_{\mathrm{b}}}, n_{n_{\mathrm{b}}}, \ell_{n_{\mathrm{b}}}, j_{n_{\mathrm{b}}})\]</span> where <span class="math inline">\(n_{\mathrm{b}}\)</span> is the number of single-particle states. Then, we must iterate over the two-body matrix elements in the following order, constrained by <span class="math inline">\(E_{\mathrm{max}}\)</span>: <span class="math display">\[\begin{gather*}
  \mathbf{for}\ p\ \mathbf{in}\ 1, \ldots, n_{\mathrm{b}} \\
  \quad \mathbf{for}\ q\ \mathbf{in}\ 1, \ldots, p \\
  \quad \quad \mathbf{if}\ e_p + e_q &gt; E_{\mathrm{max}} \\
  \quad \quad \quad \mathbf{break} \\
  \quad \quad \mathbf{for}\ r\ \mathbf{in}\ 1, \ldots, p \\
  \quad \quad \quad \mathbf{for}\ s\ \mathbf{in}\ 1, \ldots, (\mathbf{if}\ r &lt; p \ \mathbf{then}\ r\ \mathbf{else}\ q) \\
  \quad \quad \quad \quad \mathbf{if}\ e_r + e_s &gt; E_{\mathrm{max}} \\
  \quad \quad \quad \quad \quad \mathbf{break} \\
  \quad \quad \quad \quad \mathbf{if}\ (\ell_1 + \ell_2 + \ell_3 + \ell_4) \bmod 2 \ne 0 \\
  \quad \quad \quad \quad \quad \mathbf{continue} \\
  \quad \quad \quad \quad \mathbf{for}\ J\ \mathbf{in}\ \max\{|j_p - j_q|, |j_r - j_s|\}, \ldots, \min\{j_p + j_q, j_r + j_s\} \\
  \quad \quad \quad \quad \quad \mathbf{for}\ T\ \mathbf{in}\ 0, 1 \\
  \quad \quad \quad \quad \quad \quad \mathbf{for}\ M_T\ \mathbf{in}\ {-T}, \ldots, T \\
  \quad \quad \quad \quad \quad \quad \quad \mathbf{yield}\ (n_p, \ell_p, j_p, n_q, \ell_q, j_q, n_r, \ell_r, j_r, n_s, \ell_s, j_s, J, T, M_T)
\end{gather*}\]</span> Note that in ME2J, the particle physics convention is used for isospin, so <span class="math inline">\(m_t = -\frac{1}{2}\)</span> is for neutrons and <span class="math inline">\(m_t = +\frac{1}{2}\)</span> is for protons.</p>
<h2 id="implementation-of-hf"><span class="header-section-number">16.6</span> Implementation of HF</h2>
<p>The overall structure of our HF program is as follows:</p>
<ol type="1">
<li><p>Begin with the initial coefficient matrix <span class="math inline">\(\bm{C}^{(0)}\)</span> set to the identity matrix.</p></li>
<li><p>Now we loop over <span class="math inline">\(i\)</span> from 1 and terminate at some high cut-off (e.g. 1024):</p>
<ol type="a">
<li><p>Compute the Fock matrix <span class="math inline">\(\bm{F}^{(\mathrm{new})}\)</span> using <span class="math inline">\(\bm{C}^{(i - 1)}\)</span>.</p></li>
<li><p>Mix <span class="math inline">\(\bm{F}^{(i - 1)}\)</span> and <span class="math inline">\(\bm{F}^{(\mathrm{new})}\)</span> to obtain <span class="math inline">\(\bm{F}^{(i)}\)</span> using Eq. <a href="print.html#eq:hf-mixing">72</a>.</p></li>
<li><p>Solve the Hartree–Fock equation as a Hermitian eigenvalue problem on <span class="math inline">\(\bm{F}^{(i)}\)</span>. This results in a new set of coefficients <span class="math inline">\(\bm{C}^{(i)}\)</span> and a vector of eigenvalues (orbital energies) <span class="math inline">\(\bm{\varepsilon}^{(i)}\)</span>. We use <code>heevr</code> from LAPACK for this, applied separately to every block of the matrix.</p></li>
<li><p>Compute the sum of orbital energies <span class="math inline">\(S^{(i)} = \sum_p \jweight{j}_p^2 \varepsilon_p^{(i)}\)</span> as a diagnostic for convergence.</p></li>
<li><p>Adjust the linear mixing factor using Eq. <a href="print.html#eq:hf-mixing-adjustment">73</a>.</p></li>
<li><p>Test how much <span class="math inline">\(S^{(i)}\)</span> has changed compared to <span class="math inline">\(S^{(i - 1)}\)</span>. If this is within the desired tolerance, break the loop.</p></li>
</ol></li>
<li><p>Report whether the HF calculation has reached convergence (i.e. whether the loop was broken because the tolerance has met). Usually, the program will abort if this fails.</p></li>
<li><p>Transform the Hamiltonian using the final coefficient matrix.</p></li>
</ol>
<h3 id="calculation-of-the-fock-matrix"><span class="header-section-number">16.6.1</span> Calculation of the Fock matrix</h3>
<p>From <span class="math inline">\(\bm{C}\)</span>, we compute an auxiliary matrix <span class="math inline">\(\bm{Q}\)</span> defined as <span class="math display">\[Q_{r s} = \sum_{i \backslash} C_{r i&#39;}^* C_{s i&#39;}\]</span> This summation may be readily computed using GEMM.</p>
<p>Using <span class="math inline">\(\bm{Q}\)</span>, we can reduce the cost of computing the Fock matrix, which is now described by this equation in J-scheme: <span id="eq:fock-q"><span class="math display">\[F_{p q} = \bra{p} \hat{H}_1 \ket{q} + \sum_{j_{p r} r s} \frac{\jweight{j}_{p r}^2}{\jweight{j}_p^2} Q_{r s} \bra{p r} \hat{H}_2 \ket{q s}\qquad(71)\]</span></span> Compared with Eq. <a href="hartree-fock.html#eq:fock-j">43</a>, which has a triply-nested sum, this equation only has a doubly-nested sum.</p>
<p>As a demonstration of our J-scheme framework, we include the code used to calculate the two-body contribution to the Fock matrix below.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode rust"><code class="sourceCode rust"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="kw">pub</span> <span class="kw">fn</span> fock2(</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">    h2: &amp;OpJ200&lt;<span class="dt">f64</span>&gt;,</a>
<a class="sourceLine" id="cb8-3" data-line-number="3">    q1: &amp;OpJ100&lt;<span class="dt">f64</span>&gt;,</a>
<a class="sourceLine" id="cb8-4" data-line-number="4">    f1: &amp;<span class="kw">mut</span> OpJ100&lt;<span class="dt">f64</span>&gt;,</a>
<a class="sourceLine" id="cb8-5" data-line-number="5">)</a>
<a class="sourceLine" id="cb8-6" data-line-number="6"><span class="op">{</span></a>
<a class="sourceLine" id="cb8-7" data-line-number="7">    <span class="kw">let</span> scheme = h2.scheme();</a>
<a class="sourceLine" id="cb8-8" data-line-number="8">    <span class="kw">for</span> pr <span class="kw">in</span> scheme.states_20(&amp;occ::ALL2) <span class="op">{</span></a>
<a class="sourceLine" id="cb8-9" data-line-number="9">        <span class="kw">let</span> (p, r) = pr.split_to_10_10();</a>
<a class="sourceLine" id="cb8-10" data-line-number="10">        <span class="kw">for</span> q <span class="kw">in</span> p.costates_10(&amp;occ::ALL1) <span class="op">{</span></a>
<a class="sourceLine" id="cb8-11" data-line-number="11">            <span class="kw">for</span> s <span class="kw">in</span> r.costates_10(&amp;occ::ALL1) <span class="op">{</span></a>
<a class="sourceLine" id="cb8-12" data-line-number="12">                <span class="kw">for</span> qs <span class="kw">in</span> q.combine_with_10(s, pr.j()) <span class="op">{</span></a>
<a class="sourceLine" id="cb8-13" data-line-number="13">                    f1.add(p, q,</a>
<a class="sourceLine" id="cb8-14" data-line-number="14">                           pr.jweight(<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb8-15" data-line-number="15">                           / p.jweight(<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb8-16" data-line-number="16">                           * q1.at(r, s)</a>
<a class="sourceLine" id="cb8-17" data-line-number="17">                           * h2.at(pr, qs));</a>
<a class="sourceLine" id="cb8-18" data-line-number="18">                <span class="op">}</span></a>
<a class="sourceLine" id="cb8-19" data-line-number="19">            <span class="op">}</span></a>
<a class="sourceLine" id="cb8-20" data-line-number="20">        <span class="op">}</span></a>
<a class="sourceLine" id="cb8-21" data-line-number="21">    <span class="op">}</span></a>
<a class="sourceLine" id="cb8-22" data-line-number="22"><span class="op">}</span></a></code></pre></div>
<p>The inputs to this function are the three operator matrices <code>h2</code> (<span class="math inline">\(\bm{H}_2\)</span>, the two-body Hamiltonian), <code>q1</code> (<span class="math inline">\(\bm{Q}\)</span>), and <code>f1</code> (<span class="math inline">\(\bm{F}\)</span>). The output is <code>f1</code> (<span class="math inline">\(\bm{F}\)</span> is mutated in-place).</p>
<p>The function begins by binding a reference of the scheme of <code>h2</code> to the <code>scheme</code> variable. This is done out of convenience. One could just as well have chosen <code>q1.scheme()</code>, or <code>f1.scheme()</code>, since all three operators are expected to have the same scheme as a pre-condition.</p>
<p>The outermost loop over iterates over all standard-coupled two-particle states <span class="math inline">\(\ket{j_{p r}; p r}\)</span>. Keep in mind that although in storage we deduplicate states related by antisymmetry, the high-level interface here takes great pains to avoid exposing this internal detail.</p>
<p>The two-particle state <span class="math inline">\(\ket{j_{p r}; p r}\)</span> is then split into two single-particle states <span class="math inline">\(\ket{p}\)</span> and <span class="math inline">\(\ket{r}\)</span>. Note that this is a many-to-one process: multiple two-particle state can split into the same pair of single-particle states.</p>
<p>The next loop iterates over all <span class="math inline">\(\ket{q}\)</span> that are also <strong>co-states</strong> of <span class="math inline">\(\ket{p}\)</span>: these are all states that share the same channel as <span class="math inline">\(\ket{p}\)</span>. These states have the same <span class="math inline">\(l \simeq (j, \kappa)\)</span> and thus reside within the same one-body matrix block, allowing us to avoid wasting time on matrix elements that are trivially zero. Another loop iterates over all <span class="math inline">\(\ket{s}\)</span> that are co-states of <span class="math inline">\(\ket{r}\)</span>.</p>
<p>In the innermost loop, we combine <span class="math inline">\(\ket{q}\)</span>, <span class="math inline">\(\ket{s}\)</span>, and <span class="math inline">\(j_{p r}\)</span> to form the state <span class="math inline">\(\ket{j_{p r}; q s}\)</span>. This loop is somewhat unusual in that it iterates <em>at most once</em>. If for some reason the state <span class="math inline">\(\ket{j_{p r}; q s}\)</span> is forbidden, the innermost loop would do nothing. Otherwise, there can only be one state <span class="math inline">\(\ket{j_{p r}; q s}\)</span> that satisfies the requirements.</p>
<p>Lastly, we add the appropriate contributions to <code>f1</code> using the usual formula. The <code>add</code> function and <code>at</code> (getter) automatically handle the antisymmetrization phases behind the scenes. Note that the <code>p.jweight(n)</code> function computes <span class="math inline">\(\jweight{j}_p^n\)</span>.</p>
<p>This code is written in a rather naive way and utilizes the <em>high-level</em> interface of our J-scheme framework. It is certainly not the most efficient way of calculating the Fock matrix, but we consider its simplicity to be an advantage. Compared to other parts of the calculation, this sum is far from being the bottleneck, thus optimizing this code is not a high priority.</p>
<h3 id="ad-hoc-linear-mixing"><span class="header-section-number">16.6.2</span> <em>Ad hoc</em> linear mixing</h3>
<p>In some systems, the convergence of Hartree–Fock calculations can sometimes be very slow. This is usually the result of a highly oscillatory convergence. Several methods exist to mitigate this problem, including direct inversion of the iterative subspace (DIIS) <span class="citation" data-cites="PULAY1980393 JCC:JCC540030413">(Pulay 1980, 1982)</span> and Broyden’s method <span class="citation" data-cites="broyden1965class">(Broyden 1965)</span>.</p>
<p>In our code, we implement a very simple <em>ad hoc</em> linear mixing strategy that, in practice, can aid convergence in many cases. The general idea is that if the sum of energies <span class="math inline">\(S\)</span> is changing sign, then we attempt to dampen the oscillations by mixing in some portion of the old Fock matrix. If this converging is not oscillatory, then we try to keep most of the new Fock matrix.</p>
<p>The mixing is determined by a factor <span class="math inline">\(c^{(i)}\)</span> that is updated from iteration to iteration. The next Fock matrix to be used <span class="math inline">\(\bm{F}^{(i)}\)</span> is computed as: <span id="eq:hf-mixing"><span class="math display">\[\bm{F}^{(i)} = c^{(i)} \bm{F}^{(i - 1)} + (1 - c^{(i)}) \bm{F}^{(\mathrm{new})}\qquad(72)\]</span></span> where <span class="math inline">\(\bm{F}^{(\mathrm{new})}\)</span> is the Fock matrix as computed via Eq. <a href="print.html#eq:fock-q">71</a>.</p>
<p>At each step, we update the mixing factor <span class="math inline">\(c^{(i)}\)</span> via the logic: <span id="eq:hf-mixing-adjustment"><span class="math display">\[c^{(i)} = \begin{cases}
  \min\{\frac{1}{2}, b c^{(i - 1)}\} &amp; \text{if } (S^{(i)} - S^{(i - 1)}) (S^{(i - 1)} - S^{(i - 2)}) &lt; 0 \\
  \frac{c^{(i - 1)}}{b} &amp; \text{otherwise} \\
\end{cases}\qquad(73)\]</span></span> where <span class="math inline">\(b &gt; 1\)</span> is some arbitrary constant that controls how rapid <span class="math inline">\(c\)</span> should respond to the presence or absence of oscillations. We usually choose <span class="math inline">\(b = 2\)</span>. The <span class="math inline">\(\min\{\frac{1}{2}, \ldots\}\)</span> prevents the calculation from stalling because too much of the old matrix is being retained.</p>
<h3 id="hf-transformation-of-the-hamiltonian"><span class="header-section-number">16.6.3</span> HF transformation of the Hamiltonian</h3>
<p>The HF transformation is describe by Eq. <a href="hartree-fock.html#eq:hftransform">39</a>, which we reproduce here in J-scheme (not that there is any difference): <span class="math display">\[\begin{gather*}
  H&#39;_{p&#39; q&#39;} = \sum_{p q} C_{p p&#39;}^* H_{p q} C_{q q&#39;} \\
  H&#39;_{p&#39; q&#39; r&#39; s&#39;} = \sum_{p q r s} C_{p p&#39;}^* C_{q q&#39;}^* H_{p q r s} C_{r r&#39;} C_{s s&#39;}
\end{gather*}\]</span> The one-body term is very cheap and can be written in a naive way like the Fock matrix calculation.</p>
<p>The two-body term can be fairly expensive. Naive implementation of the equation would result in an 8-th power scaling, which is unbearably slow. Fortunately, the calculation can be broken down into two 6-th power steps at the cost of a temporary two-body matrix <span class="math inline">\(\bm{T}\)</span>, <span id="eq:hf-transform-2-fast"><span class="math display">\[\begin{gathered}
  T_{p&#39; q&#39; r s} = \sum_{p q} C_{p p&#39;}^* C_{q q&#39;}^* H_{p q r s} \\
  H&#39;_{p&#39; q&#39; r&#39; s&#39;} = \sum_{r s} T_{p&#39; q&#39; r s} C_{r r&#39;} C_{s s&#39;}
\end{gathered}\qquad(74)\]</span></span> This could be broken down even further into four 5-th power steps, but we generally find this an unnecessary complication – in particular, it would involve a temporary non-antisymmetrized two-body matrix, which would require introducing yet another matrix data type.</p>
<p>Eq. <a href="print.html#eq:hf-transform-2-fast">74</a> can be programmed naively, which results in a slow but tolerable transformation. Alternatively, one could perform the transformation using GEMM. Our benchmarks indicate that the use of GEMM can provide a two-orders-of-magnitude improvement in speed. Unfortunately, it causes the internal details of implicit antisymmetrization to leak, complicating the phase factor.</p>
<p>In any case, the technique is as follows. Define the following two-body antisymmetrized coefficient matrix <span class="math inline">\(\bm{G}\)</span>: <span class="math display">\[G_{r s r&#39; s&#39;} = N_{r s} \symm^{(1 + j_r + j_s - j_{r s})}_{r s} \symm^{(1 + j_{r&#39;} + j_{s&#39;} - j_{r s})}_{r&#39; s&#39;} C_{r r&#39;} C_{s s&#39;}\]</span> where <span class="math inline">\(N_{r s}\)</span> is the normalization factor in Eq. <a href="angular-momentum-coupling.html#eq:two-particle-j-normalization-factor">36</a> and <span class="math inline">\(\symm^{(i)}\)</span> is the <span class="math inline">\((-)^i\)</span>-symmetrization symbol of Sec. <a href="many-body-theory.html#sec:symmetrization">6.1.2</a>. Then we can compute the transformation using GEMM: <span class="math display">\[\begin{gathered}
  T_{p&#39; q&#39; r s} = \sum_{p \ge q} G_{p q p&#39; q&#39;}^* H_{p q r s} \\
  H&#39;_{p&#39; q&#39; r&#39; s&#39;} = \sum_{r \ge s} T_{p&#39; q&#39; r s} G_{r s r&#39; s&#39;}
\end{gathered}\]</span></p>
<h2 id="implementation-of-normal-ordering"><span class="header-section-number">16.7</span> Implementation of normal ordering</h2>
<p>Before performing IM-SRG(2), it is necessary to obtain matrix elements of <span class="math inline">\(\hat{H}\)</span> relative to the Fermi vacuum. This step is often referred to as the <em>normal ordering</em> of <span class="math inline">\(\hat{H}\)</span> (the terminology is somewhat overloaded). As part of this step, we also obtain the Hartree–Fock energy.</p>
<p>In the case of two-body operators, there are only two interesting operations here. One is the calculation of the zero-body component (HF energy) using Eq. <a href="hartree-fock.html#eq:hfenergy">38</a> or Eq. <a href="many-body-theory.html#eq:normord-ph">4</a>, which we reproduce here in J-scheme: <span class="math display">\[E_\Phi = E_\varnothing + \sum_{i \backslash} \jweight{j}_{i}^2 H^\varnothing_{i i} + \frac{1}{2} \sum_{j_{i j}} \sum_{i j \backslash} \jweight{j}_{i j}^2 H^\varnothing_{i j i j}\]</span> We have omitted the primes because at this point normal ordering itself can be applied independent of HF. This calculation can be done naively as it is very cheap.</p>
<p>The other part is the folding of the two-body component into the one-body component as shown in Eq. <a href="many-body-theory.html#eq:normord-ph">4</a> and reproduced here in J-scheme: <span class="math display">\[H^\Phi_{p q} = H^\varnothing_{p q} + \sum_{j_{p i}} \sum_{i \backslash} \frac{\jweight{j}_{p i}^2}{\jweight{j}_p^2} H^\varnothing_{p i q i}\]</span> This calculation can also be done naively as it is still very cheap.</p>
<h2 id="im-srg2-implementation"><span class="header-section-number">16.8</span> IM-SRG(2) implementation</h2>
<p>The overall structure of the IM-SRG implementation is centered around an ODE loop with tests for convergence, much like HF. The inputs to IM-SRG are the normal-ordered, zero-, one-, and two-body operator matrices in their standard-coupled forms.</p>
<ol type="1">
<li><p>Pack all three standard-coupled Hamiltonian components into a single array <span class="math inline">\(\bm{y}\)</span> for the ODE solver to consume. In doing so, deduplicate elements that are related by hermitivity.</p></li>
<li><p>Initialize and maintain a cache of 6-j symbols, needed for the Pandya transformations.</p></li>
<li><p>Initialize the Shampine–Gordon ODE solver.</p></li>
<li><p>Now enter the main IM-SRG loop, starting with the flow parameter <span class="math inline">\(s\)</span> set to zero. If the loop exceeds some predefined limit on <span class="math inline">\(s\)</span>, abort.</p>
<ol type="a">
<li><p>Request the solver to proceed to <span class="math inline">\(s + \Delta s\)</span>, for some <span class="math inline">\(\Delta s\)</span> specified by the user. Provide the derivative function <span class="math inline">\(\dot{\bm{y}} = \bm{f}(s, \bm{y})\)</span> to the solver. While the solver is stepping, it will attempt to evaluate our function <span class="math inline">\(\bm{f}\)</span>:</p>
<ul>
<li>Unpack <span class="math inline">\(\bm{y}\)</span> back into the standard-coupled operator matrices <span class="math inline">\(\bm{H}\)</span>.</li>
<li>Compute the generator <span class="math inline">\(\bm{\eta}\)</span> from <span class="math inline">\(\bm{H}\)</span>.</li>
<li>Compute the comutator <span class="math inline">\(\bm{D} = [\bm{\eta}, \bm{H}]\)</span>, making use of the 6-j cache.</li>
<li>Pack the comutator <span class="math inline">\(\bm{D}\)</span> into the derivative array <span class="math inline">\(\dot{\bm{y}}\)</span>.</li>
</ul></li>
<li><p>If the stepping failed, abort.</p></li>
<li><p>Get the ground state energy <span class="math inline">\(E_\Phi\)</span>, which in our packing convention is simply the first element of <span class="math inline">\(\bm{y}\)</span>.</p></li>
<li><p>Check how much the ground state energy has changed since the previous iteration. If it is less the user-specified tolerance, break the loop with success.</p></li>
</ol></li>
</ol>
<p>We use the White generator for our IM-SRG calculations, as described in Eq. <a href="imsrg.html#eq:white-generator">51</a>. Our implementation supports both Møller–Plesset and Epstein–Nesbet denominators, using monopole matrix elements in the latter case.</p>
<h3 id="calculation-of-the-im-srg2-commutator"><span class="header-section-number">16.8.1</span> Calculation of the IM-SRG(2) commutator</h3>
<p>The bulk of the implementation complexity and computational cost lies in the calculation of the commutator <span class="math inline">\(\bm{D} = [\bm{\eta}, \bm{H}]\)</span>. At the moment, we implement this as by calculating the linked products of <span class="math inline">\(\hat{\eta} \hat{H}\)</span> and subtracting the linked products of <span class="math inline">\(\hat{H} \hat{\eta}\)</span>. This allows us to reuse the linked product code. However, in the future, we may disrupt this symmetry for optimization reasons – to take advantage of <span class="math inline">\(\hat{\eta}\)</span>’s higher sparsity as compared to <span class="math inline">\(\hat{H}\)</span>.</p>
<p>Since the linked product corresponds to the <span class="math inline">\(\hat{C}\)</span> operator in Secs. <a href="imsrg.html#sec:imsrg-eqs">11.4</a>, <a href="imsrg.html#sec:imsrg-j-eqs">11.5</a>, we will discuss the various terms using the naming convention in that chapter. We will not attempt to discuss all of the terms but instead focus on a few interesting ones.</p>
<h4 id="optimization-of-terms-2220-and-2222"><span class="header-section-number">16.8.1.1</span> Optimization of terms 2220 and 2222</h4>
<p>These are one of the most costly terms in the commutator, but also one the easiest to optimize: <span class="math display">\[\begin{gather*}
  C^{2220}_{p q r s} = \frac{1}{2} \sum_{i j \backslash} A_{i j r s} B_{p q i j} \\
  C^{2222}_{p q r s} = \frac{1}{2} \sum_{\backslash a b} A_{p q a b} B_{a b r s}
\end{gather*}\]</span> Calculating these terms using GEMM is quite straightforward and offers orders of magnitude in improvement.</p>
<p>However, a subtlety arises due to the implicit antisymmetrization, which we also encountered earlier in the HF transformation optimization: we must not double-count the <span class="math inline">\(i = j\)</span> (or <span class="math inline">\(a = b\)</span>) states. With this taken into account, the equations become <span class="math display">\[\begin{gather*}
  C^{2220}_{p q r s} = \frac{1}{2} \sum_{i \ge j \backslash} N_{i j} A_{i j r s} B_{p q i j} \\
  C^{2222}_{p q r s} = \frac{1}{2} \sum_{\backslash a \ge b} N_{a b} A_{p q a b} B_{a b r s}
\end{gather*}\]</span> where <span class="math inline">\(N_{a b}\)</span> denotes the normalization factor in Eq. <a href="angular-momentum-coupling.html#eq:two-particle-j-normalization-factor">36</a>. This is an unfortunate consequence of using unnormalized matrix elements; had we used normalized ones, the spurious <span class="math inline">\(N_{a b}\)</span> factor would not appear.</p>
<p>Note that the above two equations are extremely similar and can be implemented as just one function. The difference between the two is the that <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> have been swapped, and that the parts of states being summed over are different.</p>
<h4 id="optimization-of-terms-2221"><span class="header-section-number">16.8.1.2</span> Optimization of terms 2221</h4>
<p>The 2221 term is one of the most interesting and costly terms. It is actually described by a three-step process. First, use the Pandya transformation to convert the standard-coupled operators into Pandya coupling (Sec. <a href="angular-momentum-coupling.html#sec:pandya">8.12.2</a>): <span class="math display">\[\tilde{A}_{p s r q} =
  -\sum_{j_{p q}}
  (-)^{2 j_{p q}}
  \jweight{j}_{p q}^2
  \begin{Bmatrix}
    j_p &amp; j_q &amp; j_{p q} \\
    j_r &amp; j_s &amp; j_{p s} \\
  \end{Bmatrix}
  A_{p q r s}
\]</span> Then, use GEMM to compute the product using Pandya-coupled matrices: <span class="math display">\[\tilde{C}^{2221}_{p s r q} = +4 \sum_{i \backslash a} \tilde{A}_{i a r q} \tilde{B}_{p s i a}\]</span> Finally, convert back into standard coupling using the antisymmetrizing inverse Pandya transformation.</p>
<p>The GEMM part is probably the most straightforward. Unlike 2220 or 2221, there are no unusual phase factors because we do not use implicit antisymmetrization here.</p>
<p>Our benchmarks show that a very significant amount of time is spent on the Pandya transformation, thus it is worthwhile to optimize that operation despite being a roughly 5-th power operation.</p>
<p>One technique is to rewrite the Pandya transformation itself as a GEMM-compatible product: <span class="math display">\[\tilde{A}^{j_p j_q j_r j_s}_{j_{p s}; \alpha_p \alpha_q \alpha_r \alpha_s} =
  -\sum_{j_{p q}}
  W^{j_p j_q j_r j_s}_{j_{p s}; j_{p q}}
  A^{j_p j_q j_r j_s}_{j_{p q}; \alpha_p \alpha_q \alpha_r \alpha_s}
\]</span> where <span class="math display">\[W^{j_p j_q j_r j_s}_{j_{p s}; j_{p q}} =
  (-)^{2 j_{p q}}
  \jweight{j}_{p q}^2
  \begin{Bmatrix}
    j_p &amp; j_q &amp; j_{p q} \\
    j_r &amp; j_s &amp; j_{p s} \\
  \end{Bmatrix}\]</span> In this “four-j” matrix layout, each diagonal block of <span class="math inline">\(A\)</span> or <span class="math inline">\(\tilde{A}\)</span> is indexed not by the usual channels, but by <span class="math inline">\((j_p, j_q, j_r, j_s)\)</span>. The right axis of both matrices is labeled by <span class="math inline">\((\alpha_p, \alpha_q, \alpha_r, \alpha_s)\)</span>, where <span class="math inline">\(\alpha_p\)</span> denotes all the non-<span class="math inline">\(j\)</span> quantum numbers of <span class="math inline">\(p\)</span>. The use of this layout, in conjunction with a GEMM-powered Pandya transformation, saves about 40% time.<a href="print.html#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a> The gains are not as dramatic as in the case of 2220 or 2222 because the matrix-matrix multiplication is only over <span class="math inline">\(j_{p s}\)</span> whose dimensions are usually not very big.</p>
<p>The dominant work is now pushed onto the conversion from the standard- or Pandya-coupled matrices into this four-j layout. This can be expensive due to the large number of hash table lookups for translation between two-particle states and pairs of single-particle states. To mitigate this we cache the translated indices within a separate four-j-layout matrix, bypassing the need for expensive hash table lookups. This saves another 50% time at the cost of extra memory usage.<a href="print.html#fn32" class="footnote-ref" id="fnref32"><sup>32</sup></a></p>
<h2 id="qdpt3-implementation"><span class="header-section-number">16.9</span> QDPT3 implementation</h2>
<p>The QDPT3 implementation is fairly tedious as it involves coding about 20 or so terms from Sec. <a href="qdpt.html#sec:qdpt-eqs">12.1</a>. It is also quite error-prone, much like the IM-SRG commutator, therefore extensive testing is necessary.</p>
<p>Fortunately, all terms up to third order are fairly inexpensive, therefore writing them out naively using the high-level J-scheme interface would suffice as the cost of IM-SRG dwarfs the cost of QDPT.</p>
<p>Additionally, a large number of QDPT terms share similar topologies: there is one unique topology at second order (type A), and only three unique topologies at third order (types B, C, and D). Thus, they can reuse with the same code simply by tweaking a the state parts that are being summed over and customizing the denominator. As an example, consider the type B QDPT term: <span class="math display">\[W^{(\mathrm{B})}_{p q}(\chi_r, \chi_{s t}, \chi_{u v}, D)
= \frac{1}{4} \sum_{r \in \chi_r} \sum_{s t \in \chi_{s t}} \sum_{u v \in \chi_{u v}} \frac{\jweight{j}_{r p}^2}{\jweight{j}_p^2} \frac{H_{r p s t} H_{s t u v} H_{u v r q}}{D(r, s, t, u, v)}
\]</span> All of the first six terms/diagrams at third-order, shown in the equations of Sec. <a href="qdpt.html#sec:qdpt-eqs">12.1</a>, have this type B topology. The arguments <span class="math inline">\(\chi_r\)</span>, <span class="math inline">\(\chi_{s t}\)</span>, and <span class="math inline">\(\chi_{u v}\)</span> indicate which parts of the states should be summed (i.e. hole or particle) for <span class="math inline">\(\ket{r}\)</span>, <span class="math inline">\(\ket{s t}\)</span>, and <span class="math inline">\(\ket{u v}\)</span> respectively.</p>
<p>The code to compute type B terms is shown below:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode rust"><code class="sourceCode rust"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="kw">pub</span> <span class="kw">fn</span> qdpt_term_b&lt;F&gt;(</a>
<a class="sourceLine" id="cb9-2" data-line-number="2">    h1: &amp;OpJ100&lt;<span class="dt">f64</span>&gt;,</a>
<a class="sourceLine" id="cb9-3" data-line-number="3">    h2: &amp;OpJ200&lt;<span class="dt">f64</span>&gt;,</a>
<a class="sourceLine" id="cb9-4" data-line-number="4">    p: StateJ10,</a>
<a class="sourceLine" id="cb9-5" data-line-number="5">    q: StateJ10,</a>
<a class="sourceLine" id="cb9-6" data-line-number="6"></a>
<a class="sourceLine" id="cb9-7" data-line-number="7">    <span class="co">// these are denoted &quot;chi&quot; in the equations</span></a>
<a class="sourceLine" id="cb9-8" data-line-number="8">    r_occ: Occ,</a>
<a class="sourceLine" id="cb9-9" data-line-number="9">    st_occ: <span class="op">[</span>Occ; <span class="dv">2</span><span class="op">]</span>,</a>
<a class="sourceLine" id="cb9-10" data-line-number="10">    uv_occ: <span class="op">[</span>Occ; <span class="dv">2</span><span class="op">]</span>,</a>
<a class="sourceLine" id="cb9-11" data-line-number="11"></a>
<a class="sourceLine" id="cb9-12" data-line-number="12">    <span class="co">// the denominator (closure / function object)</span></a>
<a class="sourceLine" id="cb9-13" data-line-number="13">    denom: F,</a>
<a class="sourceLine" id="cb9-14" data-line-number="14"></a>
<a class="sourceLine" id="cb9-15" data-line-number="15">) -&gt; <span class="dt">f64</span> <span class="kw">where</span></a>
<a class="sourceLine" id="cb9-16" data-line-number="16">    F: <span class="bu">Fn</span>(StateJ10, StateJ10, StateJ10,</a>
<a class="sourceLine" id="cb9-17" data-line-number="17">          StateJ10, StateJ10) -&gt; <span class="dt">f64</span>,</a>
<a class="sourceLine" id="cb9-18" data-line-number="18"><span class="op">{</span></a>
<a class="sourceLine" id="cb9-19" data-line-number="19">    <span class="co">// make sure p and q are within the same block</span></a>
<a class="sourceLine" id="cb9-20" data-line-number="20">    <span class="co">// (i.e. have the same conserved quantum numbers)</span></a>
<a class="sourceLine" id="cb9-21" data-line-number="21">    <span class="pp">assert_eq!</span>(p.lu().l, q.lu().l);</a>
<a class="sourceLine" id="cb9-22" data-line-number="22"></a>
<a class="sourceLine" id="cb9-23" data-line-number="23">    <span class="kw">let</span> scheme = h1.scheme();</a>
<a class="sourceLine" id="cb9-24" data-line-number="24">    <span class="kw">let</span> <span class="kw">mut</span> result = <span class="dv">0.0</span>;</a>
<a class="sourceLine" id="cb9-25" data-line-number="25">    <span class="kw">for</span> r <span class="kw">in</span> scheme.states_10(&amp;<span class="op">[</span>r_occ<span class="op">]</span>) <span class="op">{</span></a>
<a class="sourceLine" id="cb9-26" data-line-number="26">        <span class="kw">for</span> jrp <span class="kw">in</span> Half::tri_range(r.j(), p.j()) <span class="op">{</span></a>
<a class="sourceLine" id="cb9-27" data-line-number="27">            <span class="co">// combining states can fail,</span></a>
<a class="sourceLine" id="cb9-28" data-line-number="28">            <span class="co">// in which case we just continue</span></a>
<a class="sourceLine" id="cb9-29" data-line-number="29">            <span class="kw">let</span> rp = <span class="kw">match</span> r.combine_with_10(p, jrp) <span class="op">{</span></a>
<a class="sourceLine" id="cb9-30" data-line-number="30">                <span class="cn">None</span> =&gt; <span class="kw">continue</span>,</a>
<a class="sourceLine" id="cb9-31" data-line-number="31">                <span class="cn">Some</span>(x) =&gt; x,</a>
<a class="sourceLine" id="cb9-32" data-line-number="32">            <span class="op">}</span>;</a>
<a class="sourceLine" id="cb9-33" data-line-number="33">            <span class="kw">let</span> rq = <span class="kw">match</span> r.combine_with_10(q, jrp) <span class="op">{</span></a>
<a class="sourceLine" id="cb9-34" data-line-number="34">                <span class="cn">None</span> =&gt; <span class="kw">continue</span>,</a>
<a class="sourceLine" id="cb9-35" data-line-number="35">                <span class="cn">Some</span>(x) =&gt; x,</a>
<a class="sourceLine" id="cb9-36" data-line-number="36">            <span class="op">}</span>;</a>
<a class="sourceLine" id="cb9-37" data-line-number="37">            <span class="kw">for</span> st <span class="kw">in</span> rp.costates_20(&amp;<span class="op">[</span>st_occ<span class="op">]</span>) <span class="op">{</span></a>
<a class="sourceLine" id="cb9-38" data-line-number="38">                <span class="kw">let</span> (s, t) = st.split_to_10_10();</a>
<a class="sourceLine" id="cb9-39" data-line-number="39">                <span class="kw">for</span> uv <span class="kw">in</span> rp.costates_20(&amp;<span class="op">[</span>uv_occ<span class="op">]</span>) <span class="op">{</span></a>
<a class="sourceLine" id="cb9-40" data-line-number="40">                    <span class="kw">let</span> (u, v) = uv.split_to_10_10();</a>
<a class="sourceLine" id="cb9-41" data-line-number="41">                    result += <span class="dv">1.0</span> / <span class="dv">4.0</span></a>
<a class="sourceLine" id="cb9-42" data-line-number="42">                        * rp.jweight(<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb9-43" data-line-number="43">                        / p.jweight(<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb9-44" data-line-number="44">                        * h2.at(rp, st)</a>
<a class="sourceLine" id="cb9-45" data-line-number="45">                        * h2.at(st, uv)</a>
<a class="sourceLine" id="cb9-46" data-line-number="46">                        * h2.at(uv, rq)</a>
<a class="sourceLine" id="cb9-47" data-line-number="47">                        / denom(r, s, t, u, v);</a>
<a class="sourceLine" id="cb9-48" data-line-number="48">                <span class="op">}</span></a>
<a class="sourceLine" id="cb9-49" data-line-number="49">            <span class="op">}</span></a>
<a class="sourceLine" id="cb9-50" data-line-number="50">        <span class="op">}</span></a>
<a class="sourceLine" id="cb9-51" data-line-number="51">    <span class="op">}</span></a>
<a class="sourceLine" id="cb9-52" data-line-number="52">    <span class="co">// in Rust syntax, the last expression of a function is</span></a>
<a class="sourceLine" id="cb9-53" data-line-number="53">    <span class="co">// implicitly returned if not terminated by semicolon</span></a>
<a class="sourceLine" id="cb9-54" data-line-number="54">    result</a>
<a class="sourceLine" id="cb9-55" data-line-number="55"><span class="op">}</span></a></code></pre></div>
<p>Observe that we allow the denominator argument <code>denom</code> to be a closure of any type <code>F</code>, allowing it to be easily inlined by the compiler for efficiency. This permits the use of anonymously-typed closures, each with a distinct type, making it trivial for the compiler to tell different closures apart. As long as the type of the closure is not erased, the compiler is guaranteed to create distinct copies of the <code>qdpt_term_b</code> function for each closure type <code>F</code>, greatly improving optimizability. This is an inherent feature of monomorphization in both Rust and C++.</p>
<p>Here is a snippet of code that demonstrates the use of <code>qdpt_term_b</code> to compute the first third-order term shown in the equations of Sec. <a href="qdpt.html#sec:qdpt-eqs">12.1</a>:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode rust"><code class="sourceCode rust"><a class="sourceLine" id="cb10-1" data-line-number="1">qdpt_term_b(</a>
<a class="sourceLine" id="cb10-2" data-line-number="2">    h1, h2, p, q,</a>
<a class="sourceLine" id="cb10-3" data-line-number="3">    <span class="co">// notation: I = hole state, A = particle state</span></a>
<a class="sourceLine" id="cb10-4" data-line-number="4">    occ::I, occ::AA, occ::AA,</a>
<a class="sourceLine" id="cb10-5" data-line-number="5">    <span class="co">// we define the denominator using a lambda function;</span></a>
<a class="sourceLine" id="cb10-6" data-line-number="6">    |i, a, b, c, d| <span class="op">{</span></a>
<a class="sourceLine" id="cb10-7" data-line-number="7">        <span class="co">// the &quot;hd&quot; function extracts the diagonal part</span></a>
<a class="sourceLine" id="cb10-8" data-line-number="8">        <span class="co">// of the one-body Hamiltonian</span></a>
<a class="sourceLine" id="cb10-9" data-line-number="9">        (hd(i) + hd(q) - hd(a) - hd(b))</a>
<a class="sourceLine" id="cb10-10" data-line-number="10">            * (hd(i) + hd(q) - hd(c) - hd(d))</a>
<a class="sourceLine" id="cb10-11" data-line-number="11">    <span class="op">}</span>,</a>
<a class="sourceLine" id="cb10-12" data-line-number="12">)</a></code></pre></div>
<h2 id="sec:testing"><span class="header-section-number">16.10</span> Testing and benchmarking</h2>
<p>The first line of defense for ensuring correct code is through properly designed abstractions and data types. By categorizing values into distinct types one can avoid accidental confusion of quantities.</p>
<p>For example, we have introduced a special data type called <code>Half</code> to represent half-integers. Since no native machine type exists for half-integers, the usual workaround is to represent half-integers with twice its effective value. For example, the half-integer <span class="math inline">\(m = 3/2\)</span> would be represented as <code>m = 3</code> on a computer.</p>
<p>This leaves room for human error, if one say, adds a half-integer <span class="math inline">\(m = 3/2\)</span> to a normal integer <span class="math inline">\(n = 1\)</span>. The result would be <code>3 + 1 = 4</code>, which is incorrect. The <code>Half</code> data type, defined below, prevents this problem,</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode rust"><code class="sourceCode rust"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="kw">pub</span> <span class="kw">struct</span> Half(<span class="kw">pub</span> <span class="dt">i32</span>);</a></code></pre></div>
<p>It is not possible to add <code>Half</code> to an <code>i32</code>, because no such operator is defined. Thus the human error becomes a compile error, preventing the incorrect program from compiling.</p>
<p>As another example, we have distinct types for standard-coupled and Pandya-coupled two-body matrices, which prevents us from accidentally using a Pandya-coupled state to look up a standard-coupled matrix.</p>
<p>Types cannot catch all bugs, but with judicious use they certainly catch a lot of the obvious ones. We use tests to catch bugs that cannot be detected at compile time, either because the solution would be too complex, too awkward to use, or downright impossible. Not only do tests ensure that the code is correct <em>right now</em>, they also guard against future mistakes as the code evolves. Several kinds of testing strategies are used in Lutario.</p>
<p>The most basic ones are <strong>unit tests</strong>, which are short tests intended to verify basic functionality. These are often suitable for small functions that require little to no setup. For example, we have the following test for our implementation of Euclidean division and modulo:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode rust"><code class="sourceCode rust"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="at">#[</span>test<span class="at">]</span></a>
<a class="sourceLine" id="cb12-2" data-line-number="2"><span class="kw">fn</span> test_euclid_div_mod() <span class="op">{</span></a>
<a class="sourceLine" id="cb12-3" data-line-number="3">    <span class="pp">assert_eq!</span>(euclid_div(<span class="dv">10</span>, <span class="dv">5</span>), <span class="dv">10</span> / <span class="dv">5</span>);</a>
<a class="sourceLine" id="cb12-4" data-line-number="4">    <span class="pp">assert_eq!</span>(euclid_mod(<span class="dv">10</span>, <span class="dv">5</span>), <span class="dv">10</span> % <span class="dv">5</span>);</a>
<a class="sourceLine" id="cb12-5" data-line-number="5">    <span class="pp">assert_eq!</span>(euclid_div(-<span class="dv">10</span>, <span class="dv">5</span>), -<span class="dv">10</span> / <span class="dv">5</span>);</a>
<a class="sourceLine" id="cb12-6" data-line-number="6">    <span class="pp">assert_eq!</span>(euclid_mod(-<span class="dv">10</span>, <span class="dv">5</span>), -<span class="dv">10</span> % <span class="dv">5</span>);</a>
<a class="sourceLine" id="cb12-7" data-line-number="7">    <span class="pp">assert_eq!</span>(euclid_div(<span class="dv">10</span>, -<span class="dv">5</span>), <span class="dv">10</span> / -<span class="dv">5</span>);</a>
<a class="sourceLine" id="cb12-8" data-line-number="8">    <span class="pp">assert_eq!</span>(euclid_mod(<span class="dv">10</span>, -<span class="dv">5</span>), <span class="dv">10</span> % -<span class="dv">5</span>);</a>
<a class="sourceLine" id="cb12-9" data-line-number="9">    <span class="co">/* etc ... */</span></a>
<a class="sourceLine" id="cb12-10" data-line-number="10"><span class="op">}</span></a></code></pre></div>
<p>The function attribute <code>#[test]</code> informs the Rust compiler that this function is part of the test suite. The test explores all the potential sign errors that could happen in an implementation of Euclidean division and modulo.</p>
<p>It is generally impossible to check programs over all possible inputs as the input space is usually far too large. One way to ensure that the <em>interesting</em> cases are tested is through <strong>code coverage</strong> tools. These tools can track which lines of the source code are executed during the tests. If there are certain lines that are never executed because an if-condition is never true during the tests, then those lines effectively untested. Full code coverage is not a guarantee that the test is exhaustive, however.</p>
<p>When the input space is too large to explore, one could also consider <strong>randomized testing</strong>, in which inputs <span class="math inline">\(y\)</span> are generated randomly and then the test is responsible for verifying the results <span class="math inline">\(y = f(x)\)</span> in some way. One could either (1) compare the results using another function <span class="math inline">\(f&#39;\)</span> that reproduces the result, or (2) check whether certain properties <span class="math inline">\(P(x, y)\)</span> hold (<strong>property testing</strong>). We offer a more concrete example in Sec. <a href="print.html#sec:testing-numerical">16.10.1</a>.</p>
<p>While it is generally difficult to prove that testing has exhaustively covered all cases, it is nevertheless better to have at lesat one test case than none. These are often called <em>smoke tests</em> and they are still remarkably useful in practice.</p>
<p>Larger tests, where multiple components of the program are tested together, are known as <strong>integration tests</strong>. These are used to test the many-body methods, as they are fairly complicated and require several components working together to achieve a result. We have numerical results for, e.g. ground state energy, from other implementations of the same many-body methods that we can test against.</p>
<p>From time to time, bugs will inevitably slip past the existing tests. Whenever such a bug is discovered, it is important to add additional tests to ensure the bug will not go undetected again in the future – these are known as <strong>regression tests</strong>.</p>
<p>Tests are only useful if they are being run. Unfortunately, tests may require a substantial amount of time to run, which discourages the programmer from running such tests. Frequent runs of tests are important: they ensure that code remains valid at all times, and they allow problems to be discovered at the earliest opportunity.</p>
<p>In Lutario, we have configured a <strong>continuous integration</strong> (CI) system that automatically runs tests on every commit pushed to the repository and notifies failures by email. It ensures that problems are always discovered quickly. Furthermore, it allows us to keep the build process streamlined and reproducible as otherwise the automated testing script, which runs in a clean environment, would fail. It helps prevent environmental problems where the code functions correctly only on the developer’s machines, but not on the users’.</p>
<h3 id="sec:testing-numerical"><span class="header-section-number">16.10.1</span> Randomized testing of numerical code</h3>
<p>The sheer number and tedious nature of the IM-SRG commutator terms and QDPT terms offers a ripe environment for human errors. To mitigate against this, we use tests to verify that the commutators are performing the calculations we expect.</p>
<p>There is a chicken-or-egg problem regarding numerical computations: we generally do not know the answers <em>a priori</em> without running a program to calculate it – manual calculations are usually impractical – yet we do not know if the program is calculating the formula we intended. To break this loop, we have to trust at least one program to compute the result – to “bootstrap” our test suite.</p>
<p>We assign the most trust to the simplest and most naively implementation of the program. Even if it is very slow, it is often sufficient to test just a few small nontrivial cases. This would serve as our <em>reference</em> program.</p>
<p>With a reference program in hand, we need some input (matrix elements) to test against. We could use actual matrix elements from physical systems, but it suffices to use a randomly generated set of matrix elements, provided that these matrices satisfy the necessary symmetries and conservation laws for the formula to remain valid. This has the added advantage that as long as the random number generator is deterministic, we only need to store the seed to recover the entire suite of test matrices.</p>
<p>In the predecessor to Lutario, we have generated a set of random test matrices in the quantum dot basis for testing the commutator. They were verified by comparing against an extremely naive implementation that does not take advantage of the sparsity of the matrix. These input matrices, along with the expected output, have now been inherited by Lutario’s test suite. They ensure that the new J-scheme implementation remains correct for <span class="math inline">\(j = 0\)</span> (i.e. pseudo-M-scheme).</p>
<p>To test cases where <span class="math inline">\(j \ne 0\)</span> (proper J-scheme), we construct random matrix elements in the nuclei basis in J-scheme and compute the commutator in two different ways:</p>
<ul>
<li>We perform the commutator in J-scheme (operation <span class="math inline">\(C_{\mathrm{J}}\)</span>), and then convert the resulting matrices to pseudo-M-scheme (operation <span class="math inline">\(\varphi\)</span>).</li>
<li>We convert the matrices to pseudo-M-scheme (operation <span class="math inline">\(\varphi\)</span>), and then perform the commutator in pseudo-M-scheme (operation <span class="math inline">\(C_{\mathrm{M}}\)</span>).</li>
</ul>
<p>We expect the results to be identical in both cases. This is mathematically described by the commutative square: <span class="math display">\[\varphi \circ C_{\mathrm{J}} = C_{\mathrm{M}} \circ \varphi\]</span></p>
<p>This is a general approach of testing J-scheme equations that does not require us to know what the correct answers are, as long as the pseudo-M-scheme code is correct.</p>
<h3 id="linting-static-analysis-and-dynamic-sanitization"><span class="header-section-number">16.10.2</span> Linting, static analysis, and dynamic sanitization</h3>
<p>Several kinds of automated tools exist to aid the detection of bugs.</p>
<p><strong>Static analyzers</strong> read the source code of a program and attempt to look for bugs without actually running it. Due to the halting problem, it is impossible for a static analyzer to avoid false negatives in any Turing-complete language.</p>
<p>Linting tools are a subtype of static analyzers designed to find not only bugs, but also suspicious constructs, non-idiomatic code, and, in some cases, code that does not conform to a particular stylistic convention.</p>
<p>Modern compilers are also capable of giving useful warnings for potentially buggy code. C and C++ compilers by default are very conservative about warnings, but it is possible to request more comprehensive diagnostics using a flag similar to <code>-Wall</code>. This alone can catch many common mistakes.</p>
<p>In contrast, the Rust compiler by default issues all warnings. Our code is always written to avoid such warnings, even if the warning is of low priority or not justified. This ensures that if an important warning appears later on, it is not drown out by the deluge of low-priority warnings that had been intentionally ignored. If a warning is a false positive, we can either find a workaround or, failing that, silence the warning at that particular location using an attribute such as <code>#[allow(...)]</code> in Rust.</p>
<p><strong>Dynamic sanitizers</strong> are designed to detect errors during the execution of a program. Dynamic sanitizers are naturally better at detecting problems, but aside from the need to actually execute the program, they also introduce some performance overhead. Examples of such tools include Valgrind <span class="citation" data-cites="Valgrind">(Valgrind Developers 2017)</span>, as well as various Clang and GCC sanitizer flags (<code>-fsanitize=...</code>) .</p>
<p>Sanitizers can be extremely helpful at finding the cause of bugs when there is suspicion of memory errors in a given program. In our experience, Valgrind has been particularly effective at detecting memory errors in our C and C++ projects. The tools can even be used pre-emptively, run routinely as part of the test suite, to reduce the risk of memory errors being introduced as the codebase evolves.</p>
<h3 id="benchmarks-and-profiling"><span class="header-section-number">16.10.3</span> Benchmarks and profiling</h3>
<p>For benchmarking, we make use of Rust’s official (but unstable) <code>test</code> library, which offers a very simple interface:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode rust"><code class="sourceCode rust"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="at">#![</span>feature<span class="at">(</span>test<span class="at">)]</span></a>
<a class="sourceLine" id="cb13-2" data-line-number="2"><span class="kw">extern</span> <span class="kw">crate</span> test; <span class="co">// import the test library</span></a>
<a class="sourceLine" id="cb13-3" data-line-number="3"></a>
<a class="sourceLine" id="cb13-4" data-line-number="4"><span class="at">#[</span>bench<span class="at">]</span></a>
<a class="sourceLine" id="cb13-5" data-line-number="5"><span class="kw">fn</span> my_bench(b: &amp;<span class="kw">mut</span> Bencher) <span class="op">{</span></a>
<a class="sourceLine" id="cb13-6" data-line-number="6">    b.iter(|| <span class="op">{</span></a>
<a class="sourceLine" id="cb13-7" data-line-number="7">        <span class="co">// code goes here</span></a>
<a class="sourceLine" id="cb13-8" data-line-number="8">    <span class="op">}</span>);</a>
<a class="sourceLine" id="cb13-9" data-line-number="9"><span class="op">}</span></a></code></pre></div>
<p>The code within the closure <code>|| { ... }</code> is executed several times by the benchmark runner to obtain an accurate timing along with an estimated uncertainty. This means the code being benchmarked must avoid irreversibly changing the environment, or else the timing will not be accurate.</p>
<p>It is important to write the benchmarked code in a way such that the compiler cannot delete the code entirely. Consider this example, where one is attempting to benchmark the addition of two integers:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode rust"><code class="sourceCode rust"><a class="sourceLine" id="cb14-1" data-line-number="1">b.iter(|| <span class="op">{</span></a>
<a class="sourceLine" id="cb14-2" data-line-number="2">    <span class="kw">let</span> x = <span class="dv">1</span> + <span class="dv">2</span>;</a>
<a class="sourceLine" id="cb14-3" data-line-number="3"><span class="op">}</span>);</a></code></pre></div>
<p>There are several reasons why this naive benchmark would not yield any meaningful results:</p>
<ul>
<li><p>The compiler can easily precompute the result “3” without any effort. This means the input must <em>not</em> be predictable to the compiler. To mitigate this, one could either read the input from a file, randomize the input, or use a special <code>black_box</code> function to obscure the input from the optimizer, e.g. <code>black_box(1) + 2</code>.</p></li>
<li><p>Even if the compiler does not know the inputs, it does know that addition is a pure operation with no side-effects. Thus it would safe to hoist the statement outside the loop (<code>b.iter(...)</code> is really a loop in disguise). One could insert <code>black_box(x)</code> within the loop to prevent this.</p></li>
<li><p>Moreover, the compiler can easily see that the output variable <code>x</code> is not being used. This means the compiler will likely delete the entire calculation through dead-code elimination (DCE). To mitigate this, one could either print the output, or again use a <code>black_box</code>.</p></li>
<li><p>Lastly, addition of integers is such a fast operation that the overhead from the benchmark runner as well as environmental noise will heavily skew the results.</p></li>
</ul>
<p>We use the nuclei system for benchmarks, but with randomized matrix elements. We split the commutator into groups of terms that are benchmarked separately so that we can analyze the individual terms separately without the expensive ones drowning out the cheap ones.</p>
<p>To analyze the performance costs of given implementation, we make use of profilers. We generally avoid profilers that instrument code, because the instrumentation itself can easily add a substantial amount of overhead that can completely distort the results. For this reason, we use Perf <span class="citation" data-cites="Perf">(“Perf: Linux Profiling with Performance Counters,” n.d.)</span>, a sampling profiler for Linux that captures stack traces of the program periodically. Similar tools exist other platforms. Perf pairs quite well with flame graphs <span class="citation" data-cites="Gregg:2016:FG:2942427.2909476">(Gregg 2016)</span> for visualization, allowing easy identification of hotspots in the code.</p>
<p>Perf can run an optimized program as-is, with no instrumentation. The only extra information needed for sensible output is debugging information (<code>-g</code> flag in most compilers), which is tracked separately and does not pessimize the program. Unfortunately, high levels of optimization usually renders the debugging information inaccurate, so it remains important to compare against the assembly code.</p>
<h2 id="version-control-and-reproducibility"><span class="header-section-number">16.11</span> Version control and reproducibility</h2>
<p>The codebase for Lutario is stored in a distributed version control system (DVCS) and can be viewed online <span class="citation" data-cites="Lutario">(Yuan, n.d.)</span>. We use the Git <span class="citation" data-cites="Git">(“Git” 2017)</span> as our DVCS but one could equally well have chosen other DVCSes such as Mercurial <span class="citation" data-cites="Hg">(“Mercurial” 2017)</span>.</p>
<p>Version control systems (VCS) are tools designed to store the entire history of a codebase. At a rudimentary level, it may be considered a special kind of database tailored specifically for projects that are dominated by plain text files like code. By recording all changes that occur in a project, it becomes easy to track down the origin of both code and bugs.</p>
<p>VCSes are also designed to support collaboration on projects. Collaborators may work independently on different parts of the project, accumulating their own history of changes. They can periodically synchronize and merge their changes together to form a unified timeline. The merge can be automated as long as the collaborators work on different parts of the project.</p>
<p>Distributed VCSes are unique in that, unlike centralized VCSes, each repository – i.e. the directory managed by the VCS – maintains its own database of histories and is on equal footing as all other repositories. This means there is no centralized point of failure if any one of the repositories becomes inaccessible, allowing it act as a distributed backup system. The histories need not match either: a repository might store the main history of the project, but may also keep a private fork of this history, or of a new feature, or something entirely unrelated.</p>
<p>VCSes are most useful when they store predominantly relevant, textual data. It is particularly important to avoid storing large files as they can rapidly grow the size of the database. It is also important to avoid storing files that could be easily regenerated, such as executable files, library files, or any non-essential or transient files. Ignore lists are useful for filtering out irrelevant files.</p>
<p>Changes in a VCS are stored in the unit of a <em>commit</em>, which should generally perform a single task or add a single feature. Maintaining a clean commit history ensures that if problems appear later on, one can easily isolate the cause down to a single commit, with the aid of strategies such as bisection (e.g. <code>git-bisect</code>).</p>
<p>The use of a version control aids in the reproducibility of results. One can accurately refer to a specific version of code within a version-controlled repository using commit identifiers or human-readable tags. In particular, Git and Hg use hashes as the commit identifier, thus knowing the hash one can verify whether the files of the commit are correct with a high degree of confidence, as it is very difficult to forge these hashes.<a href="print.html#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a></p>
<p>Of course, knowing that one has the correct code alone does not guarantee that the results will be reproduced perfectly. One may also need to track the version numbers of all transitive dependencies of the program, the compiler, as well as the environmental conditions under which the program is run. Nondeterminism caused by environmental fluctuations (e.g. in parallel code) can further complicate reproducibility.</p>
<h2 id="documentation"><span class="header-section-number">16.12</span> Documentation</h2>
<p>There are two orthogonal ways to categorize documentation. On one axis, there is</p>
<ul>
<li>external documentation (for users), and</li>
<li>internal documentation (for developers of the project).</li>
</ul>
<p>On another axis:</p>
<ul>
<li><p>There is reference documentation (manuals, technical documents, specifications, API<a href="print.html#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a> documentation), which aims to describe every detail of the program including corner cases. It is usually written to follow the structure of the program (modules, functions, data types). Their target audience are the advanced users who already know their way around the software.</p></li>
<li><p>There is also review documentation (tutorials, guides, overviews), which are usually pedagogical in nature. They are used to teach the important parts of a program, without overwhelming the reader with details. They generally do not follow the structure of the program, but are structured more like a book intended for human consumption. The target audience are the new users who are not yet familiar with the software.</p></li>
</ul>
<p>At the moment, external documentation for Lutario is very sparse, given the recency of the project. As the project is still under heavily development, we expect the user-facing interfaces to change substantially. We will consider adding external documentation when a point of stability is reached.</p>
<p>Internal documentation is primarily through this chapter – which may become out of date as the project progresses – as well as the source code comments. This chapter is intended to be an overview of the machinery in Lutario without focus on any one particular aspect. Source code comments may be categorized into two types:</p>
<ul>
<li><p>Documentation comments are designated by the <code>///</code> or <code>//!</code> prefix in Rust.<a href="print.html#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a> They are useful for documenting public interfaces (APIs). These special comments can be automatically exported by the Rustdoc documentation generator. The tool outputs a book in HTML format with the comments displayed against the corresponding module, function, data type, etc. Similar tools exist for other languages, including Sphinx <span class="citation" data-cites="Sphinx">(Brandl 2018)</span> for Python, Haddock <span class="citation" data-cites="Haddock">(Marlow 2017)</span> for Haskell, and Doxygen <span class="citation" data-cites="Doxygen">(Heesch 2017)</span> for C, C++, and Fortran.</p>
<p>They can also be used to provide examples. These snippets of code are automatically tested by the Rust build system, ensuring that the example code does not fall out of date as the code evolves.</p></li>
<li><p>Normal comments (<code>//</code> or <code>/* ... */</code> in Rust) are used to explain tricky aspects of the code for the developers. They are generally used sparingly, because such comments are meant to convey <em>important</em> information that is not evident from the code itself. Excessive use of comments can hinder the readability of code. Moreover, comments – which are not sanity-checked by the compiler – are always at risk of becoming out of sync with the actual code.</p></li>
</ul>
<p>Tests themselves can also serve as useful examples, if they are written cleanly. Such dual-purpose tests are extremely useful: they are automatically tested for validity, moreover a learning user can immediately read from the test code what the expected output of the program should be. We currently have three major integration</p>
<h2 id="coding-style"><span class="header-section-number">16.13</span> Coding style</h2>
<p>While source code is to be ultimately consumed by compilers and interpreters, it is equally important for it to be comprehensible to human readers. This reduces mistakes, encourages collaboration, and simplifies maintenance of the program over the long run.</p>
<h3 id="formatting-of-code"><span class="header-section-number">16.13.1</span> Formatting of code</h3>
<p>On a superficial level, code should be formatted neatly and, most importantly, <em>consistently</em>. One should adhere to the official style guide of the language (if any), or any prevailing style used by the language community, domain, project, and/or subproject. These style conventions help establish many aspects of formatting, including indentation, spacing, line length, wrapping, and naming conventions.</p>
<p>Some languages such as Fortran, C, C++, or Haskell lack official style guides, but there may exist one or more <em>de facto</em> styles from which one can adopt. Others, like Go, Rust, Python have official style guides <span class="citation" data-cites="Gofmt FmtRFCs PEP8">(<em>Command Gofmt</em>, n.d.; “Rust Code Formatting Rfcs,” n.d.; Rossum, Warsaw, and Coghlan 2001)</span> with varying degrees of strictness, which improves collaboration and avoids unnecessary <em>bikeshedding</em> (trivial arguments) among the language community. In either case, various automatic reformatting tools are available to help maintain uniformity in coding style, such as <code>clang-format</code> for C and C++ <span class="citation" data-cites="ClFmt">(<em>ClangFormat</em> 2017)</span>, <code>gofmt</code> for Go <span class="citation" data-cites="Gofmt">(<em>Command Gofmt</em>, n.d.)</span>, and <code>rustfmt</code> for Rust <span class="citation" data-cites="Rustfmt">(“Rustfmt,” n.d.)</span>.</p>
<h3 id="coupling-and-complexity"><span class="header-section-number">16.13.2</span> Coupling and complexity</h3>
<p>A major source of complexity in programs arises from <em>coupling</em>: an interaction between different components of a system. It is analogous to coupling in physics. A system of non-interacting particles is generally easy to study. As the interactions become stronger and stronger, the system becomes increasingly difficult to understand.</p>
<p>The same principle applies to programming. Coupling should generally be avoided where possible. But that is unlikely in any non-trivial program. When it is not avoidable, coupling should always be explicitly visible to the reader. This helps avoid “effect at a distance” where, say, a programmer attempts to fix a bug, only to break something else entirely unrelated.</p>
<p>Many kinds of coupling exist. The most common one is <strong>aliasing</strong>: when different parts of a program have a shared reference or pointer to the same variable, and at least one them modifies it.</p>
<p>As discussed in Sec. <a href="print.html#sec:uniqueness-and-borrowing">16.1.2</a>, if one has exclusive control over a piece of data, they can modify it without other components of the program observing the effects of the modification. If one has shared a piece of data with other components of the program and the data is never modified by anyone, then no-one will know the difference either. However, if the data is mutated, then problems can arise because the value of the variable may unexpectedly change. Thus, aliasing makes it difficult to reason about code.</p>
<p>Without thread synchronization, aliasing generally breaks thread-safety. This is because modern CPUs like to cache data as much as possible. Without some sort of notification to the CPU that data has been modified by another thread, it will by default assume that it has exclusive control over it and continue using the cached value. The only way to ensure this is safe is through synchronization (e.g. memory fences, mutexes), which carries a performance penalty.</p>
<p>Even without threads, there are other performance penalties that arise from aliasing. The compiler can make fewer assumptions about the behavior of an aliased variable, therefore code that involves aliasing may be less well optimized.</p>
<p>Aliasing is not always avoidable. It is generally a good idea to document where aliasing occurs. Rust, in particular, takes a fairly draconian stance with regard to aliasing: all aliasing is forbidden except through one of the alias-enabling wrapper types (e.g. <code>Cell</code>, <code>RefCell</code>, <code>Mutex</code>, <code>RWLock</code>).</p>
<p>C and C++ have a set of rules (type-based alias analysis / strict aliasing rule) that determine when aliasing is acceptable and when it is not (in which case aliasing becomes undefined behavior). In C, one may assert the <em>absence</em> of aliasing through the <code>restrict</code> keyword, but the compiler make no effort to verify that assertion.</p>
<p>Global variables are a special case of aliasing, except more sinister because they are much less obvious, since whether a function accesses a global variable cannot be deduced from the function signature. The only way to tell whether a function uses a global variable is by inspecting the contents of the function and all its transitive dependencies.</p>
<p>Aliasing may be considered a type of <strong>side effect</strong>. A function is said to have side effects if it modifies some kind of state that is externally visible. Aliased variables are examples of such state, but so are things like input/output (I/O), spawning/killing a process, sending/receiving data over network, etc.</p>
<p>Side effects are a form of coupling as well, except the coupling may involve the external environment: other processes, other machines, or even other people. Like any coupling, it is always good idea to document side effects to aid reasoning of programs.</p>
<p>To help manage side effects, one should keep them contained and isolated. In particular, code that has lots of side effects should be kept separate from code with no side effects (<strong>pure</strong> code). Complicated logic are best written without side effects, allowing it to be easily refactored without concern of temporal ordering. Furthermore, pure code is generally more reusable and composable, whereas code with side-effects are usually less flexible. Some languages such as Haskell or PureScript explicitly track side-effects through the type system, encouraging the programmer to manage side-effects in a principled manner.</p>
<p>As an example, in our Lutario codebase, we generally refrain from performing any sort of I/O except in designated functions. In cases where it is not obvious, we name the function with a <code>do_</code> prefix to indicate that it does I/O.</p>
<h3 id="trade-offs"><span class="header-section-number">16.13.3</span> Trade-offs</h3>
<p>We advise against blind adherence to any particular paradigm, principle, or pattern in programming. After all, programming is best described as a form of engineering where one must constantly make compromises and trade-offs. There are no hard and fast rules in programming: it is normally a good idea to follow them, but it is even more important to understand their provenance, costs, and benefits so that the programmer can judge whether the pay-offs are worthwhile. Over-engineering can increase the size of the codebase, which can impede understanding just as much as unruly one does.</p>
<h1 id="results-and-analysis"><span class="header-section-number">17</span> Results and analysis</h1>
<p>Finally, we discuss the results we obtained with our many-body methods for quantum dots and nuclei.</p>
<h2 id="sec:methodology"><span class="header-section-number">17.1</span> Methodology</h2>
<figure>
<img src="fig-methods" alt="Figure 22: A schematic view of the various ways in which many-body methods in this work could be combined to calculate ground state, addition, and removal energies." id="fig:methods" /><figcaption>Figure 22: A schematic view of the various ways in which many-body methods in this work could be combined to calculate ground state, addition, and removal energies.</figcaption>
</figure>
<p>There is significant flexibility in the application of many-body methods. The approaches we use are shown in Fig. <a href="print.html#fig:methods">22</a>. Applying the methods in this order maximizes the benefits of each method: HF acts as an initial, crude procedure to soften the Hamiltonian, followed by IM-SRG or CC (coupled cluster method) to refine the ground state energy, and then finally QDPT or EOM (equations-of-motion method) to refine the addition and removal energies. We expect single-reference IM-SRG and CC to recover a substantial part of the dynamical correlations, while QDPT and EOM help account for static correlations.</p>
<p>The general process begins with setting up the input matrix elements. Afterward, there are several paths through which one can traverse Fig. <a href="print.html#fig:methods">22</a> to obtain output observables. Our primarily focus is on the three combinations:</p>
<ol type="a">
<li>HF + IM-SRG(2) + QDPT3, computed by us,</li>
<li>HF + IM-SRG(2) + EOM2, computed and contributed by Nathan M. Parzuchowski, and</li>
<li>HF + CCSD + EOM2, computed and contributed by Samuel J. Novario.</li>
</ol>
<p>It is possible to omit some steps of the process. For example, one can omit HF, but continue with the remaining two steps. While this is doable, from our experience HF significantly improves the results of the later post-HF methods at very low cost compared to the post-HF methods. Therefore, in practice there is little reason to omit HF. We will however investigate the effects of removing one or more of the post-HF methods.</p>
<p>Since every calculation in this work begins with the HF stage, we will not explicitly state <em>HF</em> unless there is no post-HF method used at all, in which case we write <em>HF only</em>.</p>
<p>All calculations of ground state energy <span class="math inline">\(E_N\)</span> in this work are restricted to cases where the number of particles <span class="math inline">\(N\)</span> is a magic number, i.e. a <strong>closed shell</strong> system. This is a limitation of the many-body methods used in this work and while there are ways to overcome this limit they are beyond the scope of this work (see <span class="citation" data-cites="HeikoReview">(Hergert 2017)</span>). Addition/removal energies <span class="math inline">\(\varepsilon^{(\pm)}\)</span> are similarly restricted in that we only calculate the energy difference between <span class="math inline">\(E_N\)</span> of a closed shell system and <span class="math inline">\(E_{N \pm 1}\)</span> of the same system but with one particle added/removed: <span class="math display">\[\begin{align*}
  \varepsilon^{(+)} &amp;= E_{(N + 1)} - E_N \\
  \varepsilon^{(-)} &amp;= E_N - E_{(N - 1)}
\end{align*}\]</span></p>
<h2 id="results-for-quantum-dots"><span class="header-section-number">17.2</span> Results for quantum dots</h2>
<p>The results in this section have been previously presented in <span class="citation" data-cites="doi:10.1063/1.4995615">(Yuan et al. 2017)</span>. There is a difference, however, in the numerical data for HF + QDPT3 presented here. In the original paper, one of the QDPT3 was calculated with the incorrect sign, affecting all HF + QDPT3 results. It has been corrected in this chapter. The conclusions remain unchanged.</p>
<p>Ideally, ground state energies should be characterized entirely by the two system parameters <span class="math inline">\((N, \omega)\)</span>, where <span class="math inline">\(N\)</span> is number of particles and <span class="math inline">\(\omega\)</span> is the oscillator frequency. However, the methods that we study are limited to a <em>finite</em> (truncated) basis and the results depend on the level of truncation. This is characterized by <span class="math inline">\(K\)</span>, the total number of shells in the single-particle basis. Thus, results are generally presented as a graph plotted against <span class="math inline">\(K\)</span>. In Sec. <a href="print.html#sec:extrapolation">17.2.4</a> we discuss how to estimate results as <span class="math inline">\(K \to \infty\)</span> (infinite-basis limit) through extrapolations.</p>
<p>The addition and removal energies are similar, but they require an additional parameter: the total orbital angular momentum <span class="math inline">\(M_\ell\)</span>, defined as the sum of the <span class="math inline">\(m_\ell\)</span> of each particle. This is due to the presence of multiple states with near-degenerate energies. For this work, we will consider exclusively the addition/removal energies with the lowest <span class="math inline">\(|M_\ell|\)</span> subject to the constraint that the particle added/removed lies within the next/last shell. This means the <span class="math inline">\(N + 1\)</span> states of interest are those with <span class="math inline">\(|M_\ell| = K_{\mathrm{F}} \bmod 2\)</span> (where <span class="math inline">\(\bmod\)</span> stands for the modulo operation) where <span class="math inline">\(K_{\mathrm{F}}\)</span> is the number of occupied shells, while the <span class="math inline">\(N - 1\)</span> states of interest are those with <span class="math inline">\(|M_\ell| = 1 - (K_{\mathrm{F}} \bmod 2)\)</span>.</p>
<p>Not all cases are solvable with our selection of many-body methods. Low frequency systems are particularly strenuous for these many-body methods due to their strong correlations, leading to equations that are difficult and expensive to solve numerically. In the tables, <em>n.c.</em> marks the cases where IM-SRG(2) or CCSD either diverged or converged extremely slowly. This also affects the extrapolation results in Sec. <a href="print.html#sec:extrapolation">17.2.4</a>, as for consistency reasons we chose to extrapolate only when all five points were available.</p>
<p>Numerical calculations in this section are performed with a relative precision of about <span class="math inline">\(10^{-5}\)</span> or lower. This does not necessarily mean the results are as precise as <span class="math inline">\(10^{-5}\)</span>, since numerical errors tend to accumulate over the multiple steps of the calculation, thus the precision of the final results is expected to be roughly <span class="math inline">\(10^{-4}\)</span>.</p>
<h3 id="ground-state-energy"><span class="header-section-number">17.2.1</span> Ground state energy</h3>

<figure>
<embed src="fig-gs2.pdf" id="fig:gs" /><figcaption>Figure 23: Plots of ground state energy of quantum dots with <span class="math inline">\(N\)</span> particles and an oscillatory frequency of <span class="math inline">\(\omega\)</span> against the number of shells <span class="math inline">\(K\)</span>. Since DMC does not utilize a finite basis, the horizontal axis is irrelevant and DMC results are plotted as horizontal lines.</figcaption>
</figure>

<p>Fig. <a href="print.html#fig:gs">23</a> and Tbl.  display a selection of ground state energies calculated using HF + IM-SRG(2) and HF + CCSD as described in Sec. <a href="print.html#sec:methodology">17.1</a>. We include results from Møller–Plesset perturbation theory to second order (MP2), DMC <span class="citation" data-cites="hoegberget2013thesis">(Høgberget 2013)</span>, and FCI <span class="citation" data-cites="olsen2013thesis">(Olsen 2013)</span> (see Tbl. ) for comparison where available.</p>
<p>We do not include results from <em>HF only</em> to avoid overshadowing the comparatively smaller differences between the non-HF results in the plots. Some HF results can be found in Fig. <a href="print.html#fig:by-freq-10-6-normal">26</a> instead. Generally, the HF ground state energies differ from the non-HF ones by a few to several percent, whereas non-HF energies tend to differ from each other by less than a percent.</p>
<p>With respect to the number of shells, both IM-SRG(2) and CCSD appear to converge slightly faster than second order perturbation theory (MP2), mainly due to the presence of higher order corrections in IM-SRG(2) and CCSD.</p>
<p>There are a few cases where the IM-SRG over-corrects the result, leading to an energy lower than the quasi-exact DMC results. This is not unexpected given that, unlike the HF results, the IM-SRG method is non-variational in the presence of operator truncations, which in turn results in small unitarity violations. This over-correction tends to occur when the frequency is low (high correlation), or when <em>few</em> particles are involved.</p>
<h3 id="addition-and-removal-energies"><span class="header-section-number">17.2.2</span> Addition and removal energies</h3>

<figure>
<img src="fig-add2" alt="Figure 24: Addition energies for a selection of quantum dot parameters. See Fig. 23 for details." id="fig:add" /><figcaption>Figure 24: Addition energies for a selection of quantum dot parameters. See Fig. <a href="print.html#fig:gs">23</a> for details.</figcaption>
</figure>
<figure>
<embed src="fig-rm2.pdf" id="fig:rm" /><figcaption>Figure 25: Removal energies for a selection of quantum dot parameters. See Fig. <a href="print.html#fig:add">24</a> for details.</figcaption>
</figure>
<p>The results of our addition and removal energy calculations are summarized in Fig. <a href="print.html#fig:add">24</a> and Fig. <a href="print.html#fig:rm">25</a> respectively. The figures show the addition/removal energies for using the approaches mentioned in Sec. <a href="print.html#sec:methodology">17.1</a>. Where available, results from diffusion Monte Carlo (DMC) <span class="citation" data-cites="PhysRevB.84.115302">(Pedersen Lohne et al. 2011)</span> are shown as a dashed line.</p>
<p>As before, we do not include results from <em>HF only</em> in these plots as they are significantly further from the rest. Analogously, we also exclude results from pure IM-SRG (i.e. without QDPT nor EOM) or pure CCSD, as QDPT or EOM both add significant contributions to addition and removal energies. Some HF only and pure IM-SRG results can be seen in Fig. <a href="print.html#fig:by-freq-10-6-normal">26</a>.</p>
<figure>
<img src="fig-by-freq-10-6-normal" alt="Figure 26: The behavior of ground state, addition, and removal energies as a function of the oscillator frequency \omega, with K = 10 shells in the basis. The energy is normalized with respect to the HF values to magnify the differences. Lower frequency leads to stronger correlations and thereby a more difficult problem." id="fig:by-freq-10-6-normal" /><figcaption>Figure 26: The behavior of ground state, addition, and removal energies as a function of the oscillator frequency <span class="math inline">\(\omega\)</span>, with <span class="math inline">\(K = 10\)</span> shells in the basis. The energy is normalized with respect to the HF values to magnify the differences. Lower frequency leads to stronger correlations and thereby a more difficult problem.</figcaption>
</figure>
<p>There is strong agreement between IM-SRG(2) + QDPT3 and IM-SRG(2) + EOM2 in many cases, and slightly weaker agreement between the IM-SRG and CCSD families. This suggests that the EOM2 corrections are largely accounted for by the inexpensive QDPT3 method. However, in some cases, most notably with few particles and high correlations (low frequency), the IM-SRG(2) + QDPT3 result differs significantly from both IM-SRG(2) + EOM2 and CCSD + EOM2.</p>
<h3 id="rate-of-convergence"><span class="header-section-number">17.2.3</span> Rate of convergence</h3>
<figure>
<embed src="fig-rel-slopes2.pdf" id="fig:rel-slopes" /><figcaption>Figure 27: The impact of the interaction on convergence of addition and removal energies using IM-SRG(2) + QDPT3. For clarity, the plot does not distinguish between addition and removal energies. The horizontal axis shows the system parameters, where <span class="math inline">\(N\)</span> is the number of particles and <span class="math inline">\(\omega\)</span> is the oscillator frequency. The vertical axis shows <span class="math inline">\(|\rho_{15}|\)</span> (<em>relative slope</em>), which estimates the rate of convergence at 15 total shells. The lower the value of <span class="math inline">\(|\rho_{15}|\)</span>, the faster the convergence. The data points are categorized by the interactions. The trends suggest that the singular short-range part of the interaction has a much stronger impact on the convergence than the long-range tail.</figcaption>
</figure>
<p>To analyze the rate of convergence more quantitatively, we define <span class="math inline">\(\rho_K\)</span> as the relative backward difference of the energy (<strong>relative slope</strong>): <span class="math display">\[\rho_K = \frac{\varepsilon_K - \varepsilon_{(K - 1)}}{\varepsilon_K}\]</span> The denominator allows the quantity to be meaningfully compared between different systems. We expect this quantity to become increasingly small as the calculations converge towards the complete basis set limit.</p>
<p>In Fig. <a href="print.html#fig:rel-slopes">27</a>, we plot the <span class="math inline">\(\rho_{15}\)</span> for IM-SRG(2) + QDPT3. The many-body methods were tested against a <em>modified</em> Coulomb-like interaction, parametrized by two lengths <span class="math inline">\(\sigma_{\mathrm{A}}\)</span> and <span class="math inline">\(\sigma_{\mathrm{B}}\)</span> that characterize the range of the interaction: <span class="math display">\[V_{\sigma_{\mathrm{A}}, \sigma_{\mathrm{B}}}(r) = \frac{(1 + c)^{1 - 1/c}}{c} \left(1 - \E^{-r^2 / (2 \sigma_{\mathrm{A}}^2)}\right) \E^{-r^2 / (2 \sigma_{\mathrm{B}}^2)} \frac{1}{r}\]</span> where <span class="math inline">\(c = \sqrt{\sigma_{\mathrm{B}} / \sigma_{\mathrm{A}}}\)</span>. The coefficient is chosen to ensure the peak of the envelope remains at unity. With <span class="math inline">\((\sigma_{\mathrm{A}}, \sigma_{\mathrm{B}}) = (0, \infty)\)</span> one recovers the original Coulomb interaction. By increasing <span class="math inline">\(\sigma_{\mathrm{A}}\)</span> one can truncate the short-range part of the interaction, and analogously by increasing <span class="math inline">\(\sigma_{\mathrm{B}}\)</span> one can truncate the long-range part of the interaction. For our numerical experiments we considered the following four combinations of <span class="math inline">\((\sigma_{\mathrm{A}}, \sigma_{\mathrm{B}})\)</span>: <span class="math inline">\((0, \infty)\)</span>, <span class="math inline">\((\frac{1}{2}, \infty)\)</span>, <span class="math inline">\((0, 4)\)</span>, <span class="math inline">\((\frac{1}{2}, 4)\)</span>.</p>
<p>Reducing the short-range part of the interaction appears to improve the rate of convergence substantially. Many of the cases have reached the precision of the ODE solver (<span class="math inline">\(10^{-5}\)</span> to <span class="math inline">\(10^{-6}\)</span>). In contrast, eliminating the long-range part of the interaction had very little effect. This suggests that the main cause of the slow convergence lies in the highly repulsive, short-ranged part of the interaction, which leads to the presence of nondifferentiable cusps (the so-called <em>Coulomb cusps</em>) in the exact wave functions that are difficult to reproduce exactly using linear combinations of the smooth harmonic oscillator wave functions.</p>
<p>The convergence is negatively impacted at lower frequencies and, to a lesser extent, by the increased number of particles. Both are expected: lower frequencies increase the correlation in the system, while higher number of particles naturally require more shells to converge.</p>
<p>In general, there does not appear to be any difference between the convergence behavior of addition energies as compared to that of removal energies.</p>
<h3 id="sec:extrapolation"><span class="header-section-number">17.2.4</span> Extrapolation</h3>

<figure>
<img src="fig-fit-2-1p0-add" alt="Figure 28: A five-point fit of the addition energies of the (N, \omega) = (6, 1.0) system with K_{\text{stop}} = 15. The grey shaded region contains the masked data points, which are ignored by the fitting procedure. The left figure plots the central difference of the addition energies \varepsilon^{(+)} with respect to the number of shells K. On such a plot, the power law model should appear as a straight line. The fits are optimized using the procedure described in Sec. 17.2.4. Note that the lines do not evenly pass through the points in the left plot as the fitting weights are tuned for the energy on a linear scale, not the energy differences on a logarithmic scale." id="fig:by-fit-2-1p0-add" /><figcaption>Figure 28: A five-point fit of the addition energies of the <span class="math inline">\((N, \omega) = (6, 1.0)\)</span> system with <span class="math inline">\(K_{\text{stop}} = 15\)</span>. The grey shaded region contains the masked data points, which are ignored by the fitting procedure. The left figure plots the central difference of the addition energies <span class="math inline">\(\varepsilon^{(+)}\)</span> with respect to the number of shells <span class="math inline">\(K\)</span>. On such a plot, the power law model should appear as a straight line. The fits are optimized using the procedure described in Sec. <a href="print.html#sec:extrapolation">17.2.4</a>. Note that the lines do not evenly pass through the points in the left plot as the fitting weights are tuned for the energy on a linear scale, not the energy differences on a logarithmic scale.</figcaption>
</figure>
<p>To reduce errors from the basis set truncation, one can either use explicitly correlated R12/F12 methods that account for the correct cusp behavior in many-electron wave functions <span class="citation" data-cites="Kutzelnigg1985 KLOPPER198717 explicitcorrelationreview">(Kutzelnigg 1985; Klopper and Kutzelnigg 1987; Kong, Bischoff, and Valeev 2012)</span>, or one can use basis extrapolation techniques. In the present work, we focus on the latter. As derived by Kvaal <span class="citation" data-cites="PhysRevB.80.045321 Kvaal2007">(Kvaal 2009; Kvaal, Hjorth-Jensen, and Møll Nilsen 2007)</span>, the asymptotic convergence of quantum dot observables in a finite harmonic oscillator basis can be approximately described by a power law model: <span class="math display">\[\Delta E \propto K^{-\beta}\]</span> where <span class="math inline">\(\Delta E\)</span> is the difference between the finite-basis result and the infinite-basis result, <span class="math inline">\(K\)</span> is the number of shells in the single-particle basis, and <span class="math inline">\(\beta\)</span> is some positive real exponent. The <em>smoothness</em> of the exact wave function determines the rate of the convergence: the more times the exact wave function can be differentiated, the higher the exponent <span class="math inline">\(\beta\)</span>.</p>
<p>We note that this model was derived under the assumption that all correlations are included in the calculation (i.e. FCI), thus we are making an assumption that our selection of methods approximately obey the same behavior. The validity of this assumption will be assessed at the end of this section.</p>
<p>In general, the exponent <span class="math inline">\(\beta\)</span> cannot be determined <em>a priori</em>, thus we will empirically compute <span class="math inline">\(\beta\)</span> by fitting the following model through our data: <span id="eq:power_law_model"><span class="math display">\[E = \alpha K^{-\beta} + \gamma \qquad(75)\]</span></span> As a nonlinear curve fit, it can be quite sensitive to the initial parameters. Therefore, good guesses of the parameters are necessary to obtain a sensible result. For this, we first fit a linear model of <span class="math inline">\(\log |\partial E / \partial K|\)</span> against <span class="math inline">\(\log K\)</span>: <span class="math display">\[\log \left|\frac{\partial E}{\partial K}\right| = - (\beta + 1) \log K + \log|\alpha \beta|\]</span> This is useful because linear fits are very robust and will often converge even if the initial parameters are far from their final values. It also provides a means to visually assess the quality of the fit. The derivative is approximated using the central difference: <span class="math display">\[\frac{\partial E}{\partial K} \approx E\left(K + \frac{1}{2}\right) - E\left(K - \frac{1}{2}\right)\]</span> The process of numerically calculating the derivative can amplify the noise in the data and distorts the weights of the data points. Moreover, it does not provide a means to compute <span class="math inline">\(\gamma\)</span>, the extrapolated energy. Thus a second accurate nonlinear curve fit is necessary.</p>
<p>The parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are extracted from the linear fit and used as inputs for a power-law fit of <span class="math inline">\(E\)</span> against <span class="math inline">\(K\)</span>. It is necessary to estimate the infinite-basis energy <span class="math inline">\(\gamma\)</span> as well, which is done by fitting Eq. <a href="print.html#eq:power_law_model">75</a> while the parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are fixed to the initial guesses. The fixing ensures that the fit is still linear in nature and thus highly likely to converge. Afterward, we do a final fit with all three parameters free to vary. All fits are done using the traditional Levenberg–Marquardt (LM) optimization algorithm <span class="citation" data-cites="10.2307/43633451 doi:10.1137/0111030">(Levenberg 1944; Marquardt 1963)</span> as implemented in <code>MINPACK</code> <span class="citation" data-cites="More1978 More:126569">(Moré 1978; Moré, Garbow, and Hillstrom 1980)</span>, with equal weighting of all data points.</p>
<p>There is still one additional tuning knob for this model that is not explicitly part of Eq. <a href="print.html#eq:power_law_model">75</a>: the range of data points taken into consideration (<strong>fit range</strong>). Since the model describes the <em>asymptotic</em> behavior, we do not expect the fit to produce good results when the energy is still very far from convergence. To account for this, we only fit the last few data points within some chosen range. If the range is too large, then the non-asymptotic behavior would perturb the result too much, whereas if the range is too small, there would be more noise and less confidence in whether the trend is legitimate rather than accidental. Empirically, we chose to fit the last 5 points of our available data. The results are shown in Tbls. , , and . A specific example of the fit is shown in Fig. <a href="print.html#fig:by-fit-2-1p0-add">28</a></p>
<p>The LM fitting procedure also computes uncertainties for the parameters from an approximate Hessian of the model function. It is therefore tempting to use the uncertainty of the fit to quantify the uncertainty of the extrapolated energy. We certainly would not expect this to account for the error due to the operator truncation, but how accurately does it quantify the discrepancy of our extrapolated result from the true infinite-basis energy?</p>
<p>We investigated this idea by performing a fit over <em>all possible</em> 5-point fit ranges <span class="math inline">\([K_{\text{stop}} - 4, K_{\text{stop}}]\)</span>. By comparing the extrapolated results at varying values of <span class="math inline">\(K_{\text{stop}}\)</span> with the extrapolated result at the highest possible <span class="math inline">\(K_{\text{stop}}\)</span> and treating the latter as the “true” infinite-basis result, we can statistically assess whether the fit uncertainties are a good measure of the discrepancy from the true infinite-basis result. Our results show a somewhat bimodal distribution: when the relative fit uncertainty is higher than <span class="math inline">\(10^{-3.5}\)</span>, the fit uncertainty quantifies the discrepancy well; otherwise, the fit uncertainty underestimates the discrepancy by a factor of 10 or less.</p>
<p>Unlike the other methods, HF energies are somewhat unusual in that they generally do not conform to the power-law model. In fact, the plots indicate an <em>exponential</em> convergence with respect to the number of shells, which has also been observed in molecular systems <span class="citation" data-cites="HALKIER1999437">(Halkier et al. 1999)</span>. We surmise that HF is insensitive to the Coulomb cusp.</p>
<p>Nonetheless, despite the poor fits that often arise, the extrapolated energies are often quite good for HF. This is likely due to its rapid convergence, which leaves very little degree of freedom even for a poorly chosen model. Moreover, we found that the fit uncertainties of the energy are fairly good measures of the true discrepancy.</p>
<p>Not all fits yield a positive value of <span class="math inline">\(\beta\)</span> for addition and removal energies, which suggests that the data points do not converge, or require a very high number of shells to converge. This affects exclusively IM-SRG(2) + QDPT3 for systems with few particles and low frequencies, indicating that perturbation theory is inadequate for such systems.</p>
<h2 id="results-for-nuclei"><span class="header-section-number">17.3</span> Results for nuclei</h2>
<p>In this section, we provide a few selected results for nuclear systems as a proof of concept. Due to time constraints, we have not been able to run calculations with higher values of <span class="math inline">\(e_{\mathrm{max}}\)</span> (Eq. <a href="nuclei.html#eq:emax">63</a>) or to explore a greater span of the oscillator frequency <span class="math inline">\(\omega\)</span> of the basis. We expect to gather a more diverse collection of results in a future publication <span class="citation" data-cites="SpEnergiesNucl">(Yuan et al., n.d.)</span>.</p>
<figure>
<img src="fig-o16" alt="Figure 29: Ground state of 16O, computed using IM-SRG(2) and CCSD with the N3LO(\Lambda = \SI{500}{MeV}, \lambda_{\mathrm{SRG}} = \SI{2}{fm^{-1}}) interaction" id="fig:o16" /><figcaption>Figure 29: Ground state of <sup>16</sup>O, computed using IM-SRG(2) and CCSD with the N<sup>3</sup>LO<span class="math inline">\((\Lambda = \SI{500}{MeV}, \lambda_{\mathrm{SRG}} = \SI{2}{fm^{-1}})\)</span> interaction</figcaption>
</figure>
<p>Fig. <a href="print.html#fig:o16">29</a> shows the computed ground state energies of oxygen-16 plotted as a function of the basis oscillator frequency <span class="math inline">\(\omega\)</span>. The results were computed using two many-body methods: HF + IM-SRG and HF + CCSD (coupled cluster singles and doubles). The interaction we use is the N<sup>3</sup>LO<span class="math inline">\((\Lambda = \SI{500}{MeV})\)</span> interaction of <span class="citation" data-cites="PhysRevC.68.041001">(Entem and Machleidt 2003)</span>, softened by SRG evolution to <span class="math inline">\(\lambda_{\mathrm{SRG}} = \SI{2}{fm^{-1}}\)</span>. We use a strictly two-body nuclear interaction here.</p>
<p>We observe that both methods agree with each other to about <span class="math inline">\(\SI{1}{MeV}\)</span>. Furthermore, we see that the results are very close to convergence with respect to <span class="math inline">\(e_{\mathrm{max}}\)</span>. The cup-shaped curve suggests the existence of a local minimum near <span class="math inline">\(\omega = \SI{24}{MeV} / \hbar\)</span>. The curve is quite flat, which again suggests that the results are nearly converged.</p>
<p>For reference, the experimental value is about <span class="math inline">\(\SI{-128}{MeV}\)</span>. The reason for this large discrepancy is that the SRG softening of the interaction has introduced a significant three-body component to the nuclear interaction that we are neglecting. With the appropriate treatment of this three-body component, one can achieve values much closer to experimental data. Readers interested in more elaborate ground state energy calculations using IM-SRG may consult <span class="citation" data-cites="PhysRevC.87.034307">(Hergert et al. 2013)</span>.</p>
<figure>
<img src="fig-o17" alt="Figure 30: Addition energy from 16O to 17O, computed using IM-SRG(2) + QDPT3 and CCSD + EOM2 with the N3LO(\Lambda = \SI{500}{MeV}, \lambda_{\mathrm{SRG}} = \SI{2}{fm^{-1}}) interaction" id="fig:o17" /><figcaption>Figure 30: Addition energy from <sup>16</sup>O to <sup>17</sup>O, computed using IM-SRG(2) + QDPT3 and CCSD + EOM2 with the N<sup>3</sup>LO<span class="math inline">\((\Lambda = \SI{500}{MeV}, \lambda_{\mathrm{SRG}} = \SI{2}{fm^{-1}})\)</span> interaction</figcaption>
</figure>
<p>We now consider the addition energy going from oxygen-16 to oxygen-17, achieved by adding a neutron to the <span class="math inline">\(0\mathrm{d}_{5/2}\)</span> state. This is presented in Fig. <a href="print.html#fig:o17">30</a>. The energies were calculated using HF + IM-SRG(2) + QDPT3 and HF + CCSD + EOM2 with the same nuclear interaction as before.</p>
<p>Both methods agree with each other to about <span class="math inline">\(\SI{0.2}{MeV}\)</span>. With respect to <span class="math inline">\(e_{\mathrm{max}}\)</span>, both curves are converging at a rate of <span class="math inline">\(\SI{0.05}{MeV}\)</span> per shell, which is also quite good. Unlike the ground state however, the curve is no longer cup-shaped, but increasing with the frequency. This is not entirely unusual, as such shapes have been observed in other non-energy observables. It may also be possible that there is a local minimum to the left side of the graph, though we consider this unlikely given our removal energy results in the next figure.</p>
<p>For comparison, the experimental value is about <span class="math inline">\(\SI{-4.1}{MeV}\)</span>. We suspect that the absence of three-body forces is a significant reason for this discrepancy.</p>
<figure>
<img src="fig-n15" alt="Figure 31: Removal energy from 16O to 15N, computed using IM-SRG(2) + QDPT3 and CCSD + EOM2 with the N3LO(\Lambda = \SI{500}{MeV}, \lambda_{\mathrm{SRG}} = \SI{2}{fm^{-1}}) interaction" id="fig:n15" /><figcaption>Figure 31: Removal energy from <sup>16</sup>O to <sup>15</sup>N, computed using IM-SRG(2) + QDPT3 and CCSD + EOM2 with the N<sup>3</sup>LO<span class="math inline">\((\Lambda = \SI{500}{MeV}, \lambda_{\mathrm{SRG}} = \SI{2}{fm^{-1}})\)</span> interaction</figcaption>
</figure>
<p>The removal energy going from oxygen-16 to nitrogen-15 is achieved by removing a proton from the <span class="math inline">\(0\mathrm{p}_{1/2}\)</span> state. This is presented in Fig. <a href="print.html#fig:n15">31</a>. The energies were calculated using HF + IM-SRG(2) + QDPT3 and HF + CCSD + EOM2 with the same nuclear interaction as before.</p>
<p>Both methods agree with each other to about <span class="math inline">\(\SI{0.3}{MeV}\)</span>. With respect to <span class="math inline">\(e_{\mathrm{max}}\)</span>, both curves are converging at a rate of <span class="math inline">\(\SI{0.02}{MeV}\)</span> per shell, which is really good considering the magnitude of the removal energy. Like the addition energies, the curve is not cup-shaped, but leans to the side. However, in this case we clearly see a point where the curves at different <span class="math inline">\(e_{\mathrm{max}}\)</span> values cross each other, at around <span class="math inline">\(\omega = \SI{25}{MeV} / \hbar\)</span>.</p>
<p>For comparison, the experimental value is about <span class="math inline">\(\SI{-12}{MeV}\)</span>. Again, our values are significantly different, likely due to missing three-body contributions.</p>
<p>For reference, we have also attached the results for nitrogen-15 in the excited state <span class="math inline">\(J^\pi = \frac{3}{2}^-\)</span> in Fig. <a href="print.html#fig:n15-3">32</a>, oxygen-23 in Fig. <a href="print.html#fig:o23">33</a>, and oxygen 21 in Fig. <a href="print.html#fig:o21">34</a>. All these results were calculated using the same approach as before. In all cases, the difference between the two methods is very small and the convergence with respect to <span class="math inline">\(e_{\mathrm{max}}\)</span> appears to be quite good.</p>
<figure>
<img src="fig-n15-3" alt="Figure 32: Removal energy from 16O to 15N in the excited J^\pi = \frac{3}{2}^- state, computed using IM-SRG(2) + QDPT3 and CCSD + EOM2 with the N3LO(\Lambda = \SI{500}{MeV}, \lambda_{\mathrm{SRG}} = \SI{2}{fm^{-1}}) interaction" id="fig:n15-3" /><figcaption>Figure 32: Removal energy from <sup>16</sup>O to <sup>15</sup>N in the excited <span class="math inline">\(J^\pi = \frac{3}{2}^-\)</span> state, computed using IM-SRG(2) + QDPT3 and CCSD + EOM2 with the N<sup>3</sup>LO<span class="math inline">\((\Lambda = \SI{500}{MeV}, \lambda_{\mathrm{SRG}} = \SI{2}{fm^{-1}})\)</span> interaction</figcaption>
</figure>
<figure>
<img src="fig-o23" alt="Figure 33: Addition energy from 22O to 23O, computed using IM-SRG(2) + QDPT3 and CCSD + EOM2 with the N3LO(\Lambda = \SI{500}{MeV}, \lambda_{\mathrm{SRG}} = \SI{2}{fm^{-1}}) interaction" id="fig:o23" /><figcaption>Figure 33: Addition energy from <sup>22</sup>O to <sup>23</sup>O, computed using IM-SRG(2) + QDPT3 and CCSD + EOM2 with the N<sup>3</sup>LO<span class="math inline">\((\Lambda = \SI{500}{MeV}, \lambda_{\mathrm{SRG}} = \SI{2}{fm^{-1}})\)</span> interaction</figcaption>
</figure>
<figure>
<img src="fig-o21" alt="Figure 34: Removal energy from 22O to 21O, computed using IM-SRG(2) + QDPT3 and CCSD + EOM2 with the N3LO(\Lambda = \SI{500}{MeV}, \lambda_{\mathrm{SRG}} = \SI{2}{fm^{-1}}) interaction" id="fig:o21" /><figcaption>Figure 34: Removal energy from <sup>22</sup>O to <sup>21</sup>O, computed using IM-SRG(2) + QDPT3 and CCSD + EOM2 with the N<sup>3</sup>LO<span class="math inline">\((\Lambda = \SI{500}{MeV}, \lambda_{\mathrm{SRG}} = \SI{2}{fm^{-1}})\)</span> interaction</figcaption>
</figure>
<p>From the preliminary results so far, we see that our perturbative results agree quite well with the EOM results. In conjunction with the testing and verification described in Sec. <a href="implementation.html#sec:testing">16.10</a>, this helps confirm the correctness of our J-scheme implementation. We believe these results indicate a promising start for more extensive studies of nuclei through this approach.</p>
<h1 id="conclusions"><span class="header-section-number">18</span> Conclusions</h1>
<p>In this work, our focus has been on the calculation of single-particle energies (addition and removal energies) of quantum dots and nuclei using a combination of Hartree–Fock (HF) theory, in-medium similarity renormalization group theory up to two-body operators (IM-SRG(2)), and quasidegenerate perturbation theory at third order (QDPT3). We have compared the results to other methods like equations-of-motion up to two-particle excitations (EOM2) and coupled cluster with singles and doubles (CCSD) and found good agreement in the majority of the systems. Thus, we have a reasonably effective and inexpensive way to compute energies of states near closed-shell nuclei.</p>
<p>To achieve this calculation, we have developed an open-source J-scheme implementation of the three major many-body methods verified by a variety of tests. It is capable of calculating various quantum systems, including quantum dots and nuclei. The framework of the code is highly flexible: one can readily add additional quantum systems simply by writing a module that supplies the appropriate input single-particle basis (Sec. <a href="implementation.html#sec:input-single-particle-basis">16.4.4.1</a>).</p>
<p>In concert with the J-scheme implementation, we have also developed a graphical tool for painless manipulation of angular momentum coupling diagrams. This greatly reduces the effort required to derive J-scheme equations and eliminates many sources of human error. We expect this to be particularly useful in theories where spherical tensor operators occur.</p>
<h2 id="future-perspectives"><span class="header-section-number">18.1</span> Future perspectives</h2>
<p>There are many directions in which our current work can be improved upon. The most immediate extension is the exploration of additional parameters for our nuclear calculations, including additional oscillator frequencies <span class="math inline">\(\omega\)</span>, additional values of <span class="math inline">\(e_{\mathrm{max}}\)</span> (maximum shell index, Eq. <a href="nuclei.html#eq:emax">63</a>), and of course additional nuclear isotopes. There are numerous possibilities here.</p>
<p>After obtaining nuclear results with more parameters, we could perform a more detailed analysis of the convergence patterns with respect to both <span class="math inline">\(e_{\mathrm{max}}\)</span> and <span class="math inline">\(\omega\)</span>. We can also compute extrapolations using, for example, the prescription in <span class="citation" data-cites="Hergert2016165">(Hergert et al. 2016)</span>.</p>
<p>As we have already implemented systems like infinite nuclear matter <span class="citation" data-cites="lnp936">(Hjorth-Jensen, Lombardo, and Kolck 2017)</span> and homogeneous electron gas <span class="citation" data-cites="PhysRevLett.110.226401">(Shepherd and Grüneis 2013)</span>, we could explore these systems and analyze the quality our method in these systems. Neutron drop calculations can also be readily achieved with our code since it uses essentially the same basis as nuclei.</p>
<p>It is possible to construct valence shell model Hamiltonians using only QDPT <span class="citation" data-cites="HJORTHJENSEN1995125">(Hjorth-Jensen, Kuo, and Osnes 1995)</span>, but concerns were raised about its convergence due to the strength of the nuclear interaction. Given our preliminary but promising results, it may be possible to use IM-SRG + QDPT to construct valence shell model Hamiltonians and operators with comparable quality to those from EOM-based approaches, which are significantly more expensive.</p>
<p>The inclusion of three-body force is likely a necessity for results that are comparable with experimental data. We can introduce a large fraction of its contribution through the three-body normal-ordering process, which is computationally tractable, unlike IM-SRG(3). We could also upgrade the HF framework to include three-body forces.</p>
<p>We could improve the IM-SRG(2) approximation by incorporating some of the truncated higher-body terms in the commutator through approximate techniques such as those described in <span class="citation" data-cites="Hergert2016165 morris2016thesis">(Hergert et al. 2016; Morris 2016)</span>. It may also be worth evaluating additional QDPT terms at fourth order for greater accuracy. Since the nature of IM-SRG can eliminate a large number of QDPT terms, QDPT4 may be feasible. Some classes of diagrams could even be summed to infinite order through resummation techniques.</p>
<p>Our J-scheme implementation is not yet fully optimized. Some of the expensive commutator terms are still coded fairly naively and could be improved. We have also made very little use of parallelization at either the shared-memory or distributed-memory level – currently, parallelization occurs primarily within the external GEMM implementation, which is limited to threads. The Shampine–Gordon ODE solver library that we use is very much designed for distributed-memory parallelization – if we enable this feature, it would help distribute both the computational and memory load across multiple nodes. Several of the expensive GEMM calculations could be distributed between nodes on a block-by-block basis similar to <span class="citation" data-cites="5999822">(Aktulga et al. 2011)</span>.</p>
<h1 class="unnumbered">References,heading=bibintoc</h1>
<div id="refs" class="references">
<div id="ref-5999822">
<p>Aktulga, H. M., C. Yang, E. G. Ng, P. Maris, and J. P. Vary. 2011. “Large-Scale Parallel Null Space Calculation for Nuclear Configuration Interaction.” In <em>2011 International Conference on High Performance Computing Simulation</em>, 176–85. <a href="https://doi.org/10.1109/HPCSim.2011.5999822" class="uri">https://doi.org/10.1109/HPCSim.2011.5999822</a>.</p>
</div>
<div id="ref-laug">
<p>Anderson, E., Z. Bai, C. Bischof, S. Blackford, J. Demmel, J. Dongarra, J. Du Croz, et al. 1999. <em>LAPACK Users’ Guide</em>. Third. Philadelphia, PA: Society for Industrial; Applied Mathematics. <a href="https://doi.org/10.1137/1.9780898719604" class="uri">https://doi.org/10.1137/1.9780898719604</a>.</p>
</div>
<div id="ref-0953-8984-10-3-013">
<p>Anisimovas, E., and A. Matulis. 1998. “Energy Spectra of Few-Electron Quantum Dots.” <em>J. Phys. Condens. Mat.</em> 10 (3):601. <a href="https://doi.org/10.1088/0953-8984/10/3/013" class="uri">https://doi.org/10.1088/0953-8984/10/3/013</a>.</p>
</div>
<div id="ref-Apache2">
<p>“Apache License, Version 2.0.” n.d. Apache Software Foundation. <a href="https://www.apache.org/licenses/LICENSE-2.0" class="uri">https://www.apache.org/licenses/LICENSE-2.0</a>.</p>
</div>
<div id="ref-BalcarLovesey2009">
<p>Balcar, Ewald, and Stephen W. Lovesey. 2009. <em>Introduction to the Graphical Theory of Angular Momentum: Case Studies</em>. 1st ed. Vol. 234. Springer Tracts in Modern Physics. Berlin, Heidelberg: Springer. <a href="https://doi.org/10.1007/978-3-642-03118-2" class="uri">https://doi.org/10.1007/978-3-642-03118-2</a>.</p>
</div>
<div id="ref-ISI:A1981MN73700014">
<p>Bartlett, R. J. 1981. “Many-Body Perturbation-Theory and Coupled Cluster Theory for Electron Correlation in Molecules.” <em>Annu. Rev. Phys. Chem.</em> 32:359. <a href="https://doi.org/10.1146/annurev.pc.32.100181.002043" class="uri">https://doi.org/10.1146/annurev.pc.32.100181.002043</a>.</p>
</div>
<div id="ref-tuprints3946">
<p>Binder, Sven. 2014. “Coupled-Cluster Theory for Nuclear Structure.” PhD thesis, Darmstadt: Technische Universität. <a href="https://tuprints.ulb.tu-darmstadt.de/3946/" class="uri">https://tuprints.ulb.tu-darmstadt.de/3946/</a>.</p>
</div>
<div id="ref-PhysRevC.75.061001">
<p>Bogner, S. K., R. J. Furnstahl, and R. J. Perry. 2007. “Similarity Renormalization Group for Nucleon-Nucleon Interactions.” <em>Phys. Rev. C</em> 75. American Physical Society:061001.</p>
</div>
<div id="ref-PhysRevLett.113.142501">
<p>Bogner, S. K., H. Hergert, J. D. Holt, A. Schwenk, S. Binder, A. Calci, J. Langhammer, and R. Roth. 2014. “Nonperturbative Shell-Model Interactions from the in-Medium Similarity Renormalization Group.” <em>Phys. Rev. Lett.</em> 113 (14). American Physical Society:142501. <a href="https://doi.org/10.1103/PhysRevLett.113.142501" class="uri">https://doi.org/10.1103/PhysRevLett.113.142501</a>.</p>
</div>
<div id="ref-BOGNER201094">
<p>Bogner, S.K., R.J. Furnstahl, and A. Schwenk. 2010. “From Low-Momentum Interactions to Nuclear Structure.” <em>Progress in Particle and Nuclear Physics</em> 65 (1):94–147. <a href="https://doi.org/10.1016/j.ppnp.2010.03.001" class="uri">https://doi.org/10.1016/j.ppnp.2010.03.001</a>.</p>
</div>
<div id="ref-Sphinx">
<p>Brandl, Georg. 2018. “Sphinx: Python Documentation Generator.” <a href="http://www.sphinx-doc.org" class="uri">http://www.sphinx-doc.org</a>.</p>
</div>
<div id="ref-RevModPhys.39.771">
<p>Brandow, Baird H. 1967. “Linked-Cluster Expansions for the Nuclear Many-Body Problem.” <em>Rev. Mod. Phys.</em> 39 (4). American Physical Society:771–828. <a href="https://doi.org/10.1103/RevModPhys.39.771" class="uri">https://doi.org/10.1103/RevModPhys.39.771</a>.</p>
</div>
<div id="ref-brody1967tables">
<p>Brody, T.A., and M. Moshinsky. 1967. <em>Tables of Transformation Brackets for Nuclear Shell-Model Calculations</em>. 2nd ed. Mexico.</p>
</div>
<div id="ref-doi:10.1146/annurev.ns.38.120188.000333">
<p>Brown, B A, and B H Wildenthal. 1988. “Status of the Nuclear Shell Model.” <em>Annual Review of Nuclear and Particle Science</em> 38 (1):29–66. <a href="https://doi.org/10.1146/annurev.ns.38.120188.000333" class="uri">https://doi.org/10.1146/annurev.ns.38.120188.000333</a>.</p>
</div>
<div id="ref-broyden1965class">
<p>Broyden, Charles G. 1965. “A Class of Methods for Solving Nonlinear Simultaneous Equations.” <em>Math. Comput.</em> 19 (92). JSTOR:577–93. <a href="https://doi.org/10.1090/S0025-5718-1965-0198670-6" class="uri">https://doi.org/10.1090/S0025-5718-1965-0198670-6</a>.</p>
</div>
<div id="ref-tuprints4069">
<p>Calci, Angelo. 2014. “Evolved Chiral Hamiltonians at the Three-Body Level and Beyond.” PhD thesis, Darmstadt: Technische Universität. <a href="https://tuprints.ulb.tu-darmstadt.de/4069/" class="uri">https://tuprints.ulb.tu-darmstadt.de/4069/</a>.</p>
</div>
<div id="ref-Cargo">
<p>“Cargo: The Rust Package Manager.” n.d. GitHub. <a href="https://github.com/rust-lang/cargo" class="uri">https://github.com/rust-lang/cargo</a>.</p>
</div>
<div id="ref-ClFmt">
<p><em>ClangFormat</em>. 2017. LLVM. <a href="https://clang.llvm.org/docs/ClangFormat.html" class="uri">https://clang.llvm.org/docs/ClangFormat.html</a>.</p>
</div>
<div id="ref-Gofmt">
<p><em>Command Gofmt</em>. n.d. Google. <a href="https://golang.org/cmd/gofmt/" class="uri">https://golang.org/cmd/gofmt/</a>.</p>
</div>
<div id="ref-darwin_1931">
<p>Darwin, C. G. 1931. “The Diamagnetism of the Free Electron.” <em>Mathematical Proceedings of the Cambridge Philosophical Society</em> 27 (1). Cambridge University Press:86–90. <a href="https://doi.org/10.1017/S0305004100009373" class="uri">https://doi.org/10.1017/S0305004100009373</a>.</p>
</div>
<div id="ref-PhysRevC.68.041001">
<p>Entem, D. R., and R. Machleidt. 2003. “Accurate Charge-Dependent Nucleon-Nucleon Potential at Fourth Order of Chiral Perturbation Theory.” <em>Phys. Rev. C</em> 68 (4). American Physical Society:041001. <a href="https://doi.org/10.1103/PhysRevC.68.041001" class="uri">https://doi.org/10.1103/PhysRevC.68.041001</a>.</p>
</div>
<div id="ref-RevModPhys.81.1773">
<p>Epelbaum, E., H.-W. Hammer, and Ulf-G. Meißner. 2009. “Modern Theory of Nuclear Forces.” <em>Rev. Mod. Phys.</em> 81 (4). American Physical Society:1773–1825. <a href="https://doi.org/10.1103/RevModPhys.81.1773" class="uri">https://doi.org/10.1103/RevModPhys.81.1773</a>.</p>
</div>
<div id="ref-PhysRev.28.695">
<p>Epstein, Paul S. 1926. “The Stark Effect from the Point of View of Schroedinger’s Quantum Theory.” <em>Phys. Rev.</em> 28 (4). American Physical Society:695–710. <a href="https://doi.org/10.1103/PhysRev.28.695" class="uri">https://doi.org/10.1103/PhysRev.28.695</a>.</p>
</div>
<div id="ref-Evangelista">
<p>Evangelista, Francesco A. 2014. “A Driven Similarity Renormalization Group Approach to Quantum Many-Body Problems.” <em>J. Chem. Phys.</em> 141 (5):054109. <a href="https://doi.org/10.1063/1.4890660" class="uri">https://doi.org/10.1063/1.4890660</a>.</p>
</div>
<div id="ref-PhysRev.76.7496">
<p>Feynman, R. P. 1949. “The Theory of Positrons.” <em>Phys. Rev.</em> 76 (6). American Physical Society:749–59. <a href="https://doi.org/10.1103/PhysRev.76.749" class="uri">https://doi.org/10.1103/PhysRev.76.749</a>.</p>
</div>
<div id="ref-Fock1928">
<p>Fock, V. 1928. “Bemerkung Zur Quantelung Des Harmonischen Oszillators Im Magnetfeld.” <em>Z. Phys.</em> 47 (5):446–48. <a href="https://doi.org/10.1007/BF01390750" class="uri">https://doi.org/10.1007/BF01390750</a>.</p>
</div>
<div id="ref-Fock1930">
<p>———. 1930. “Näherungsmethode Zur Lösung Des Quantenmechanischen Mehrkörperproblems.” <em>Z. Phys.</em> 61 (1):126–48. <a href="https://doi.org/10.1007/BF01340294" class="uri">https://doi.org/10.1007/BF01340294</a>.</p>
</div>
<div id="ref-FNV">
<p>Fowler, Glenn, Landon Curt Noll, Kiem-Phong Vo, Donald Eastlake, and Tony Hansen. 2017. “The Fnv Non-Cryptographic Hash Algorithm.” Internet-Draft draft-eastlake-fnv-14. IETF Secretariat; Working Draft. <a href="https://tools.ietf.org/html/draft-eastlake-fnv-14" class="uri">https://tools.ietf.org/html/draft-eastlake-fnv-14</a>.</p>
</div>
<div id="ref-Git">
<p>“Git.” 2017. <a href="https://git-scm.com" class="uri">https://git-scm.com</a>.</p>
</div>
<div id="ref-Goldstone267">
<p>Goldstone, Jeffrey. 1957. “Derivation of the Brueckner Many-Body Theory.” <em>Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering Sciences</em> 239 (1217). The Royal Society:267–79. <a href="https://doi.org/10.1098/rspa.1957.0037" class="uri">https://doi.org/10.1098/rspa.1957.0037</a>.</p>
</div>
<div id="ref-Goto:2008:AHM:1356052.1356053">
<p>Goto, Kazushige, and Robert A. van de Geijn. 2008. “Anatomy of High-Performance Matrix Multiplication.” <em>ACM Trans. Math. Softw.</em> 34 (3). New York, NY, USA: ACM:12:1–12:25. <a href="https://doi.org/10.1145/1356052.1356053" class="uri">https://doi.org/10.1145/1356052.1356053</a>.</p>
</div>
<div id="ref-Granlund12">
<p>Granlund, Torbjörn, and the GMP development team. 2016. <em>GNU Mp: The Gnu Multiple Precision Arithmetic Library</em>. 6.1.2 ed. <a href="https://gmplib.org" class="uri">https://gmplib.org</a>.</p>
</div>
<div id="ref-Gregg:2016:FG:2942427.2909476">
<p>Gregg, Brendan. 2016. “The Flame Graph.” <em>Commun. ACM</em> 59 (6). New York, NY, USA: ACM:48–57. <a href="https://doi.org/10.1145/2909476" class="uri">https://doi.org/10.1145/2909476</a>.</p>
</div>
<div id="ref-HALKIER1999437">
<p>Halkier, Asger, Trygve Helgaker, Poul Jørgensen, Wim Klopper, and Jeppe Olsen. 1999. “Basis-Set Convergence of the Energy in Molecular Hartree–Fock Calculations.” <em>Chem. Phys. Lett.</em> 302 (5):437–46. <a href="https://doi.org/10.1016/S0009-2614(99)00179-7" class="uri">https://doi.org/10.1016/S0009-2614(99)00179-7</a>.</p>
</div>
<div id="ref-hartree_1928">
<p>Hartree, D. R. 1928. “The Wave Mechanics of an Atom with a Non-Coulomb Central Field. Part I. Theory and Methods.” <em>Math. Proc. Cambridge</em> 24 (1). Cambridge University Press:89–110. <a href="https://doi.org/10.1017/S0305004100011919" class="uri">https://doi.org/10.1017/S0305004100011919</a>.</p>
</div>
<div id="ref-Doxygen">
<p>Heesch, Dimitri van. 2017. “Doxygen.” <a href="http://doxygen.org" class="uri">http://doxygen.org</a>.</p>
</div>
<div id="ref-HeikoReview">
<p>Hergert, H. 2017. “In-Medium Similarity Renormalization Group for Closed and Open-Shell Nuclei.” <em>Phys. Scr.</em> 92 (2):023002. <a href="https://doi.org/10.1088/1402-4896/92/2/023002" class="uri">https://doi.org/10.1088/1402-4896/92/2/023002</a>.</p>
</div>
<div id="ref-PhysRevC.87.034307">
<p>Hergert, H., S. K. Bogner, S. Binder, A. Calci, J. Langhammer, R. Roth, and A. Schwenk. 2013. “In-Medium Similarity Renormalization Group with Chiral Two- Plus Three-Nucleon Interactions.” <em>Phys. Rev. C</em> 87 (3). American Physical Society:034307. <a href="https://doi.org/10.1103/PhysRevC.87.034307" class="uri">https://doi.org/10.1103/PhysRevC.87.034307</a>.</p>
</div>
<div id="ref-Hergert2016165">
<p>Hergert, H., S. K. Bogner, T. D. Morris, A. Schwenk, and K. Tsukiyama. 2016. “The in-Medium Similarity Renormalization Group: A Novel Ab Initio Method for Nuclei.” <em>Phys. Rep.</em> 621:165. <a href="https://doi.org/10.1016/j.physrep.2015.12.007" class="uri">https://doi.org/10.1016/j.physrep.2015.12.007</a>.</p>
</div>
<div id="ref-HJORTHJENSEN1995125">
<p>Hjorth-Jensen, Morten, Thomas T. S. Kuo, and Eivind Osnes. 1995. “Realistic Effective Interactions for Nuclear Systems.” <em>Physics Reports</em> 261 (3):125–270. <a href="https://doi.org/10.1016/0370-1573(95)00012-6" class="uri">https://doi.org/10.1016/0370-1573(95)00012-6</a>.</p>
</div>
<div id="ref-lnp936">
<p>Hjorth-Jensen, Morten, Maria Paola Lombardo, and Ubirajara van Kolck. 2017. <em>An Advanced Course in Computational Nuclear Physics: Bridging the Scales from Quarks to Neutron Stars</em>. Vol. 936. Lecture Notes in Physics. Cham: Springer International Publishing. <a href="https://doi.org/10.1007/978-3-319-53336-0_1" class="uri">https://doi.org/10.1007/978-3-319-53336-0_1</a>.</p>
</div>
<div id="ref-Hoelbling2014">
<p>Hoelbling, Christian. 2014. “Lattice Qcd: Concepts, Techniques and Some Results.” <em>Acta Physica Polonica B</em> 45 (12):2143. <a href="https://doi.org/10.5506/APhysPolB.45.2143" class="uri">https://doi.org/10.5506/APhysPolB.45.2143</a>.</p>
</div>
<div id="ref-hoegberget2013thesis">
<p>Høgberget, Jørgen. 2013. “Quantum Monte-Carlo Studies of Generalized Many-Body Systems.” Master’s thesis, University of Oslo. <a href="https://www.duo.uio.no/handle/10852/37167" class="uri">https://www.duo.uio.no/handle/10852/37167</a>.</p>
</div>
<div id="ref-HUGENHOLTZ1957481">
<p>Hugenholtz, N. M. 1957. “Perturbation Theory of Large Quantum Systems.” <em>Physica</em> 23 (1):481–532. <a href="https://doi.org/10.1016/S0031-8914(57)92950-6" class="uri">https://doi.org/10.1016/S0031-8914(57)92950-6</a>.</p>
</div>
<div id="ref-Iritani2016">
<p>Iritani, T., T. Doi, S. Aoki, S. Gongyo, T. Hatsuda, Y. Ikeda, T. Inoue, et al. 2016. “Mirage in Temporal Correlation Functions for Baryon-Baryon Interactions in Lattice Qcd.” <em>Journal of High Energy Physics</em> 1610 (10):101. <a href="https://doi.org/10.1007/JHEP10(2016)101" class="uri">https://doi.org/10.1007/JHEP10(2016)101</a>.</p>
</div>
<div id="ref-PhysRevLett.99.022001">
<p>Ishii, N., S. Aoki, and T. Hatsuda. 2007. “Nuclear Force from Lattice Qcd.” <em>Phys. Rev. Lett.</em> 99 (2). American Physical Society:022001. <a href="https://doi.org/10.1103/PhysRevLett.99.022001" class="uri">https://doi.org/10.1103/PhysRevLett.99.022001</a>.</p>
</div>
<div id="ref-ISHII2012437">
<p>Ishii, Noriyoshi, Sinya Aoki, Takumi Doi, Tetsuo Hatsuda, Yoichi Ikeda, Takashi Inoue, Keiko Murano, Hidekatsu Nemura, and Kenji Sasaki. 2012. “Hadron–Hadron Interactions from Imaginary-Time Nambu–Bethe–Salpeter Wave Function on the Lattice.” <em>Physics Letters B</em> 712 (4):437–41. <a href="https://doi.org/10.1016/j.physletb.2012.04.076" class="uri">https://doi.org/10.1016/j.physletb.2012.04.076</a>.</p>
</div>
<div id="ref-C11">
<p>“ISO International Standard Iso/Iec 9899:2011 – Programming Languages c.” 2011. Standard. Geneva, Switzerland: International Organization for Standardization. <a href="http://open-std.org/jtc1/sc22/wg14/www/standards.html#9899" class="uri">http://open-std.org/jtc1/sc22/wg14/www/standards.html#9899</a>.</p>
</div>
<div id="ref-Jim2002CycloneAS">
<p>Jim, Trevor, J. Gregory Morrisett, Dan Grossman, Michael W. Hicks, James Cheney, and Yanling Wang. 2002. “Cyclone: A Safe Dialect of c.” In <em>USENIX Annual Technical Conference, General Track</em>. <a href="http://www.cs.umd.edu/~mwh/papers/cyclone-cuj.pdf" class="uri">http://www.cs.umd.edu/~mwh/papers/cyclone-cuj.pdf</a>.</p>
</div>
<div id="ref-Jucys">
<p>“Jucys.” n.d. GitHub. <a href="https://github.com/Rufflewind/jucys" class="uri">https://github.com/Rufflewind/jucys</a>.</p>
</div>
<div id="ref-kehrein2006flow">
<p>Kehrein, S. 2006. <em>The Flow Equation Approach to Many-Particle Systems</em>. Springer Tracts in Modern Physics. Springer. <a href="https://doi.org/10.1007/3-540-34068-8" class="uri">https://doi.org/10.1007/3-540-34068-8</a>.</p>
</div>
<div id="ref-KLOPPER198717">
<p>Klopper, Wim, and Werner Kutzelnigg. 1987. “Møller-Plesset Calculations Taking Care of the Correlation Cusp.” <em>Chem. Phys. Lett.</em> 134 (1):17–22. <a href="https://doi.org/10.1016/0009-2614(87)80005-2" class="uri">https://doi.org/10.1016/0009-2614(87)80005-2</a>.</p>
</div>
<div id="ref-KNOWLES1984315">
<p>Knowles, P. J., and N. C. Handy. 1984. “A New Determinant-Based Full Configuration Interaction Method.” <em>Chemical Physics Letters</em> 111 (4):315–21. <a href="https://doi.org/10.1016/0009-2614(84)85513-X" class="uri">https://doi.org/10.1016/0009-2614(84)85513-X</a>.</p>
</div>
<div id="ref-explicitcorrelationreview">
<p>Kong, Liguo, Florian A. Bischoff, and Edward F. Valeev. 2012. “Explicitly Correlated R12/F12 Methods for Electronic Structure.” <em>Chem. Rev.</em> 112 (1):75–107. <a href="https://doi.org/10.1021/cr200204r" class="uri">https://doi.org/10.1021/cr200204r</a>.</p>
</div>
<div id="ref-KUO1981237">
<p>Kuo, T. T. S, J. Shurpin, K. C. Tam, E. Osnes, and P. J. Ellis. 1981. “A Simple Method for Evaluating Goldstone Diagrams in an Angular Momentum Coupled Representation.” <em>Annals of Physics</em> 132 (2):237–76. <a href="https://doi.org/10.1016/0003-4916(81)90068-3" class="uri">https://doi.org/10.1016/0003-4916(81)90068-3</a>.</p>
</div>
<div id="ref-Kutzelnigg1985">
<p>Kutzelnigg, Werner. 1985. “R12-Dependent Terms in the Wave Function as Closed Sums of Partial Wave Amplitudes for Large L.” <em>Theor. Chim. Acta</em> 68 (6):445–69. <a href="https://doi.org/10.1007/BF00527669" class="uri">https://doi.org/10.1007/BF00527669</a>.</p>
</div>
<div id="ref-2008arXiv0810.2644K">
<p>Kvaal, S. 2008. “Open Source Fci Code for Quantum Dots and Effective Interactions.” <em>ArXiv E-Prints</em>, October.</p>
</div>
<div id="ref-Kvaal2007">
<p>Kvaal, S., M. Hjorth-Jensen, and H. Møll Nilsen. 2007. “Effective Interactions, Large-Scale Diagonalization, and One-Dimensional Quantum Dots.” <em>Phys. Rev. B</em> 76:085421. <a href="https://doi.org/10.1103/PhysRevB.76.085421" class="uri">https://doi.org/10.1103/PhysRevB.76.085421</a>.</p>
</div>
<div id="ref-PhysRevB.80.045321">
<p>Kvaal, Simen. 2009. “Harmonic Oscillator Eigenfunction Expansions, Quantum Dots, and Effective Interactions.” <em>Phys. Rev. B</em> 80:045321. <a href="https://doi.org/10.1103/PhysRevB.80.045321" class="uri">https://doi.org/10.1103/PhysRevB.80.045321</a>.</p>
</div>
<div id="ref-Kvasnicka1974">
<p>Kvasnička, V. 1974. “Construction of Model Hamiltonians in Framework of Rayleigh-Schrödinger Perturbation Theory.” <em>Czech. J. Phys. Sect. B</em> 24 (6):605–15. <a href="https://doi.org/10.1007/BF01587295" class="uri">https://doi.org/10.1007/BF01587295</a>.</p>
</div>
<div id="ref-tuprints3945">
<p>Langhammer, Joachim. 2014. “Chiral Three-Nucleon Interactions in Ab-Initio Nuclear Structure and Reactions.” PhD thesis, Darmstadt: Technische Universität. <a href="https://tuprints.ulb.tu-darmstadt.de/3945/" class="uri">https://tuprints.ulb.tu-darmstadt.de/3945/</a>.</p>
</div>
<div id="ref-Lawson:1979:BLA:355841.355847">
<p>Lawson, C. L., R. J. Hanson, D. R. Kincaid, and F. T. Krogh. 1979. “Basic Linear Algebra Subprograms for Fortran Usage.” <em>ACM Trans. Math. Softw.</em> 5 (3). New York, NY, USA: ACM:308–23. <a href="https://doi.org/10.1145/355841.355847" class="uri">https://doi.org/10.1145/355841.355847</a>.</p>
</div>
<div id="ref-Lepage2005">
<p>Lepage, G. P. 2005. “What Is Renormalization?” <em>ArXiv</em>, June.</p>
</div>
<div id="ref-10.2307/43633451">
<p>Levenberg, Kenneth. 1944. “A Method for the Solution of Certain Non-Linear Problems in Least Squares.” <em>Q. Appl. Math.</em> 2 (2). Brown University:164–68. <a href="https://www.jstor.org/stable/43633451" class="uri">https://www.jstor.org/stable/43633451</a>.</p>
</div>
<div id="ref-0022-3700-7-18-010">
<p>Lindgren, I. 1974. “The Rayleigh-Schrodinger Perturbation and the Linked-Diagram Theorem for a Multi-Configurational Model Space.” <em>J. Phys. Pt. B Atom. M. P.</em> 7 (18):2441. <a href="https://doi.org/10.1088/0022-3700/7/18/010" class="uri">https://doi.org/10.1088/0022-3700/7/18/010</a>.</p>
</div>
<div id="ref-LindgrenMorrison1986">
<p>Lindgren, Ingvar, and John Morrison. 1986. <em>Atomic Many-Body Theory</em>. 2nd ed. Vol. 3. Springer Series on Atomic, Optical, and Plasma Physics. Berlin, Heidelberg: Springer. <a href="https://doi.org/10.1007/978-3-642-96614-9" class="uri">https://doi.org/10.1007/978-3-642-96614-9</a>.</p>
</div>
<div id="ref-lohne2010coupled">
<p>Lohne, Magnus Pedersen. 2010. “Coupled-Cluster Studies of Quantum Dots.” Master’s thesis, University of Oslo. <a href="https://www.duo.uio.no/handle/10852/10966" class="uri">https://www.duo.uio.no/handle/10852/10966</a>.</p>
</div>
<div id="ref-MACHLEIDT20111">
<p>Machleidt, R., and D. R. Entem. 2011. “Chiral Effective Field Theory and Nuclear Forces.” <em>Physics Reports</em> 503 (1):1–75. <a href="https://doi.org/10.1016/j.physrep.2011.02.001" class="uri">https://doi.org/10.1016/j.physrep.2011.02.001</a>.</p>
</div>
<div id="ref-Haddock">
<p>Marlow, Simon. 2017. “Haddock: A Haskell Documentation Tool.” <a href="https://www.haskell.org/haddock/" class="uri">https://www.haskell.org/haddock/</a>.</p>
</div>
<div id="ref-doi:10.1137/0111030">
<p>Marquardt, Donald W. 1963. “An Algorithm for Least-Squares Estimation of Nonlinear Parameters.” <em>J. Soc. Ind. Appl. Math.</em> 11 (2):431–41. <a href="https://doi.org/10.1137/0111030" class="uri">https://doi.org/10.1137/0111030</a>.</p>
</div>
<div id="ref-Mazziotti2">
<p>Mazziotti, David A. 2007a. “Anti-Hermitian Formulation of the Contracted Schrödinger Theory.” In <em>Reduced-Density-Matrix Mechanics: With Application to Many-Electron Atoms and Molecules</em>, 331–42. John Wiley&amp; Sons, Inc. <a href="https://doi.org/10.1002/9780470106600.ch12" class="uri">https://doi.org/10.1002/9780470106600.ch12</a>.</p>
</div>
<div id="ref-Mazziotti1">
<p>———. 2007b. “Anti-Hermitian Part of the Contracted Schrödinger Equation for the Direct Calculation of Two-Electron Reduced Density Matrices.” <em>Phys. Rev. A</em> 75 (2). American Physical Society:022505. <a href="https://doi.org/10.1103/PhysRevA.75.022505" class="uri">https://doi.org/10.1103/PhysRevA.75.022505</a>.</p>
</div>
<div id="ref-Hg">
<p>“Mercurial.” 2017. <a href="https://www.mercurial-scm.org" class="uri">https://www.mercurial-scm.org</a>.</p>
</div>
<div id="ref-MIT">
<p>“MIT License.” n.d. Open Source Initiative. <a href="https://opensource.org/licenses/MIT" class="uri">https://opensource.org/licenses/MIT</a>.</p>
</div>
<div id="ref-MoellerPlesset1934">
<p>Møller, C., and M. S. Plesset. 1934. “Note on an Approximation Treatment for Many-Electron Systems.” <em>Phys. Rev.</em> 46 (October):618–22. <a href="https://doi.org/10.1103/PhysRev.46.618" class="uri">https://doi.org/10.1103/PhysRev.46.618</a>.</p>
</div>
<div id="ref-More:126569">
<p>Moré, J J, B S Garbow, and K E Hillstrom. 1980. <em>User Guide for MINPACK-1</em>. Argonne, IL: Argonne Nat. Lab. <a href="https://www.mcs.anl.gov/~more/ANL8074b.pdf" class="uri">https://www.mcs.anl.gov/~more/ANL8074b.pdf</a>.</p>
</div>
<div id="ref-More1978">
<p>Moré, Jorge J. 1978. “The Levenberg-Marquardt Algorithm: Implementation and Theory.” In <em>Numerical Analysis: Proceedings of the Biennial Conference Held at Dundee, June 28–July 1, 1977</em>, edited by G. A. Watson, 105–16. Berlin, Heidelberg: Springer. <a href="https://doi.org/10.1007/BFb0067700" class="uri">https://doi.org/10.1007/BFb0067700</a>.</p>
</div>
<div id="ref-PhysRevC.92.034331">
<p>Morris, T. D., N. M. Parzuchowski, and S. K. Bogner. 2015. “Magnus Expansion and in-Medium Similarity Renormalization Group.” <em>Phys. Rev. C</em> 92 (3). American Physical Society:034331. <a href="https://doi.org/10.1103/PhysRevC.92.034331" class="uri">https://doi.org/10.1103/PhysRevC.92.034331</a>.</p>
</div>
<div id="ref-morris2016thesis">
<p>Morris, Titus Dan. 2016. “Systematic Improvements of <em>Ab-Initio</em> in-Medium Similarity Renormalization Group Calculations.” PhD thesis, Michigan State University. <a href="https://publications.nscl.msu.edu/thesis/Morris_2016_387.pdf" class="uri">https://publications.nscl.msu.edu/thesis/Morris_2016_387.pdf</a>.</p>
</div>
<div id="ref-MOSHINSKY1959104">
<p>Moshinsky, Marcos. 1959. “Transformation Brackets for Harmonic Oscillator Functions.” <em>Nuclear Physics</em> 13 (1):104–16. <a href="https://doi.org/10.1016/0029-5582(59)90143-9" class="uri">https://doi.org/10.1016/0029-5582(59)90143-9</a>.</p>
</div>
<div id="ref-PhysRevC.62.054311">
<p>Navrátil, P., J. P. Vary, and B. R. Barrett. 2000. “Large-Basis Ab Initio No-Core Shell Model and Its Application to <span class="math inline">\({}^{12}\mathbf{C}\)</span>.” <em>Phys. Rev. C</em> 62 (5). American Physical Society:054311. <a href="https://doi.org/10.1103/PhysRevC.62.054311" class="uri">https://doi.org/10.1103/PhysRevC.62.054311</a>.</p>
</div>
<div id="ref-0954-3899-36-8-083101">
<p>Navrátil, Petr, Sofia Quaglioni, Ionel Stetcu, and Bruce R. Barrett. 2009. “Recent Developments in No-Core Shell-Model Calculations.” <em>Journal of Physics G: Nuclear and Particle Physics</em> 36 (8):083101. <a href="https://doi.org/10.1088/0954-3899/36/8/083101" class="uri">https://doi.org/10.1088/0954-3899/36/8/083101</a>.</p>
</div>
<div id="ref-Nesbet312">
<p>Nesbet, R. K. 1955. “Configuration Interaction in Orbital Theories.” <em>Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering Sciences</em> 230 (1182). The Royal Society:312–21. <a href="https://doi.org/10.1098/rspa.1955.0134" class="uri">https://doi.org/10.1098/rspa.1955.0134</a>.</p>
</div>
<div id="ref-CTreview">
<p>Neuscamman, Eric, Takeshi Yanai, and Garnet Kin-Lic Chan. 2010. “A Review of Canonical Transformation Theory.” <em>Int. Rev. Phys. Chem.</em> 29 (2):231–71. <a href="https://doi.org/10.1080/01442351003620540" class="uri">https://doi.org/10.1080/01442351003620540</a>.</p>
</div>
<div id="ref-DLMF">
<p>“NIST Digital Library of Mathematical Functions.” 2016. Release 1.0.14 of 2016-12-21. <a href="http://dlmf.nist.gov" class="uri">http://dlmf.nist.gov</a>.</p>
</div>
<div id="ref-doi:10.1063/1.455063">
<p>Olsen, Jeppe, Björn O. Roos, Poul Jørgensen, and Hans Jørgen Aa. Jensen. 1988. “Determinant Based Configuration Interaction Algorithms for Complete and Restricted Configuration Interaction Spaces.” <em>The Journal of Chemical Physics</em> 89 (4):2185–92. <a href="https://doi.org/10.1063/1.455063" class="uri">https://doi.org/10.1063/1.455063</a>.</p>
</div>
<div id="ref-olsen2013thesis">
<p>Olsen, Veronica K. Berglyd. 2013. “Full Configuration Interaction Simulation of Quantum Dots.” Master’s thesis, University of Oslo. <a href="https://www.duo.uio.no/handle/10852/34217" class="uri">https://www.duo.uio.no/handle/10852/34217</a>.</p>
</div>
<div id="ref-PhysRev.103.956">
<p>Pandya, Sudhir P. 1956. “Nucleon-Hole Interaction in Jj Coupling.” <em>Phys. Rev.</em> 103 (4). American Physical Society:956–57. <a href="https://doi.org/10.1103/PhysRev.103.956" class="uri">https://doi.org/10.1103/PhysRev.103.956</a>.</p>
</div>
<div id="ref-PhysRevC.95.044304">
<p>Parzuchowski, N. M., T. D. Morris, and S. K. Bogner. 2017. “Ab Initio Excited States from the in-Medium Similarity Renormalization Group.” <em>Phys. Rev. C</em> 95 (4). American Physical Society:044304. <a href="https://doi.org/10.1103/PhysRevC.95.044304" class="uri">https://doi.org/10.1103/PhysRevC.95.044304</a>.</p>
</div>
<div id="ref-parzuchowski2017thesis">
<p>Parzuchowski, Nathan Michael. 2017. “Nuclear Spectroscopy with the in-Medium Similarity Renormalization Group.” PhD thesis, Michigan State University. <a href="https://d.lib.msu.edu/etd/4630" class="uri">https://d.lib.msu.edu/etd/4630</a>.</p>
</div>
<div id="ref-PhysRevB.84.115302">
<p>Pedersen Lohne, M., G. Hagen, M. Hjorth-Jensen, S. Kvaal, and F. Pederiva. 2011. “<em>Ab Initio</em> Computation of the Energies of Circular Quantum Dots.” <em>Phys. Rev. B</em> 84:115302.</p>
</div>
<div id="ref-Perf">
<p>“Perf: Linux Profiling with Performance Counters.” n.d. <a href="https://perf.wiki.kernel.org" class="uri">https://perf.wiki.kernel.org</a>.</p>
</div>
<div id="ref-JCC:JCC540030413">
<p>Pulay, P. 1982. “Improved Scf Convergence Acceleration.” <em>J. Comput. Chem.</em> 3 (4). John Wiley &amp; Sons, Inc.:556–60. <a href="https://doi.org/10.1002/jcc.540030413" class="uri">https://doi.org/10.1002/jcc.540030413</a>.</p>
</div>
<div id="ref-PULAY1980393">
<p>Pulay, Péter. 1980. “Convergence Acceleration of Iterative Sequences. The Case of Scf Iteration.” <em>Chem. Phys. Lett.</em> 73 (2):393–98. <a href="https://doi.org/10.1016/0009-2614(80)80396-4" class="uri">https://doi.org/10.1016/0009-2614(80)80396-4</a>.</p>
</div>
<div id="ref-PhysRev.62.438">
<p>Racah, Giulio. 1942. “Theory of Complex Spectra. II.” <em>Phys. Rev.</em> 62 (9-10). American Physical Society:438–62. <a href="https://doi.org/10.1103/PhysRev.62.438" class="uri">https://doi.org/10.1103/PhysRev.62.438</a>.</p>
</div>
<div id="ref-doi:10.1137/S1064827503422932">
<p>Rasch, J., and A. C. H. Yu. 2004. “Efficient Storage Scheme for Precalculated Wigner 3j, 6j and Gaunt Coefficients.” <em>SIAM Journal on Scientific Computing</em> 25 (4):1416–28. <a href="https://doi.org/10.1137/S1064827503422932" class="uri">https://doi.org/10.1137/S1064827503422932</a>.</p>
</div>
<div id="ref-Regge1958">
<p>Regge, T. 1958. “Symmetry Properties of Clebsch-Gordon’s Coefficients.” <em>Il Nuovo Cimento</em> 10 (3):544–45. <a href="https://doi.org/10.1007/BF02859841" class="uri">https://doi.org/10.1007/BF02859841</a>.</p>
</div>
<div id="ref-reimann2013quantum">
<p>Reimann, Sarah. 2013. “Quantum-Mechanical Systems in Traps and Similarity Renormalization Group Theory.” Master’s thesis, University of Oslo. <a href="https://www.duo.uio.no/handle/10852/37161" class="uri">https://www.duo.uio.no/handle/10852/37161</a>.</p>
</div>
<div id="ref-PEP8">
<p>Rossum, Guido van, Barry Warsaw, and Nick Coghlan. 2001. “Style Guide for Python Code.” Python Enhancement Proposal 8. <a href="https://www.python.org/dev/peps/pep-0008/" class="uri">https://www.python.org/dev/peps/pep-0008/</a>.</p>
</div>
<div id="ref-PhysRevLett.109.052501">
<p>Roth, Robert, Sven Binder, Klaus Vobig, Angelo Calci, Joachim Langhammer, and Petr Navrátil. 2012. “Medium-Mass Nuclei with Normal-Ordered Chiral Nn+3n Interactions.” <em>Phys. Rev. Lett.</em> 109. American Physical Society:052501.</p>
</div>
<div id="ref-Rust">
<p>“Rust.” n.d. <a href="https://www.rust-lang.org" class="uri">https://www.rust-lang.org</a>.</p>
</div>
<div id="ref-FmtRFCs">
<p>“Rust Code Formatting Rfcs.” n.d. GitHub. <a href="https://github.com/rust-lang-nursery/fmt-rfcs" class="uri">https://github.com/rust-lang-nursery/fmt-rfcs</a>.</p>
</div>
<div id="ref-Rustfmt">
<p>“Rustfmt.” n.d. GitHub. <a href="https://github.com/rust-lang-nursery/rustfmt" class="uri">https://github.com/rust-lang-nursery/rustfmt</a>.</p>
</div>
<div id="ref-shampine1975computer">
<p>Shampine, L. F., and M. K. Gordon. 1975. <em>Computer Solution of Ordinary Differential Equations: The Initial Value Problem</em>. Freeman.</p>
</div>
<div id="ref-odesolver">
<p>Shampine, Lawrence, and Marilyn Gordon. n.d. “ODE: Ordinary Differential Equation Initial-Value Problem Solver.” <a href="http://www.netlib.org/ode/ode.f" class="uri">http://www.netlib.org/ode/ode.f</a>.</p>
</div>
<div id="ref-sgode">
<p>Shampine, Lawrence, Marilyn Gordon, and Fei Yuan. n.d. “Parallelizable Shampine-Gordon Ode Solver.” GitHub. <a href="https://github.com/xrf/sg-ode" class="uri">https://github.com/xrf/sg-ode</a>.</p>
</div>
<div id="ref-shavitt2009many">
<p>Shavitt, I., and R. J. Bartlett. 2009. <em>Many-Body Methods in Chemistry and Physics: MBPT and Coupled-Cluster Theory</em>. Cambridge Molecular Science. Cambridge University Press.</p>
</div>
<div id="ref-PhysRevLett.110.226401">
<p>Shepherd, James J., and Andreas Grüneis. 2013. “Many-Body Quantum Chemistry for the Electron Gas: Convergent Perturbative Theories.” <em>Phys. Rev. Lett.</em> 110 (22). American Physical Society:226401. <a href="https://doi.org/10.1103/PhysRevLett.110.226401" class="uri">https://doi.org/10.1103/PhysRevLett.110.226401</a>.</p>
</div>
<div id="ref-PhysRevLett.118.032502">
<p>Stroberg, S. R., A. Calci, H. Hergert, J. D. Holt, S. K. Bogner, R. Roth, and A. Schwenk. 2017. “Nucleus-Dependent Valence-Space Approach to Nuclear Structure.” <em>Phys. Rev. Lett.</em> 118 (3). American Physical Society:032502. <a href="https://doi.org/10.1103/PhysRevLett.118.032502" class="uri">https://doi.org/10.1103/PhysRevLett.118.032502</a>.</p>
</div>
<div id="ref-PhysRevC.93.051301">
<p>Stroberg, S. R., H. Hergert, J. D. Holt, S. K. Bogner, and A. Schwenk. 2016. “Ground and Excited States of Doubly Open-Shell Nuclei from Ab Initio Valence-Space Hamiltonians.” <em>Phys. Rev. C</em> 93 (5). American Physical Society:051301. <a href="https://doi.org/10.1103/PhysRevC.93.051301" class="uri">https://doi.org/10.1103/PhysRevC.93.051301</a>.</p>
</div>
<div id="ref-Suhonen2007">
<p>Suhonen, Jouni. 2007. <em>From Nucleons to Nucleus: Concepts of Microscopic Nuclear Theory</em>. 1st ed. Theoretical and Mathematical Physics. Berlin, Heidelberg: Springer. <a href="https://doi.org/10.1007/978-3-540-48861-3" class="uri">https://doi.org/10.1007/978-3-540-48861-3</a>.</p>
</div>
<div id="ref-Talmi1952">
<p>Talmi, Igal. 1952. “Nuclear Spectroscopy with Harmonic Oscillator Wave-Functions.” <em>Helvetica Physica Acta</em> 25 (3):185–234. <a href="https://doi.org/10.5169/seals-112307" class="uri">https://doi.org/10.5169/seals-112307</a>.</p>
</div>
<div id="ref-RustBook">
<p>The Rust Project Developers. 2017. <em>The Rust Programming Language</em>. Edited by Steve Klabnik. 2nd ed. https://doc.rust-lang.org/book. <a href="https://github.com/rust-lang/book" class="uri">https://github.com/rust-lang/book</a>.</p>
</div>
<div id="ref-THOENNESSEN2010688c">
<p>Thoennessen, M. 2010. “Plans for the Facility for Rare Isotope Beams.” <em>Nuclear Physics A</em> 834 (1):688c–693c. <a href="https://doi.org/10.1016/j.nuclphysa.2010.01.125" class="uri">https://doi.org/10.1016/j.nuclphysa.2010.01.125</a>.</p>
</div>
<div id="ref-PhysRevLett.106.222502">
<p>Tsukiyama, K., S. K. Bogner, and A. Schwenk. 2011. “In-Medium Similarity Renormalization Group for Nuclei.” <em>Phys. Rev. Lett.</em> 106:222502.</p>
</div>
<div id="ref-PhysRevC.85.061304">
<p>———. 2012. “In-Medium Similarity Renormalization Group for Open-Shell Nuclei.” <em>Phys. Rev. C</em> 85. American Physical Society:061304. <a href="https://doi.org/10.1103/PhysRevC.85.061304" class="uri">https://doi.org/10.1103/PhysRevC.85.061304</a>.</p>
</div>
<div id="ref-Ukawa2015">
<p>Ukawa, Akira. 2015. “Kenneth Wilson and Lattice Qcd.” <em>Journal of Statistical Physics</em> 160 (5):1081–1124. <a href="https://doi.org/10.1007/s10955-015-1197-x" class="uri">https://doi.org/10.1007/s10955-015-1197-x</a>.</p>
</div>
<div id="ref-Valgrind">
<p>Valgrind Developers. 2017. “Valgrind.” <a href="http://valgrind.org" class="uri">http://valgrind.org</a>.</p>
</div>
<div id="ref-Wang:2013:AAG:2503210.2503219">
<p>Wang, Qian, Xianyi Zhang, Yunquan Zhang, and Qing Yi. 2013. “AUGEM: Automatically Generate High Performance Dense Linear Algebra Kernels on X86 Cpus.” In <em>Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis</em>, 25:1–25:12. SC ’13. New York, NY, USA: ACM. <a href="https://doi.org/10.1145/2503210.2503219" class="uri">https://doi.org/10.1145/2503210.2503219</a>.</p>
</div>
<div id="ref-Wegner200177">
<p>Wegner, Franz J. 2001. “Flow Equations for Hamiltonians.” <em>Phys. Rep.</em> 348:77–89. <a href="https://doi.org/10.1016/S0370-1573(00)00136-8" class="uri">https://doi.org/10.1016/S0370-1573(00)00136-8</a>.</p>
</div>
<div id="ref-doi:10.1063/1.168745">
<p>Wei, Liqiang. 1998. “New Formula for 9-J Symbols and Their Direct Calculation.” <em>Computers in Physics</em> 12 (6):632–34. <a href="https://doi.org/10.1063/1.168745" class="uri">https://doi.org/10.1063/1.168745</a>.</p>
</div>
<div id="ref-WEI1999222">
<p>———. 1999. “Unified Approach for Exact Calculation of Angular Momentum Coupling and Recoupling Coefficients.” <em>Computer Physics Communications</em> 120 (2):222–30. <a href="https://doi.org/10.1016/S0010-4655(99)00232-5" class="uri">https://doi.org/10.1016/S0010-4655(99)00232-5</a>.</p>
</div>
<div id="ref-WEINBERG1979327">
<p>Weinberg, Steven. 1979. “Phenomenological Lagrangians.” <em>Physica A: Statistical Mechanics and Its Applications</em> 96 (1):327–40. <a href="https://doi.org/10.1016/0378-4371(79)90223-1" class="uri">https://doi.org/10.1016/0378-4371(79)90223-1</a>.</p>
</div>
<div id="ref-White:cond-mat0201346">
<p>White, S. R. 2002. “A Numerical Canonical Transformation Approach to Quantum Many Body Problems.” <em>J. Chem. Phys.</em> 117:7472.</p>
</div>
<div id="ref-PhysRev.80.268">
<p>Wick, G. C. 1950. “The Evaluation of the Collision Matrix.” <em>Phys. Rev.</em> 80 (2). American Physical Society:268–72. <a href="https://doi.org/10.1103/PhysRev.80.268" class="uri">https://doi.org/10.1103/PhysRev.80.268</a>.</p>
</div>
<div id="ref-Wigner1993">
<p>Wigner, E. P. 1993. “On the Matrices Which Reduce the Kronecker Products of Representations of S. R. Groups.” In <em>The Collected Works of Eugene Paul Wigner: Part a: The Scientific Papers</em>, edited by Arthur S. Wightman, 608–54. Berlin, Heidelberg: Springer. <a href="https://doi.org/10.1007/978-3-662-02781-3_42" class="uri">https://doi.org/10.1007/978-3-662-02781-3_42</a>.</p>
</div>
<div id="ref-WSH">
<p>“Wigner-Symbols.” 2015. Hackage. <a href="https://hackage.haskell.org/package/wigner-symbols" class="uri">https://hackage.haskell.org/package/wigner-symbols</a>.</p>
</div>
<div id="ref-WSR">
<p>“Wigner-Symbols.” 2017. crates.io: Rust Package Registry. <a href="https://crates.io/crates/wigner-symbols" class="uri">https://crates.io/crates/wigner-symbols</a>.</p>
</div>
<div id="ref-RevModPhys.55.583">
<p>Wilson, Kenneth G. 1983. “The Renormalization Group and Critical Phenomena.” <em>Rev. Mod. Phys.</em> 55 (3). American Physical Society:583–600. <a href="https://doi.org/10.1103/RevModPhys.55.583" class="uri">https://doi.org/10.1103/RevModPhys.55.583</a>.</p>
</div>
<div id="ref-WORMER200659">
<p>Wormer, Paul E. S., and Josef Paldus. 2006. “Angular Momentum Diagrams.” In, edited by J. R. Sabin and E. Brändas, 51:59–123. Advances in Quantum Chemistry, Supplement C. Academic Press. <a href="https://doi.org/10.1016/S0065-3276(06)51002-0" class="uri">https://doi.org/10.1016/S0065-3276(06)51002-0</a>.</p>
</div>
<div id="ref-OpenBLAS">
<p>Xianyi, Zhang, Wang Qian, and Werner Saar. 2017. “OpenBLAS.” <a href="http://www.openblas.net" class="uri">http://www.openblas.net</a>.</p>
</div>
<div id="ref-Lutario">
<p>Yuan, Fei. n.d. “Lutario.” GitHub. <a href="https://github.com/xrf/lutario" class="uri">https://github.com/xrf/lutario</a>.</p>
</div>
<div id="ref-SpEnergiesNucl">
<p>Yuan, Fei, Samuel J. Novario, Nathan M. Parzuchowski, S. K. Bogner, and Morten Hjorth-Jensen. n.d. “Addition and Removal Energies of Nuclei.”</p>
</div>
<div id="ref-doi:10.1063/1.4995615">
<p>Yuan, Fei, Samuel J. Novario, Nathan M. Parzuchowski, Sarah Reimann, S. K. Bogner, and Morten Hjorth-Jensen. 2017. “Addition and Removal Energies of Circular Quantum Dots.” <em>The Journal of Chemical Physics</em> 147 (16):164109. <a href="https://doi.org/10.1063/1.4995615" class="uri">https://doi.org/10.1063/1.4995615</a>.</p>
</div>
<div id="ref-Yutsis1962">
<p>Yutsis, A. P., I. B. Levinson, and V. V. Vanagas. 1962. <em>Mathematical Apparatus of the Theory of Angular Momentum</em>. Translated by A. Sen and R. N. Sen. Jerusalem: Israel Program for Scientific Translations. <a href="https://archive.org/details/nasa_techdoc_19630001624" class="uri">https://archive.org/details/nasa_techdoc_19630001624</a>.</p>
</div>
</div>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>URL: <a href="https://github.com/xrf/thesis" class="uri">https://github.com/xrf/thesis</a><a href="print.html#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>We use <span class="math inline">\(\hat{k}\)</span> for momentum to avoid confusion with <span class="math inline">\(p\)</span>, which will be used to denote the quantum numbers of the single-particle basis later on.<a href="print.html#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>A ket with <span class="math inline">\(\otimes\)</span> inside denotes a product state. Outside kets, <span class="math inline">\(\otimes\)</span> denotes the <em>tensor product constructor</em>, a multilinear operation that constructs maps multiple vectors to a vector in their tensor product space.<a href="print.html#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>To further add to the confusion, this <span class="math inline">\(\otimes\)</span> symbol denotes the <em>tensor product</em> of vector spaces.<a href="print.html#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>Mathematically, the space <span class="math inline">\(\mathbb{H}^0\)</span> is isomorphic to complex numbers.<a href="print.html#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>The <span class="math inline">\(\pm\)</span>-symmetrizer <span class="math inline">\(\hat{S}^\pm\)</span> should not be confused with the spin operator <span class="math inline">\(\hat{S}\)</span> introduced in later sections.<a href="print.html#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>Note the reversal of <span class="math inline">\(\hat{a}_r\)</span> and <span class="math inline">\(\hat{a}_s\)</span>.<a href="print.html#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>Note the reversal of annihilation operators again.<a href="print.html#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p>A product of field operators is sometimes referred to as an <em>operator string</em>.<a href="print.html#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p>In other literature, it is common to use the symbols <span class="math inline">\(\hat{F} = \hat{H}_1^\Phi\)</span>, <span class="math inline">\(\hat{\Gamma} = \hat{H}_2^\Phi\)</span>, and <span class="math inline">\(\hat{W} = \hat{H}_3^\Phi\)</span>.<a href="print.html#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p>That is, the result lie in the center of the algebra, commuting with all other elements.<a href="print.html#fnref11" class="footnote-back">↩</a></p></li>
<li id="fn12"><p>Unfortunately this shares the same notation as <span class="math inline">\(2 \times 3\)</span> matrices.<a href="print.html#fnref12" class="footnote-back">↩</a></p></li>
<li id="fn13"><p>Conversion from our presentation to the traditional presentation in, say, <span class="citation" data-cites="WORMER200659">(Wormer and Paldus 2006)</span> is done by a two-step process: (1) use diagrammatic rules to ensure that every internal line has an arrow and that every arrow on external lines (if any) point <em>away</em> from the terminal; (2) on any remaining external lines with no arrows, draw an arrow pointing toward the terminal. Now the diagram can be interpreted in the traditional manner. To convert back, simply revert step (2): delete all arrows on external lines that point toward the terminal.<a href="print.html#fnref13" class="footnote-back">↩</a></p></li>
<li id="fn14"><p>Because of this, unlike many-body diagrams, labels on lines are <em>not</em> optional.<a href="print.html#fnref14" class="footnote-back">↩</a></p></li>
<li id="fn15"><p>The unknown basis is distinguished from the known basis by the prime symbol <span class="math inline">\({}&#39;\)</span> in their labels.<a href="print.html#fnref15" class="footnote-back">↩</a></p></li>
<li id="fn16"><p>Hugenholtz skeletons are Hugenholtz diagrams without arrows.<a href="print.html#fnref16" class="footnote-back">↩</a></p></li>
<li id="fn17"><p>In some literature, the resolvent <span class="math inline">\(\hat{R}_u\)</span> is denoted by <span class="math display">\[\frac{\hat{Q}}{E^\circ_u - \hat{H}^\circ}\]</span><a href="print.html#fnref17" class="footnote-back">↩</a></p></li>
<li id="fn18"><p>These components are defined relative to the physical vacuum.<a href="print.html#fnref18" class="footnote-back">↩</a></p></li>
<li id="fn19"><p>Note the difference in notation compared to quantum dots.<a href="print.html#fnref19" class="footnote-back">↩</a></p></li>
<li id="fn20"><p>Note that <code>argc</code> counts the name of the program as an additional argument.<a href="print.html#fnref20" class="footnote-back">↩</a></p></li>
<li id="fn21"><p>This was tested on Clang 5.0.1 and GCC 7.2.1.<a href="print.html#fnref21" class="footnote-back">↩</a></p></li>
<li id="fn22"><p>It can, for example, destroy the data object, but it must immediately recreate a similar one in its place.<a href="print.html#fnref22" class="footnote-back">↩</a></p></li>
<li id="fn23"><p>We aim to use valid Rust code throughout to illustrate concepts, but the actual implementation may differ slightly in details.<a href="print.html#fnref23" class="footnote-back">↩</a></p></li>
<li id="fn24"><p>This is equivalent to <code>(T *)</code> in C or C++.<a href="print.html#fnref24" class="footnote-back">↩</a></p></li>
<li id="fn25"><p>This is equivalent to <code>size_t</code> in C or C++.<a href="print.html#fnref25" class="footnote-back">↩</a></p></li>
<li id="fn26"><p>This is approximately equivalent to <code>std::vector&lt;T&gt;</code> in C++.<a href="print.html#fnref26" class="footnote-back">↩</a></p></li>
<li id="fn27"><p>Generic data structures are known as templated types in C++.<a href="print.html#fnref27" class="footnote-back">↩</a></p></li>
<li id="fn28"><p>We could have asked for a total ordering instead of hashability, in which case we would use ordered trees instead of hash tables. However, trees are slower and the inherent ordering of trees does not convey any advantages for our purposes.<a href="print.html#fnref28" class="footnote-back">↩</a></p></li>
<li id="fn29"><p>The temporary array isn’t technically needed, especially if the language has good support for coroutines/generators, allowing the data to be passed into the generic channelized atlas initialization procedure in parallel. We found it easier to describe the algorithm this way, and regardless the temporary array has a negligible impact on performance.<a href="print.html#fnref29" class="footnote-back">↩</a></p></li>
<li id="fn30"><p>Not to be confused with the physical <span class="math inline">\(j\)</span> quantum number, which is put in <span class="math inline">\(\mu\)</span>.<a href="print.html#fnref30" class="footnote-back">↩</a></p></li>
<li id="fn31"><p>Benchmarked using <span class="math inline">\(e_{\mathrm{max}} = 4\)</span> for an <sup>16</sup>O-like system.<a href="print.html#fnref31" class="footnote-back">↩</a></p></li>
<li id="fn32"><p>Benchmarked using <span class="math inline">\(e_{\mathrm{max}} = 4\)</span> for an <sup>16</sup>O-like system.<a href="print.html#fnref32" class="footnote-back">↩</a></p></li>
<li id="fn33"><p>Unfortunately, SHA-1 attacks are becoming more and more possible, which means it may be possible for an attacker to forge commit hashes. Nonetheless, by accident it remains extremely difficult to have two different commits sharing identical commit hashes.<a href="print.html#fnref33" class="footnote-back">↩</a></p></li>
<li id="fn34"><p>API is a common programming acronym for <em>application programming interface</em>, or simply <em>interface</em>.<a href="print.html#fnref34" class="footnote-back">↩</a></p></li>
<li id="fn35"><p>In other languages, one might find <code>/**</code> or <code>/*!</code> prefixes for documentation comments.<a href="print.html#fnref35" class="footnote-back">↩</a></p></li>
</ol>
</section>

                </div>

                <!-- Mobile navigation buttons -->
                

                

            </div>

            

            

        </div>


        <!-- Local fallback for Font Awesome -->
        <script>
            if ($(".fa").css("font-family") !== "FontAwesome") {
                $('<link rel="stylesheet" type="text/css" href="_FontAwesome/css/font-awesome.css">').prependTo('head');
            }
        </script>

        <!-- Livereload script (if served using the cli tool) -->
        

        <script src="highlight.js"></script>
        <script src="book.js"></script>
    </body>
</html>
